
Feb 15  01:12:42.342
	[orchestrator] 09:12:40 SUCCESS Inference pool ready
[orchestrator] 09:12:40    INFO Initializing weight broadcast (type='filesystem')
[orchestrator] 09:12:40    INFO Initializing training batch sender (type='filesystem')
[orchestrator] 09:12:40    INFO Training from scratch. Skipping base weight reload because LoRA is enabled
[orchestrator] 09:12:40    INFO Starting orchestrator loop (max_steps=300)
[orchestrator] 09:12:40    INFO Starting orchestrator step 0
Feb 15  01:13:03.351
	[orchestrator] 09:13:01    INFO Logging samples to W&B table at step 0
[orchestrator] 09:13:01 SUCCESS Step 0 | Time: 20.30s | Reward: 0.0041 | Throughput: 3578.2 tokens/s | Seq. Length: 1095.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:13:01    INFO Starting orchestrator step 1
Feb 15  01:13:09.359
	[default0]:09:13:09 SUCCESS Step 0 | Time: 111.87s | Loss: 0.0004 | Entropy: 0.4112 | Mismatch KL: 0.0010 | Grad. Norm: 0.0036 | LR: 1.00e-05 | Throughput: 0 tokens/s | MFU: 0.0% | Peak Mem.: 38.8 GiB
Feb 15  01:13:18.359
	[orchestrator] 09:13:15 SUCCESS Step 1 | Time: 14.18s | Reward: 0.0000 | Throughput: 4998.7 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:13:15    INFO Starting orchestrator step 2
Feb 15  01:13:20.107
	[default0]:09:13:20 SUCCESS Step 1 | Time: 9.58s | Loss: 0.0000 | Entropy: 0.4274 | Mismatch KL: 0.0010 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 7413 tokens/s | MFU: 8.2% | Peak Mem.: 38.9 GiB
Feb 15  01:13:33.366
	[orchestrator] 09:13:32 SUCCESS Step 2 | Time: 17.16s | Reward: 0.0301 | Throughput: 4077.1 tokens/s | Seq. Length: 1085.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:13:32    INFO Starting orchestrator step 3
Feb 15  01:13:36.987
	[default0]:09:13:36 SUCCESS Step 2 | Time: 15.79s | Loss: -0.0018 | Entropy: 0.4312 | Mismatch KL: 0.0009 | Grad. Norm: 0.0074 | LR: 1.00e-05 | Throughput: 6035 tokens/s | MFU: 6.7% | Peak Mem.: 41.4 GiB
Feb 15  01:13:51.374
	[orchestrator] 09:13:50 SUCCESS Step 3 | Time: 17.44s | Reward: 0.0000 | Throughput: 4058.5 tokens/s | Seq. Length: 1095.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:13:50    INFO Starting orchestrator step 4
Feb 15  01:13:54.573
	[default0]:09:13:54 SUCCESS Step 3 | Time: 16.76s | Loss: 0.0000 | Entropy: 0.4222 | Mismatch KL: 0.0010 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 5430 tokens/s | MFU: 6.0% | Peak Mem.: 41.4 GiB
Feb 15  01:14:09.382
	[orchestrator] 09:14:07 SUCCESS Step 4 | Time: 17.02s | Reward: 0.0000 | Throughput: 4155.8 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:14:07    INFO Starting orchestrator step 5
Feb 15  01:14:11.247
	[default0]:09:14:11 SUCCESS Step 4 | Time: 15.78s | Loss: 0.0000 | Entropy: 0.4150 | Mismatch KL: 0.0009 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 5249 tokens/s | MFU: 5.8% | Peak Mem.: 41.4 GiB
Feb 15  01:14:24.389
	[orchestrator] 09:14:24 SUCCESS Step 5 | Time: 17.06s | Reward: 0.0020 | Throughput: 4151.7 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:14:24    INFO Starting orchestrator step 6
Feb 15  01:14:28.836
	[default0]:09:14:28 SUCCESS Step 5 | Time: 16.82s | Loss: 0.0000 | Entropy: 0.4234 | Mismatch KL: 0.0010 | Grad. Norm: 0.0009 | LR: 1.00e-05 | Throughput: 5077 tokens/s | MFU: 5.6% | Peak Mem.: 41.4 GiB
Feb 15  01:14:42.397
	[orchestrator] 09:14:41 SUCCESS Step 6 | Time: 17.01s | Reward: 0.0097 | Throughput: 4143.1 tokens/s | Seq. Length: 1093.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:14:41    INFO Starting orchestrator step 7
Feb 15  01:14:45.512
	[default0]:09:14:45 SUCCESS Step 6 | Time: 15.82s | Loss: 0.0002 | Entropy: 0.4282 | Mismatch KL: 0.0010 | Grad. Norm: 0.0024 | LR: 1.00e-05 | Throughput: 5019 tokens/s | MFU: 5.6% | Peak Mem.: 41.4 GiB
Feb 15  01:15:00.405
	[orchestrator] 09:14:58 SUCCESS Step 7 | Time: 17.66s | Reward: 0.0061 | Throughput: 3996.2 tokens/s | Seq. Length: 1093.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:14:58    INFO Starting orchestrator step 8
Feb 15  01:15:03.201
	[default0]:09:15:03 SUCCESS Step 7 | Time: 16.82s | Loss: 0.0001 | Entropy: 0.4204 | Mismatch KL: 0.0010 | Grad. Norm: 0.0019 | LR: 1.00e-05 | Throughput: 4933 tokens/s | MFU: 5.5% | Peak Mem.: 41.4 GiB
Feb 15  01:15:18.413
	[orchestrator] 09:15:16 SUCCESS Step 8 | Time: 17.20s | Reward: 0.0063 | Throughput: 4108.4 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:15:16    INFO Starting orchestrator step 9
Feb 15  01:15:20.786
	[default0]:09:15:20 SUCCESS Step 8 | Time: 16.77s | Loss: -0.0000 | Entropy: 0.4257 | Mismatch KL: 0.0010 | Grad. Norm: 0.0016 | LR: 1.00e-05 | Throughput: 4872 tokens/s | MFU: 5.4% | Peak Mem.: 41.4 GiB
Feb 15  01:15:33.419
	[orchestrator] 09:15:33 SUCCESS Step 9 | Time: 17.04s | Reward: 0.0041 | Throughput: 4104.6 tokens/s | Seq. Length: 1081.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:15:33    INFO Saving checkpoint at step 10
[orchestrator] 09:15:33    INFO Starting orchestrator step 10
Feb 15  01:15:37.856
	[default0]:09:15:37 SUCCESS Step 9 | Time: 16.15s | Loss: -0.0003 | Entropy: 0.4329 | Mismatch KL: 0.0009 | Grad. Norm: 0.0011 | LR: 1.00e-05 | Throughput: 4950 tokens/s | MFU: 5.5% | Peak Mem.: 43.5 GiB
Feb 15  01:15:38.662
	[default0]:09:15:38    INFO Saving checkpoint at step 10
Feb 15  01:16:09.436
	[orchestrator] 09:16:07    INFO Logging samples to W&B table at step 10
[orchestrator] 09:16:07 SUCCESS Step 10 | Time: 34.05s | Reward: 0.0038 | Throughput: 2048.7 tokens/s | Seq. Length: 1085.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 09:16:07    INFO Starting orchestrator step 11
Feb 15  01:16:27.445
	[orchestrator] 09:16:26 SUCCESS Step 11 | Time: 18.85s | Reward: -0.0011 | Throughput: 3759.2 tokens/s | Seq. Length: 1095.8 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 1
[orchestrator] 09:16:26    INFO Starting orchestrator step 12
[orchestrator] 09:16:27    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 11 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:16:30.524
	[default0]:09:16:30    INFO Saving weight checkpoint at step 10
Feb 15  01:17:42.971
	[default0]:09:17:42 SUCCESS Step 10 | Time: 4.73s | Loss: -0.0002 | Entropy: 0.4151 | Mismatch KL: 0.0009 | Grad. Norm: 0.0009 | LR: 1.00e-05 | Throughput: 2840 tokens/s | MFU: 3.2% | Peak Mem.: 43.5 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:17:45.481
	[orchestrator] 09:17:44    INFO Orchestrator resumed: checkpoint 11 ready (after 77.12s)
[orchestrator] 09:17:44 SUCCESS Step 12 | Time: 78.34s | Reward: 0.0020 | Throughput: 894.4 tokens/s | Seq. Length: 1092.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 2
[orchestrator] 09:17:44    INFO Starting orchestrator step 13
[orchestrator] 09:17:45    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 12 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:17:47.693
	[default0]:09:17:47 SUCCESS Step 11 | Time: 4.05s | Loss: -0.0001 | Entropy: 0.4291 | Mismatch KL: 0.0010 | Grad. Norm: 0.0010 | LR: 1.00e-05 | Throughput: 2945 tokens/s | MFU: 3.3% | Peak Mem.: 43.5 GiB
Feb 15  01:17:48.482
	[orchestrator] 09:17:48    INFO Orchestrator resumed: checkpoint 12 ready (after 3.01s)
Feb 15  01:17:52.414
	[default0]:09:17:52 SUCCESS Step 12 | Time: 4.03s | Loss: 0.0003 | Entropy: 0.4156 | Mismatch KL: 0.0009 | Grad. Norm: 0.0021 | LR: 1.00e-05 | Throughput: 3105 tokens/s | MFU: 3.5% | Peak Mem.: 43.5 GiB
Feb 15  01:18:21.496
	[orchestrator] 09:18:19 SUCCESS Step 13 | Time: 34.71s | Reward: 0.0263 | Throughput: 2032.3 tokens/s | Seq. Length: 1096.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 4
[orchestrator] 09:18:19    INFO Starting orchestrator step 14
Feb 15  01:18:24.155
	[default0]:09:18:24 SUCCESS Step 13 | Time: 30.93s | Loss: 0.0001 | Entropy: 0.4134 | Mismatch KL: 0.0010 | Grad. Norm: 0.0043 | LR: 1.00e-05 | Throughput: 2919 tokens/s | MFU: 3.2% | Peak Mem.: 43.5 GiB
Feb 15  01:18:36.502
	[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:18:35 SUCCESS Step 14 | Time: 16.52s | Reward: 0.0094 | Throughput: 3207.3 tokens/s | Seq. Length: 822.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 5
[orchestrator] 09:18:35    INFO Starting orchestrator step 15
Feb 15  01:18:38.931
	[default0]:09:18:38 SUCCESS Step 14 | Time: 14.01s | Loss: 0.0002 | Entropy: 0.4260 | Mismatch KL: 0.0010 | Grad. Norm: 0.0040 | LR: 1.00e-05 | Throughput: 2873 tokens/s | MFU: 3.2% | Peak Mem.: 43.5 GiB
Feb 15  01:18:54.510
	[orchestrator] 09:18:53 SUCCESS Step 15 | Time: 17.39s | Reward: 0.0042 | Throughput: 4080.4 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 6
[orchestrator] 09:18:53    INFO Starting orchestrator step 16
Feb 15  01:18:57.723
	[default0]:09:18:57 SUCCESS Step 15 | Time: 17.86s | Loss: -0.0001 | Entropy: 0.4121 | Mismatch KL: 0.0010 | Grad. Norm: 0.0010 | LR: 1.00e-05 | Throughput: 2850 tokens/s | MFU: 3.2% | Peak Mem.: 43.5 GiB
Feb 15  01:19:12.517
	[orchestrator] 09:19:10 SUCCESS Step 16 | Time: 17.25s | Reward: 0.0113 | Throughput: 4096.0 tokens/s | Seq. Length: 1096.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 7
[orchestrator] 09:19:10    INFO Starting orchestrator step 17
Feb 15  01:19:14.399
	[default0]:09:19:14 SUCCESS Step 16 | Time: 15.85s | Loss: 0.0001 | Entropy: 0.4257 | Mismatch KL: 0.0010 | Grad. Norm: 0.0033 | LR: 1.00e-05 | Throughput: 2861 tokens/s | MFU: 3.2% | Peak Mem.: 43.5 GiB
Feb 15  01:19:45.528
	[orchestrator] 09:19:44 SUCCESS Step 17 | Time: 33.81s | Reward: 0.0173 | Throughput: 2065.2 tokens/s | Seq. Length: 1084.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 8
[orchestrator] 09:19:44    INFO Starting orchestrator step 18
Feb 15  01:19:49.560
	[default0]:09:19:49 SUCCESS Step 17 | Time: 34.32s | Loss: 0.0006 | Entropy: 0.4196 | Mismatch KL: 0.0009 | Grad. Norm: 0.0048 | LR: 1.00e-05 | Throughput: 2742 tokens/s | MFU: 3.0% | Peak Mem.: 44.3 GiB
Feb 15  01:20:03.537
	[orchestrator] 09:20:01 SUCCESS Step 18 | Time: 17.30s | Reward: 0.0000 | Throughput: 4081.2 tokens/s | Seq. Length: 1096.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 9
[orchestrator] 09:20:01    INFO Starting orchestrator step 19
Feb 15  01:20:06.231
	[default0]:09:20:06 SUCCESS Step 18 | Time: 15.81s | Loss: 0.0000 | Entropy: 0.4250 | Mismatch KL: 0.0010 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 2688 tokens/s | MFU: 3.0% | Peak Mem.: 44.3 GiB
Feb 15  01:20:09.540
	[orchestrator] 09:20:08 WARNING Cancelled 1 old rollout requests (will refill naturally). Consider increasing max_off_policy_steps to avoid this.
Feb 15  01:20:21.547
	[orchestrator] 09:20:18 SUCCESS Step 19 | Time: 17.03s | Reward: 0.0020 | Throughput: 4143.2 tokens/s | Seq. Length: 1093.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:20:18    INFO Saving checkpoint at step 20
[orchestrator] 09:20:18    INFO Starting orchestrator step 20
Feb 15  01:20:22.913
	[default0]:09:20:22 SUCCESS Step 19 | Time: 15.82s | Loss: 0.0002 | Entropy: 0.4157 | Mismatch KL: 0.0010 | Grad. Norm: 0.0019 | LR: 1.00e-05 | Throughput: 4434 tokens/s | MFU: 4.9% | Peak Mem.: 44.3 GiB
Feb 15  01:20:23.817
	[default0]:09:20:23    INFO Saving checkpoint at step 20
Feb 15  01:20:39.556
	[orchestrator] 09:20:36    INFO Logging samples to W&B table at step 20
[orchestrator] 09:20:36 SUCCESS Step 20 | Time: 18.15s | Reward: 0.0000 | Throughput: 3888.2 tokens/s | Seq. Length: 1095.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:20:36    INFO Starting orchestrator step 21
Feb 15  01:20:57.564
	[orchestrator] 09:20:55 SUCCESS Step 21 | Time: 18.34s | Reward: 0.0155 | Throughput: 3860.6 tokens/s | Seq. Length: 1096.1 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:20:55    INFO Starting orchestrator step 22
[orchestrator] 09:20:55    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 21 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:21:08.609
	[default0]:09:21:08    INFO Saving weight checkpoint at step 20
Feb 15  01:22:20.582
	[default0]:09:22:20 SUCCESS Step 20 | Time: 4.43s | Loss: 0.0000 | Entropy: 0.4278 | Mismatch KL: 0.0011 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 2600 tokens/s | MFU: 2.9% | Peak Mem.: 44.3 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:22:22.934
	[orchestrator] 09:22:21    INFO Orchestrator resumed: checkpoint 21 ready (after 86.48s)
Feb 15  01:22:25.206
	[default0]:09:22:25 SUCCESS Step 21 | Time: 4.00s | Loss: 0.0005 | Entropy: 0.4054 | Mismatch KL: 0.0009 | Grad. Norm: 0.0032 | LR: 1.00e-05 | Throughput: 2600 tokens/s | MFU: 2.9% | Peak Mem.: 44.3 GiB
Feb 15  01:22:40.943
	[orchestrator] 09:22:39 SUCCESS Step 22 | Time: 104.65s | Reward: 0.0000 | Throughput: 671.6 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 2
[orchestrator] 09:22:39    INFO Starting orchestrator step 23
Feb 15  01:22:43.892
	[default0]:09:22:43 SUCCESS Step 22 | Time: 18.00s | Loss: 0.0000 | Entropy: 0.4235 | Mismatch KL: 0.0011 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 2731 tokens/s | MFU: 3.0% | Peak Mem.: 44.3 GiB
Feb 15  01:22:58.949
	[orchestrator] 09:22:58 SUCCESS Step 23 | Time: 18.31s | Reward: 0.0125 | Throughput: 3856.4 tokens/s | Seq. Length: 1092.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 3
[orchestrator] 09:22:58    INFO Starting orchestrator step 24
Feb 15  01:23:02.577
	[default0]:09:23:02 SUCCESS Step 23 | Time: 18.03s | Loss: 0.0004 | Entropy: 0.4103 | Mismatch KL: 0.0009 | Grad. Norm: 0.0039 | LR: 1.00e-05 | Throughput: 2766 tokens/s | MFU: 3.1% | Peak Mem.: 44.3 GiB
Feb 15  01:23:16.957
	[orchestrator] 09:23:16 SUCCESS Step 24 | Time: 18.02s | Reward: 0.0040 | Throughput: 3906.7 tokens/s | Seq. Length: 1092.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 4
[orchestrator] 09:23:16    INFO Starting orchestrator step 25
Feb 15  01:23:20.253
	[default0]:09:23:20 SUCCESS Step 24 | Time: 17.04s | Loss: 0.0008 | Entropy: 0.4190 | Mismatch KL: 0.0010 | Grad. Norm: 0.0038 | LR: 1.00e-05 | Throughput: 2777 tokens/s | MFU: 3.1% | Peak Mem.: 44.3 GiB
Feb 15  01:23:49.972
	[orchestrator] 09:23:49 SUCCESS Step 25 | Time: 33.84s | Reward: 0.0069 | Throughput: 2081.1 tokens/s | Seq. Length: 1095.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 5
[orchestrator] 09:23:49    INFO Starting orchestrator step 26
Feb 15  01:23:54.005
	[default0]:09:23:53 SUCCESS Step 25 | Time: 33.10s | Loss: 0.0002 | Entropy: 0.4221 | Mismatch KL: 0.0010 | Grad. Norm: 0.0023 | LR: 1.00e-05 | Throughput: 2608 tokens/s | MFU: 2.9% | Peak Mem.: 44.3 GiB
Feb 15  01:24:10.982
	[orchestrator] 09:24:08 SUCCESS Step 26 | Time: 18.61s | Reward: 0.0059 | Throughput: 3780.0 tokens/s | Seq. Length: 1092.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 6
[orchestrator] 09:24:08    INFO Starting orchestrator step 27
Feb 15  01:24:13.190
	[default0]:09:24:13 SUCCESS Step 26 | Time: 18.46s | Loss: -0.0000 | Entropy: 0.4042 | Mismatch KL: 0.0009 | Grad. Norm: 0.0011 | LR: 1.00e-05 | Throughput: 2770 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  01:24:28.989
	[orchestrator] 09:24:26 SUCCESS Step 27 | Time: 18.35s | Reward: 0.0032 | Throughput: 3822.8 tokens/s | Seq. Length: 1087.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 7
[orchestrator] 09:24:26    INFO Starting orchestrator step 28
Feb 15  01:24:31.080
	[default0]:09:24:31 SUCCESS Step 27 | Time: 17.19s | Loss: -0.0002 | Entropy: 0.4221 | Mismatch KL: 0.0009 | Grad. Norm: 0.0008 | LR: 1.00e-05 | Throughput: 2799 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  01:25:02.003
	[orchestrator] 09:25:01 SUCCESS Step 28 | Time: 34.24s | Reward: 0.0066 | Throughput: 2053.5 tokens/s | Seq. Length: 1094.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 8
[orchestrator] 09:25:01    INFO Starting orchestrator step 29
Feb 15  01:25:05.849
	[default0]:09:25:05 SUCCESS Step 28 | Time: 34.14s | Loss: 0.0006 | Entropy: 0.4212 | Mismatch KL: 0.0010 | Grad. Norm: 0.0032 | LR: 1.00e-05 | Throughput: 2620 tokens/s | MFU: 2.9% | Peak Mem.: 44.7 GiB
Feb 15  01:25:23.010
	[orchestrator] 09:25:20 SUCCESS Step 29 | Time: 19.01s | Reward: 0.0019 | Throughput: 3698.2 tokens/s | Seq. Length: 1089.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 9
[orchestrator] 09:25:20    INFO Saving checkpoint at step 30
[orchestrator] 09:25:20    INFO Starting orchestrator step 30
Feb 15  01:25:25.238
	[default0]:09:25:25 SUCCESS Step 29 | Time: 18.68s | Loss: -0.0001 | Entropy: 0.4215 | Mismatch KL: 0.0009 | Grad. Norm: 0.0007 | LR: 1.00e-05 | Throughput: 4095 tokens/s | MFU: 4.6% | Peak Mem.: 44.7 GiB
Feb 15  01:25:25.942
	[default0]:09:25:25    INFO Saving checkpoint at step 30
Feb 15  01:25:29.013
	[orchestrator] 09:25:26 WARNING Cancelled 1 old rollout requests (will refill naturally). Consider increasing max_off_policy_steps to avoid this.
Feb 15  01:25:42.380
	[orchestrator] 09:25:39    INFO Logging samples to W&B table at step 30
[orchestrator] 09:25:39 SUCCESS Step 30 | Time: 19.63s | Reward: 0.0000 | Throughput: 3596.5 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:25:39    INFO Starting orchestrator step 31
Feb 15  01:26:00.451
	[orchestrator] 09:25:58 SUCCESS Step 31 | Time: 19.04s | Reward: 0.0161 | Throughput: 3678.4 tokens/s | Seq. Length: 1084.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:25:58    INFO Starting orchestrator step 32
[orchestrator] 09:25:59    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 31 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:26:08.943
	[default0]:09:26:08    INFO Saving weight checkpoint at step 30
Feb 15  01:27:20.706
	[default0]:09:27:20 SUCCESS Step 30 | Time: 4.10s | Loss: 0.0000 | Entropy: 0.4147 | Mismatch KL: 0.0009 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 2559 tokens/s | MFU: 2.8% | Peak Mem.: 44.7 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:27:24.492
	[orchestrator] 09:27:21    INFO Orchestrator resumed: checkpoint 31 ready (after 82.09s)
[orchestrator] 09:27:21 SUCCESS Step 32 | Time: 82.91s | Reward: 0.0020 | Throughput: 846.2 tokens/s | Seq. Length: 1094.6 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:27:21    INFO Starting orchestrator step 33
[orchestrator] 09:27:22    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 32 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:27:25.727
	[default0]:09:27:25 SUCCESS Step 31 | Time: 4.32s | Loss: 0.0025 | Entropy: 0.4059 | Mismatch KL: 0.0009 | Grad. Norm: 0.0098 | LR: 1.00e-05 | Throughput: 2732 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  01:27:27.494
	[orchestrator] 09:27:26    INFO Orchestrator resumed: checkpoint 32 ready (after 4.01s)
Feb 15  01:27:30.448
	[default0]:09:27:30 SUCCESS Step 32 | Time: 4.01s | Loss: 0.0002 | Entropy: 0.4302 | Mismatch KL: 0.0010 | Grad. Norm: 0.0019 | LR: 1.00e-05 | Throughput: 2874 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  01:27:42.500
	[orchestrator] 09:27:42 SUCCESS Step 33 | Time: 20.40s | Reward: 0.0116 | Throughput: 3455.7 tokens/s | Seq. Length: 1093.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:27:42    INFO Starting orchestrator step 34
Feb 15  01:27:46.224
	[default0]:09:27:46 SUCCESS Step 33 | Time: 15.05s | Loss: 0.0010 | Entropy: 0.4315 | Mismatch KL: 0.0010 | Grad. Norm: 0.0077 | LR: 1.00e-05 | Throughput: 2895 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  01:28:03.510
	[orchestrator] 09:28:03 SUCCESS Step 34 | Time: 20.70s | Reward: 0.0048 | Throughput: 3405.2 tokens/s | Seq. Length: 1095.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:28:03    INFO Starting orchestrator step 35
Feb 15  01:28:06.923
	[default0]:09:28:06 SUCCESS Step 34 | Time: 20.05s | Loss: 0.0000 | Entropy: 0.4152 | Mismatch KL: 0.0010 | Grad. Norm: 0.0026 | LR: 1.00e-05 | Throughput: 3044 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  01:28:24.520
	[orchestrator] 09:28:23 SUCCESS Step 35 | Time: 20.70s | Reward: 0.0000 | Throughput: 3415.2 tokens/s | Seq. Length: 1096.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:28:23    INFO Starting orchestrator step 36
Feb 15  01:28:27.614
	[default0]:09:28:27 SUCCESS Step 35 | Time: 20.01s | Loss: 0.0000 | Entropy: 0.4132 | Mismatch KL: 0.0010 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 2950 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  01:28:45.530
	[orchestrator] 09:28:44 SUCCESS Step 36 | Time: 20.34s | Reward: 0.0211 | Throughput: 3468.4 tokens/s | Seq. Length: 1095.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:28:44    INFO Starting orchestrator step 37
Feb 15  01:28:48.325
	[default0]:09:28:48 SUCCESS Step 36 | Time: 20.05s | Loss: 0.0009 | Entropy: 0.4216 | Mismatch KL: 0.0010 | Grad. Norm: 0.0070 | LR: 1.00e-05 | Throughput: 2875 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  01:29:03.537
	[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 09:29:03 SUCCESS Step 37 | Time: 19.38s | Reward: 0.0375 | Throughput: 2732.3 tokens/s | Seq. Length: 822.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 09:29:03    INFO Starting orchestrator step 38
Feb 15  01:29:07.121
	[default0]:09:29:07 SUCCESS Step 37 | Time: 18.17s | Loss: -0.0048 | Entropy: 0.4183 | Mismatch KL: 0.0009 | Grad. Norm: 0.0148 | LR: 1.00e-05 | Throughput: 2983 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  01:29:42.915
	[orchestrator] 09:29:41 SUCCESS Step 38 | Time: 38.53s | Reward: 0.0094 | Throughput: 1820.8 tokens/s | Seq. Length: 1093.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 2
[orchestrator] 09:29:41    INFO Starting orchestrator step 39
Feb 15  01:29:45.898
	[default0]:09:29:45 SUCCESS Step 38 | Time: 38.04s | Loss: 0.0010 | Entropy: 0.4202 | Mismatch KL: 0.0010 | Grad. Norm: 0.0069 | LR: 1.00e-05 | Throughput: 2704 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  01:30:03.924
	[orchestrator] 09:30:01 SUCCESS Step 39 | Time: 19.64s | Reward: 0.0232 | Throughput: 3573.1 tokens/s | Seq. Length: 1089.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 3
[orchestrator] 09:30:01    INFO Saving checkpoint at step 40
[orchestrator] 09:30:01    INFO Starting orchestrator step 40
Feb 15  01:30:05.696
	[default0]:09:30:05 SUCCESS Step 39 | Time: 19.14s | Loss: 0.0008 | Entropy: 0.4067 | Mismatch KL: 0.0009 | Grad. Norm: 0.0046 | LR: 1.00e-05 | Throughput: 4272 tokens/s | MFU: 4.7% | Peak Mem.: 44.7 GiB
Feb 15  01:30:06.400
	[default0]:09:30:06    INFO Saving checkpoint at step 40
Feb 15  01:30:22.253
	[orchestrator] 09:30:21    INFO Logging samples to W&B table at step 40
[orchestrator] 09:30:21 SUCCESS Step 40 | Time: 19.49s | Reward: 0.0042 | Throughput: 3616.4 tokens/s | Seq. Length: 1095.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 4
[orchestrator] 09:30:21    INFO Starting orchestrator step 41
Feb 15  01:30:55.745
	[default0]:09:30:55    INFO Saving weight checkpoint at step 40
Feb 15  01:30:56.170
	[orchestrator] 09:30:55 SUCCESS Step 41 | Time: 34.49s | Reward: 0.0062 | Throughput: 2043.9 tokens/s | Seq. Length: 1094.4 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 4
[orchestrator] 09:30:55    INFO Starting orchestrator step 42
Feb 15  01:30:59.169
	[orchestrator] 09:30:56    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 41 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:32:05.343
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:09:32:05 SUCCESS Step 40 | Time: 4.49s | Loss: 0.0004 | Entropy: 0.4256 | Mismatch KL: 0.0010 | Grad. Norm: 0.0030 | LR: 1.00e-05 | Throughput: 2471 tokens/s | MFU: 2.7% | Peak Mem.: 44.7 GiB
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:32:08.199
	[orchestrator] 09:32:06    INFO Orchestrator resumed: checkpoint 41 ready (after 70.08s)
[orchestrator] 09:32:06 SUCCESS Step 42 | Time: 70.93s | Reward: 0.0134 | Throughput: 989.4 tokens/s | Seq. Length: 1094.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 5
[orchestrator] 09:32:06    INFO Starting orchestrator step 43
[orchestrator] 09:32:07    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 42 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:32:10.067
	[default0]:09:32:10 SUCCESS Step 41 | Time: 4.01s | Loss: 0.0010 | Entropy: 0.4040 | Mismatch KL: 0.0010 | Grad. Norm: 0.0038 | LR: 1.00e-05 | Throughput: 2472 tokens/s | MFU: 2.7% | Peak Mem.: 44.7 GiB
Feb 15  01:32:14.203
	[orchestrator] 09:32:11    INFO Orchestrator resumed: checkpoint 42 ready (after 4.01s)
Feb 15  01:32:15.291
	[default0]:09:32:15 SUCCESS Step 42 | Time: 4.48s | Loss: 0.0012 | Entropy: 0.4139 | Mismatch KL: 0.0010 | Grad. Norm: 0.0066 | LR: 1.00e-05 | Throughput: 2569 tokens/s | MFU: 2.9% | Peak Mem.: 44.7 GiB
Feb 15  01:32:23.207
	[orchestrator] 09:32:23 SUCCESS Step 43 | Time: 16.42s | Reward: 0.0020 | Throughput: 4309.0 tokens/s | Seq. Length: 1096.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 7
[orchestrator] 09:32:23    INFO Starting orchestrator step 44
Feb 15  01:32:27.958
	[default0]:09:32:27 SUCCESS Step 43 | Time: 11.63s | Loss: -0.0000 | Entropy: 0.4073 | Mismatch KL: 0.0010 | Grad. Norm: 0.0007 | LR: 1.00e-05 | Throughput: 2647 tokens/s | MFU: 2.9% | Peak Mem.: 44.7 GiB
Feb 15  01:32:56.220
	[orchestrator] 09:32:54 SUCCESS Step 44 | Time: 31.87s | Reward: 0.0000 | Throughput: 2211.8 tokens/s | Seq. Length: 1096.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 8
[orchestrator] 09:32:54    INFO Starting orchestrator step 45
Feb 15  01:32:59.709
	[default0]:09:32:59 SUCCESS Step 44 | Time: 30.97s | Loss: 0.0000 | Entropy: 0.3981 | Mismatch KL: 0.0009 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 2540 tokens/s | MFU: 2.8% | Peak Mem.: 44.7 GiB
Feb 15  01:33:14.228
	[orchestrator] 09:33:11 SUCCESS Step 45 | Time: 16.79s | Reward: 0.0844 | Throughput: 4238.2 tokens/s | Seq. Length: 1104.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 9
[orchestrator] 09:33:11    INFO Starting orchestrator step 46
Feb 15  01:33:16.489
	[default0]:09:33:16 SUCCESS Step 45 | Time: 16.11s | Loss: 0.0019 | Entropy: 0.3856 | Mismatch KL: 0.0009 | Grad. Norm: 0.0253 | LR: 1.00e-05 | Throughput: 2590 tokens/s | MFU: 2.9% | Peak Mem.: 44.7 GiB
Feb 15  01:33:20.230
	[orchestrator] 09:33:18 WARNING Cancelled 1 old rollout requests (will refill naturally). Consider increasing max_off_policy_steps to avoid this.
Feb 15  01:33:29.233
	[orchestrator] 09:33:27 SUCCESS Step 46 | Time: 16.18s | Reward: 0.0023 | Throughput: 4371.7 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:33:27    INFO Starting orchestrator step 47
Feb 15  01:33:32.563
	[default0]:09:33:32 SUCCESS Step 46 | Time: 15.08s | Loss: 0.0000 | Entropy: 0.4098 | Mismatch KL: 0.0010 | Grad. Norm: 0.0008 | LR: 1.00e-05 | Throughput: 2695 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  01:33:47.526
	[orchestrator] 09:33:44 SUCCESS Step 47 | Time: 16.61s | Reward: 0.0197 | Throughput: 4237.2 tokens/s | Seq. Length: 1091.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:33:44    INFO Starting orchestrator step 48
Feb 15  01:33:48.631
	[default0]:09:33:48 SUCCESS Step 47 | Time: 14.50s | Loss: 0.0005 | Entropy: 0.4176 | Mismatch KL: 0.0010 | Grad. Norm: 0.0046 | LR: 1.00e-05 | Throughput: 2942 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  01:34:02.532
	[orchestrator] 09:34:01 SUCCESS Step 48 | Time: 16.58s | Reward: 0.0431 | Throughput: 4195.8 tokens/s | Seq. Length: 1080.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:34:01    INFO Starting orchestrator step 49
Feb 15  01:34:05.402
	[default0]:09:34:05 SUCCESS Step 48 | Time: 16.05s | Loss: -0.0026 | Entropy: 0.4192 | Mismatch KL: 0.0010 | Grad. Norm: 0.0072 | LR: 1.00e-05 | Throughput: 2994 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  01:34:20.541
	[orchestrator] 09:34:18 SUCCESS Step 49 | Time: 17.04s | Reward: 0.0375 | Throughput: 4140.6 tokens/s | Seq. Length: 1095.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:34:18    INFO Saving checkpoint at step 50
[orchestrator] 09:34:18    INFO Starting orchestrator step 50
Feb 15  01:34:22.086
	[default0]:09:34:21 SUCCESS Step 49 | Time: 15.94s | Loss: 0.0054 | Entropy: 0.4142 | Mismatch KL: 0.0010 | Grad. Norm: 0.0367 | LR: 1.00e-05 | Throughput: 5251 tokens/s | MFU: 5.8% | Peak Mem.: 44.7 GiB
Feb 15  01:34:22.789
	[default0]:09:34:22    INFO Saving checkpoint at step 50
Feb 15  01:34:35.547
	[orchestrator] 09:34:34    INFO Logging samples to W&B table at step 50
[orchestrator] 09:34:34 SUCCESS Step 50 | Time: 16.68s | Reward: 0.0299 | Throughput: 4188.3 tokens/s | Seq. Length: 1084.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:34:34    INFO Starting orchestrator step 51
Feb 15  01:34:53.559
	[orchestrator] 09:34:51 SUCCESS Step 51 | Time: 16.54s | Reward: 0.0355 | Throughput: 4160.5 tokens/s | Seq. Length: 1067.4 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:34:51    INFO Starting orchestrator step 52
[orchestrator] 09:34:51    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 51 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:35:05.383
	[default0]:09:35:05    INFO Saving weight checkpoint at step 50
Feb 15  01:36:13.472
	[default0]:09:36:13 SUCCESS Step 50 | Time: 4.67s | Loss: 0.0002 | Entropy: 0.4127 | Mismatch KL: 0.0011 | Grad. Norm: 0.0109 | LR: 1.00e-05 | Throughput: 2994 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  01:36:13.496
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:36:17.597
	[orchestrator] 09:36:14    INFO Orchestrator resumed: checkpoint 51 ready (after 83.16s)
[orchestrator] 09:36:15 SUCCESS Step 52 | Time: 83.71s | Reward: 0.0159 | Throughput: 806.5 tokens/s | Seq. Length: 1053.5 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:36:15    INFO Starting orchestrator step 53
[orchestrator] 09:36:16    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 52 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:36:18.604
	[default0]:09:36:18 SUCCESS Step 51 | Time: 4.36s | Loss: -0.0022 | Entropy: 0.4038 | Mismatch KL: 0.0011 | Grad. Norm: 0.0058 | LR: 1.00e-05 | Throughput: 3061 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  01:36:20.598
	[orchestrator] 09:36:20    INFO Orchestrator resumed: checkpoint 52 ready (after 4.01s)
Feb 15  01:36:23.729
	[default0]:09:36:23 SUCCESS Step 52 | Time: 4.42s | Loss: -0.0003 | Entropy: 0.3921 | Mismatch KL: 0.0015 | Grad. Norm: 0.0027 | LR: 1.00e-05 | Throughput: 3233 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  01:36:35.607
	[orchestrator] 09:36:32 SUCCESS Step 53 | Time: 17.38s | Reward: 0.1350 | Throughput: 3918.7 tokens/s | Seq. Length: 1057.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:36:32    INFO Starting orchestrator step 54
Feb 15  01:36:37.995
	[default0]:09:36:37 SUCCESS Step 53 | Time: 13.61s | Loss: -0.0029 | Entropy: 0.3940 | Mismatch KL: 0.0009 | Grad. Norm: 0.0175 | LR: 1.00e-05 | Throughput: 3570 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:36:50.615
	[orchestrator] 09:36:49 SUCCESS Step 54 | Time: 17.02s | Reward: 0.0285 | Throughput: 3895.4 tokens/s | Seq. Length: 1029.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:36:49    INFO Starting orchestrator step 55
Feb 15  01:36:54.170
	[default0]:09:36:54 SUCCESS Step 54 | Time: 15.50s | Loss: -0.0003 | Entropy: 0.3366 | Mismatch KL: 0.0008 | Grad. Norm: 0.0037 | LR: 1.00e-05 | Throughput: 3639 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:37:08.623
	[orchestrator] 09:37:06 SUCCESS Step 55 | Time: 16.83s | Reward: 0.0580 | Throughput: 3968.3 tokens/s | Seq. Length: 1036.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:37:06    INFO Starting orchestrator step 56
Feb 15  01:37:11.349
	[default0]:09:37:11 SUCCESS Step 55 | Time: 16.50s | Loss: -0.0021 | Entropy: 0.3611 | Mismatch KL: 0.0008 | Grad. Norm: 0.0071 | LR: 1.00e-05 | Throughput: 3691 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:37:23.630
	[orchestrator] 09:37:23 SUCCESS Step 56 | Time: 17.09s | Reward: 0.0902 | Throughput: 3749.7 tokens/s | Seq. Length: 995.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:37:23    INFO Starting orchestrator step 57
Feb 15  01:37:27.932
	[default0]:09:37:27 SUCCESS Step 56 | Time: 15.96s | Loss: -0.0018 | Entropy: 0.3602 | Mismatch KL: 0.0010 | Grad. Norm: 0.0152 | LR: 1.00e-05 | Throughput: 3659 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:37:41.638
	[orchestrator] 09:37:40 SUCCESS Step 57 | Time: 16.86s | Reward: 0.0805 | Throughput: 4028.2 tokens/s | Seq. Length: 1054.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:37:40    INFO Starting orchestrator step 58
Feb 15  01:37:45.511
	[default0]:09:37:45 SUCCESS Step 57 | Time: 16.88s | Loss: 0.0002 | Entropy: 0.3665 | Mismatch KL: 0.0008 | Grad. Norm: 0.0167 | LR: 1.00e-05 | Throughput: 3717 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:38:00.035
	[orchestrator] 09:37:58 SUCCESS Step 58 | Time: 17.61s | Reward: 0.0762 | Throughput: 3858.3 tokens/s | Seq. Length: 1055.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:37:58    INFO Starting orchestrator step 59
Feb 15  01:38:02.990
	[default0]:09:38:02 SUCCESS Step 58 | Time: 16.83s | Loss: -0.0003 | Entropy: 0.3396 | Mismatch KL: 0.0007 | Grad. Norm: 0.0134 | LR: 1.00e-05 | Throughput: 3773 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:38:18.047
	[orchestrator] 09:38:15 SUCCESS Step 59 | Time: 17.48s | Reward: 0.0863 | Throughput: 3907.5 tokens/s | Seq. Length: 1060.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:38:15    INFO Saving checkpoint at step 60
[orchestrator] 09:38:15    INFO Starting orchestrator step 60
Feb 15  01:38:20.273
	[default0]:09:38:20 SUCCESS Step 59 | Time: 16.59s | Loss: -0.0027 | Entropy: 0.3378 | Mismatch KL: 0.0008 | Grad. Norm: 0.0105 | LR: 1.00e-05 | Throughput: 6636 tokens/s | MFU: 7.4% | Peak Mem.: 44.7 GiB
Feb 15  01:38:21.280
	[default0]:09:38:21    INFO Saving checkpoint at step 60
Feb 15  01:38:33.051
	[orchestrator] 09:38:32    INFO Logging samples to W&B table at step 60
[orchestrator] 09:38:32 SUCCESS Step 60 | Time: 17.01s | Reward: 0.0777 | Throughput: 3987.2 tokens/s | Seq. Length: 1053.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:38:32    INFO Starting orchestrator step 61
Feb 15  01:38:51.061
	[orchestrator] 09:38:49 SUCCESS Step 61 | Time: 16.59s | Reward: 0.1962 | Throughput: 4021.0 tokens/s | Seq. Length: 1035.3 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:38:49    INFO Starting orchestrator step 62
[orchestrator] 09:38:50    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 61 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:39:05.299
	[default0]:09:39:05    INFO Saving weight checkpoint at step 60
Feb 15  01:40:14.456
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:40:14.501
	[default0]:09:40:14 SUCCESS Step 60 | Time: 4.84s | Loss: -0.0025 | Entropy: 0.3380 | Mismatch KL: 0.0007 | Grad. Norm: 0.0100 | LR: 1.00e-05 | Throughput: 3579 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:40:18.105
	[orchestrator] 09:40:15    INFO Orchestrator resumed: checkpoint 61 ready (after 85.14s)
[orchestrator] 09:40:15 SUCCESS Step 62 | Time: 86.27s | Reward: 0.1314 | Throughput: 767.6 tokens/s | Seq. Length: 1033.5 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:40:15    INFO Starting orchestrator step 63
[orchestrator] 09:40:16    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 62 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:40:19.622
	[default0]:09:40:19 SUCCESS Step 61 | Time: 4.44s | Loss: -0.0012 | Entropy: 0.3547 | Mismatch KL: 0.0008 | Grad. Norm: 0.0240 | LR: 1.00e-05 | Throughput: 3583 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:40:21.107
	[orchestrator] 09:40:20    INFO Orchestrator resumed: checkpoint 62 ready (after 4.01s)
Feb 15  01:40:24.741
	[default0]:09:40:24 SUCCESS Step 62 | Time: 4.52s | Loss: -0.0012 | Entropy: 0.3590 | Mismatch KL: 0.0009 | Grad. Norm: 0.0189 | LR: 1.00e-05 | Throughput: 3734 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:40:33.114
	[orchestrator] 09:40:32 SUCCESS Step 63 | Time: 17.17s | Reward: 0.1923 | Throughput: 3941.0 tokens/s | Seq. Length: 1050.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:40:32    INFO Starting orchestrator step 64
Feb 15  01:40:37.898
	[default0]:09:40:37 SUCCESS Step 63 | Time: 12.48s | Loss: -0.0046 | Entropy: 0.3641 | Mismatch KL: 0.0008 | Grad. Norm: 0.0182 | LR: 1.00e-05 | Throughput: 3791 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:40:51.122
	[orchestrator] 09:40:49 SUCCESS Step 64 | Time: 16.58s | Reward: 0.2009 | Throughput: 3904.1 tokens/s | Seq. Length: 1004.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:40:49    INFO Starting orchestrator step 65
Feb 15  01:40:54.074
	[default0]:09:40:53 SUCCESS Step 64 | Time: 15.46s | Loss: -0.0051 | Entropy: 0.3469 | Mismatch KL: 0.0007 | Grad. Norm: 0.0316 | LR: 1.00e-05 | Throughput: 3819 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:40:54.130
	[rank_0] [32mStep 64 | Time: 15.46s | Loss: -0.0051 | Entropy: 0.3469 | Mismatch KL: 0.0007 | Grad. Norm: 0.0316 | LR: 1.00e-05 | Throughput: 3819 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:41:09.136
	[orchestrator] 09:41:06 SUCCESS Step 65 | Time: 16.85s | Reward: 0.1492 | Throughput: 4068.6 tokens/s | Seq. Length: 1064.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:41:06    INFO Starting orchestrator step 66
Feb 15  01:41:11.246
	[default0]:09:41:11 SUCCESS Step 65 | Time: 16.49s | Loss: -0.0019 | Entropy: 0.3597 | Mismatch KL: 0.0008 | Grad. Norm: 0.0174 | LR: 1.00e-05 | Throughput: 3923 tokens/s | MFU: 4.4% | Peak Mem.: 44.7 GiB
Feb 15  01:41:12.139
	[rank_0] 09:41:11 SUCCESS Step 65 | Time: 16.49s | Loss: -0.0019 | Entropy: 0.3597 | Mismatch KL: 0.0008 | Grad. Norm: 0.0174 | LR: 1.00e-05 | Throughput: 3923 tokens/s | MFU: 4.4% | Peak Mem.: 44.7 GiB
Feb 15  01:41:24.145
	[orchestrator] 09:41:23 SUCCESS Step 66 | Time: 17.07s | Reward: 0.1271 | Throughput: 3808.7 tokens/s | Seq. Length: 1010.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:41:23    INFO Starting orchestrator step 67
Feb 15  01:41:28.434
	[default0]:09:41:28 SUCCESS Step 66 | Time: 16.54s | Loss: 0.0002 | Entropy: 0.3436 | Mismatch KL: 0.0008 | Grad. Norm: 0.0183 | LR: 1.00e-05 | Throughput: 3930 tokens/s | MFU: 4.4% | Peak Mem.: 44.7 GiB
Feb 15  01:41:30.148
	[rank_0] 09:41:28 SUCCESS Step 66 | Time: 16.54s | Loss: 0.0002 | Entropy: 0.3436 | Mismatch KL: 0.0008 | Grad. Norm: 0.0183 | LR: 1.00e-05 | Throughput: 3930 tokens/s | MFU: 4.4% | Peak Mem.: 44.7 GiB
Feb 15  01:41:42.153
	[orchestrator] 09:41:40 SUCCESS Step 67 | Time: 17.34s | Reward: 0.2073 | Throughput: 3910.2 tokens/s | Seq. Length: 1052.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:41:40    INFO Starting orchestrator step 68
Feb 15  01:41:45.511
	[default0]:09:41:45 SUCCESS Step 67 | Time: 16.46s | Loss: 0.0031 | Entropy: 0.3587 | Mismatch KL: 0.0008 | Grad. Norm: 0.0271 | LR: 1.00e-05 | Throughput: 3949 tokens/s | MFU: 4.4% | Peak Mem.: 44.7 GiB
Feb 15  01:41:48.156
	[rank_0] 09:41:45 SUCCESS Step 67 | Time: 16.46s | Loss: 0.0031 | Entropy: 0.3587 | Mismatch KL: 0.0008 | Grad. Norm: 0.0271 | LR: 1.00e-05 | Throughput: 3949 tokens/s | MFU: 4.4% | Peak Mem.: 44.7 GiB
Feb 15  01:42:00.162
	[orchestrator] 09:41:57 SUCCESS Step 68 | Time: 16.57s | Reward: 0.1693 | Throughput: 4018.1 tokens/s | Seq. Length: 1033.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:41:57    INFO Starting orchestrator step 69
Feb 15  01:42:01.983
	[default0]:09:42:01 SUCCESS Step 68 | Time: 15.78s | Loss: -0.0039 | Entropy: 0.3576 | Mismatch KL: 0.0010 | Grad. Norm: 0.0219 | LR: 1.00e-05 | Throughput: 3939 tokens/s | MFU: 4.4% | Peak Mem.: 44.7 GiB
Feb 15  01:42:03.163
	[rank_0] 09:42:01 SUCCESS Step 68 | Time: 15.78s | Loss: -0.0039 | Entropy: 0.3576 | Mismatch KL: 0.0010 | Grad. Norm: 0.0219 | LR: 1.00e-05 | Throughput: 3939 tokens/s | MFU: 4.4% | Peak Mem.: 44.7 GiB
Feb 15  01:42:15.170
	[orchestrator] 09:42:13 SUCCESS Step 69 | Time: 16.60s | Reward: 0.2484 | Throughput: 4018.4 tokens/s | Seq. Length: 1035.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:42:13    INFO Saving checkpoint at step 70
[orchestrator] 09:42:13    INFO Starting orchestrator step 70
Feb 15  01:42:18.059
	[default0]:09:42:18 SUCCESS Step 69 | Time: 15.44s | Loss: -0.0074 | Entropy: 0.3351 | Mismatch KL: 0.0009 | Grad. Norm: 0.0270 | LR: 1.00e-05 | Throughput: 7042 tokens/s | MFU: 7.8% | Peak Mem.: 44.7 GiB
Feb 15  01:42:18.170
	[rank_0] 09:42:18 SUCCESS Step 69 | Time: 15.44s | Loss: -0.0074 | Entropy: 0.3351 | Mismatch KL: 0.0009 | Grad. Norm: 0.0270 | LR: 1.00e-05 | Throughput: 7042 tokens/s | MFU: 7.8% | Peak Mem.: 44.7 GiB
Feb 15  01:42:18.763
	[default0]:09:42:18    INFO Saving checkpoint at step 70
Feb 15  01:42:21.172
	[rank_0] 09:42:18    INFO Saving checkpoint at step 70
Feb 15  01:42:33.179
	[orchestrator] 09:42:30    INFO Logging samples to W&B table at step 70
[orchestrator] 09:42:30 SUCCESS Step 70 | Time: 16.68s | Reward: 0.2421 | Throughput: 4051.4 tokens/s | Seq. Length: 1048.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:42:30    INFO Starting orchestrator step 71
Feb 15  01:42:48.215
	[orchestrator] 09:42:47 SUCCESS Step 71 | Time: 16.85s | Reward: 0.2246 | Throughput: 4068.2 tokens/s | Seq. Length: 1063.8 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:42:47    INFO Starting orchestrator step 72
[orchestrator] 09:42:47    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 71 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:43:24.742
	[default0]:09:43:24    INFO Saving weight checkpoint at step 70
Feb 15  01:43:27.238
	[rank_0] 09:43:24    INFO Saving weight checkpoint at step 70
Feb 15  01:44:33.270
	[rank_0] 09:44:33 SUCCESS Step 70 | Time: 4.51s | Loss: -0.0030 | Entropy: 0.3323 | Mismatch KL: 0.0008 | Grad. Norm: 0.0269 | LR: 1.00e-05 | Throughput: 3431 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:44:33.326
	[default0]:09:44:33 SUCCESS Step 70 | Time: 4.51s | Loss: -0.0030 | Entropy: 0.3323 | Mismatch KL: 0.0008 | Grad. Norm: 0.0269 | LR: 1.00e-05 | Throughput: 3431 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  01:44:36.272
	[orchestrator] 09:44:34    INFO Orchestrator resumed: checkpoint 71 ready (after 107.15s)
[orchestrator] 09:44:35 SUCCESS Step 72 | Time: 107.68s | Reward: 0.1789 | Throughput: 617.3 tokens/s | Seq. Length: 1037.5 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:44:35    INFO Starting orchestrator step 73
[orchestrator] 09:44:35    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 72 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:44:38.549
	[default0]:09:44:38 SUCCESS Step 71 | Time: 4.51s | Loss: -0.0020 | Entropy: 0.3505 | Mismatch KL: 0.0008 | Grad. Norm: 0.0267 | LR: 1.00e-05 | Throughput: 3426 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  01:44:39.274
	[rank_0] 09:44:38 SUCCESS Step 71 | Time: 4.51s | Loss: -0.0020 | Entropy: 0.3505 | Mismatch KL: 0.0008 | Grad. Norm: 0.0267 | LR: 1.00e-05 | Throughput: 3426 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  01:44:42.276
	[orchestrator] 09:44:39    INFO Orchestrator resumed: checkpoint 72 ready (after 4.01s)
Feb 15  01:44:43.672
	[default0]:09:44:43 SUCCESS Step 72 | Time: 4.47s | Loss: -0.0043 | Entropy: 0.3281 | Mismatch KL: 0.0008 | Grad. Norm: 0.0232 | LR: 1.00e-05 | Throughput: 3545 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  01:44:45.277
	[rank_0] 09:44:43 SUCCESS Step 72 | Time: 4.47s | Loss: -0.0043 | Entropy: 0.3281 | Mismatch KL: 0.0008 | Grad. Norm: 0.0232 | LR: 1.00e-05 | Throughput: 3545 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  01:44:54.280
	[orchestrator] 09:44:51 SUCCESS Step 73 | Time: 16.89s | Reward: 0.4264 | Throughput: 4093.0 tokens/s | Seq. Length: 1072.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:44:51    INFO Starting orchestrator step 74
Feb 15  01:44:56.735
	[default0]:09:44:56 SUCCESS Step 73 | Time: 12.45s | Loss: 0.0077 | Entropy: 0.2997 | Mismatch KL: 0.0007 | Grad. Norm: 0.0854 | LR: 1.00e-05 | Throughput: 3588 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:44:57.283
	[rank_0] 09:44:56 SUCCESS Step 73 | Time: 12.45s | Loss: 0.0077 | Entropy: 0.2997 | Mismatch KL: 0.0007 | Grad. Norm: 0.0854 | LR: 1.00e-05 | Throughput: 3588 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:45:09.289
	[orchestrator] 09:45:09 SUCCESS Step 74 | Time: 17.06s | Reward: 0.4602 | Throughput: 3895.8 tokens/s | Seq. Length: 1031.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:45:09    INFO Starting orchestrator step 75
Feb 15  01:45:13.917
	[default0]:09:45:13 SUCCESS Step 74 | Time: 16.52s | Loss: -0.0092 | Entropy: 0.3309 | Mismatch KL: 0.0008 | Grad. Norm: 0.0363 | LR: 1.00e-05 | Throughput: 3578 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:45:15.292
	[rank_0] 09:45:13 SUCCESS Step 74 | Time: 16.52s | Loss: -0.0092 | Entropy: 0.3309 | Mismatch KL: 0.0008 | Grad. Norm: 0.0363 | LR: 1.00e-05 | Throughput: 3578 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:45:27.296
	[orchestrator] 09:45:26 SUCCESS Step 75 | Time: 17.33s | Reward: 0.4684 | Throughput: 3948.3 tokens/s | Seq. Length: 1062.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:45:26    INFO Starting orchestrator step 76
Feb 15  01:45:31.093
	[default0]:09:45:31 SUCCESS Step 75 | Time: 16.48s | Loss: -0.0061 | Entropy: 0.2790 | Mismatch KL: 0.0007 | Grad. Norm: 0.0341 | LR: 1.00e-05 | Throughput: 3577 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:45:33.298
	[rank_0] 09:45:31 SUCCESS Step 75 | Time: 16.48s | Loss: -0.0061 | Entropy: 0.2790 | Mismatch KL: 0.0007 | Grad. Norm: 0.0341 | LR: 1.00e-05 | Throughput: 3577 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:45:45.305
	[orchestrator] 09:45:43 SUCCESS Step 76 | Time: 16.94s | Reward: 0.5456 | Throughput: 4086.3 tokens/s | Seq. Length: 1074.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:45:43    INFO Starting orchestrator step 77
Feb 15  01:45:48.167
	[default0]:09:45:48 SUCCESS Step 76 | Time: 16.44s | Loss: -0.0136 | Entropy: 0.3289 | Mismatch KL: 0.0008 | Grad. Norm: 0.0540 | LR: 1.00e-05 | Throughput: 3572 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:45:48.305
	[rank_0] 09:45:48 SUCCESS Step 76 | Time: 16.44s | Loss: -0.0136 | Entropy: 0.3289 | Mismatch KL: 0.0008 | Grad. Norm: 0.0540 | LR: 1.00e-05 | Throughput: 3572 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:46:03.312
	[orchestrator] 09:46:00 SUCCESS Step 77 | Time: 17.09s | Reward: 0.5640 | Throughput: 3982.3 tokens/s | Seq. Length: 1056.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:46:00    INFO Starting orchestrator step 78
Feb 15  01:46:05.352
	[default0]:09:46:05 SUCCESS Step 77 | Time: 16.49s | Loss: -0.0079 | Entropy: 0.3124 | Mismatch KL: 0.0007 | Grad. Norm: 0.0377 | LR: 1.00e-05 | Throughput: 3578 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:46:06.314
	[rank_0] 09:46:05 SUCCESS Step 77 | Time: 16.49s | Loss: -0.0079 | Entropy: 0.3124 | Mismatch KL: 0.0007 | Grad. Norm: 0.0377 | LR: 1.00e-05 | Throughput: 3578 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:46:18.319
	[orchestrator] 09:46:17 SUCCESS Step 78 | Time: 16.93s | Reward: 0.4156 | Throughput: 3982.1 tokens/s | Seq. Length: 1046.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:46:17    INFO Starting orchestrator step 79
Feb 15  01:46:22.433
	[default0]:09:46:22 SUCCESS Step 78 | Time: 16.42s | Loss: -0.0010 | Entropy: 0.3056 | Mismatch KL: 0.0008 | Grad. Norm: 0.0339 | LR: 1.00e-05 | Throughput: 3567 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:46:24.321
	[rank_0] 09:46:22 SUCCESS Step 78 | Time: 16.42s | Loss: -0.0010 | Entropy: 0.3056 | Mismatch KL: 0.0008 | Grad. Norm: 0.0339 | LR: 1.00e-05 | Throughput: 3567 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:46:36.326
	[orchestrator] 09:46:34 SUCCESS Step 79 | Time: 16.65s | Reward: 0.7083 | Throughput: 4138.8 tokens/s | Seq. Length: 1069.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:46:34    INFO Saving checkpoint at step 80
[orchestrator] 09:46:34    INFO Starting orchestrator step 80
Feb 15  01:46:38.608
	[default0]:09:46:38 SUCCESS Step 79 | Time: 15.49s | Loss: -0.0085 | Entropy: 0.3000 | Mismatch KL: 0.0008 | Grad. Norm: 0.0687 | LR: 1.00e-05 | Throughput: 6958 tokens/s | MFU: 7.7% | Peak Mem.: 44.7 GiB
Feb 15  01:46:39.311
	[default0]:09:46:39    INFO Saving checkpoint at step 80
Feb 15  01:46:39.328
	[rank_0] 09:46:38 SUCCESS Step 79 | Time: 15.49s | Loss: -0.0085 | Entropy: 0.3000 | Mismatch KL: 0.0008 | Grad. Norm: 0.0687 | LR: 1.00e-05 | Throughput: 6958 tokens/s | MFU: 7.7% | Peak Mem.: 44.7 GiB
[rank_0] 09:46:39    INFO Saving checkpoint at step 80
Feb 15  01:46:51.334
	[orchestrator] 09:46:50    INFO Logging samples to W&B table at step 80
[orchestrator] 09:46:51 SUCCESS Step 80 | Time: 16.94s | Reward: 0.6862 | Throughput: 3789.1 tokens/s | Seq. Length: 996.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:46:51    INFO Starting orchestrator step 81
Feb 15  01:47:09.343
	[orchestrator] 09:47:07 SUCCESS Step 81 | Time: 16.52s | Reward: 0.5289 | Throughput: 4152.4 tokens/s | Seq. Length: 1064.0 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:47:07    INFO Starting orchestrator step 82
[orchestrator] 09:47:08    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 81 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:47:23.335
	[default0]:09:47:23    INFO Saving weight checkpoint at step 80
Feb 15  01:47:24.350
	[rank_0] 09:47:23    INFO Saving weight checkpoint at step 80
Feb 15  01:48:32.123
	[default0]:09:48:32 SUCCESS Step 80 | Time: 3.84s | Loss: -0.0042 | Entropy: 0.3066 | Mismatch KL: 0.0010 | Grad. Norm: 0.0519 | LR: 1.00e-05 | Throughput: 3624 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:48:32.208
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:48:33.384
	[rank_0] 09:48:32 SUCCESS Step 80 | Time: 3.84s | Loss: -0.0042 | Entropy: 0.3066 | Mismatch KL: 0.0010 | Grad. Norm: 0.0519 | LR: 1.00e-05 | Throughput: 3624 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
[orchestrator] 09:48:33    INFO Orchestrator resumed: checkpoint 81 ready (after 85.11s)
Feb 15  01:48:36.386
	[orchestrator] 09:48:33 SUCCESS Step 82 | Time: 85.98s | Reward: 0.8279 | Throughput: 781.3 tokens/s | Seq. Length: 1048.5 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:48:33    INFO Starting orchestrator step 83
[orchestrator] 09:48:34    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 82 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:48:38.153
	[default0]:09:48:38 SUCCESS Step 81 | Time: 4.91s | Loss: 0.0039 | Entropy: 0.3049 | Mismatch KL: 0.0009 | Grad. Norm: 0.0806 | LR: 1.00e-05 | Throughput: 3590 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:48:39.388
	[rank_0] 09:48:38 SUCCESS Step 81 | Time: 4.91s | Loss: 0.0039 | Entropy: 0.3049 | Mismatch KL: 0.0009 | Grad. Norm: 0.0806 | LR: 1.00e-05 | Throughput: 3590 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:48:42.390
	[orchestrator] 09:48:39    INFO Orchestrator resumed: checkpoint 82 ready (after 5.01s)
Feb 15  01:48:43.173
	[default0]:09:48:43 SUCCESS Step 82 | Time: 4.32s | Loss: -0.0053 | Entropy: 0.3198 | Mismatch KL: 0.0008 | Grad. Norm: 0.0454 | LR: 1.00e-05 | Throughput: 3707 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:48:45.391
	[rank_0] 09:48:43 SUCCESS Step 82 | Time: 4.32s | Loss: -0.0053 | Entropy: 0.3198 | Mismatch KL: 0.0008 | Grad. Norm: 0.0454 | LR: 1.00e-05 | Throughput: 3707 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:48:51.394
	[orchestrator] 09:48:50 SUCCESS Step 83 | Time: 16.95s | Reward: 0.8858 | Throughput: 3923.2 tokens/s | Seq. Length: 1032.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:48:50    INFO Starting orchestrator step 84
Feb 15  01:48:55.342
	[default0]:09:48:55 SUCCESS Step 83 | Time: 11.31s | Loss: -0.0050 | Entropy: 0.2978 | Mismatch KL: 0.0007 | Grad. Norm: 0.0429 | LR: 1.00e-05 | Throughput: 3799 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:48:57.397
	[rank_0] 09:48:55 SUCCESS Step 83 | Time: 11.31s | Loss: -0.0050 | Entropy: 0.2978 | Mismatch KL: 0.0007 | Grad. Norm: 0.0429 | LR: 1.00e-05 | Throughput: 3799 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:49:27.416
	[orchestrator] 09:49:25 SUCCESS Step 84 | Time: 34.64s | Reward: 0.8729 | Throughput: 2032.8 tokens/s | Seq. Length: 1096.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 09:49:25    INFO Starting orchestrator step 85
Feb 15  01:49:29.919
	[default0]:09:49:29 SUCCESS Step 84 | Time: 33.87s | Loss: -0.0061 | Entropy: 0.2513 | Mismatch KL: 0.0007 | Grad. Norm: 0.0545 | LR: 1.00e-05 | Throughput: 3443 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  01:49:30.417
	[rank_0] 09:49:29 SUCCESS Step 84 | Time: 33.87s | Loss: -0.0061 | Entropy: 0.2513 | Mismatch KL: 0.0007 | Grad. Norm: 0.0545 | LR: 1.00e-05 | Throughput: 3443 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  01:49:45.424
	[orchestrator] 09:49:43 SUCCESS Step 85 | Time: 18.04s | Reward: 1.0132 | Throughput: 3929.4 tokens/s | Seq. Length: 1097.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 2
[orchestrator] 09:49:43    INFO Starting orchestrator step 86
Feb 15  01:49:47.705
	[default0]:09:49:47 SUCCESS Step 85 | Time: 17.04s | Loss: -0.0082 | Entropy: 0.2579 | Mismatch KL: 0.0008 | Grad. Norm: 0.0521 | LR: 1.00e-05 | Throughput: 3364 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  01:49:48.425
	[rank_0] 09:49:47 SUCCESS Step 85 | Time: 17.04s | Loss: -0.0082 | Entropy: 0.2579 | Mismatch KL: 0.0008 | Grad. Norm: 0.0521 | LR: 1.00e-05 | Throughput: 3364 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  01:50:03.433
	[orchestrator] 09:50:03 SUCCESS Step 86 | Time: 20.03s | Reward: 1.1516 | Throughput: 3386.1 tokens/s | Seq. Length: 1054.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 3
[orchestrator] 09:50:03    INFO Starting orchestrator step 87
Feb 15  01:50:07.806
	[default0]:09:50:07 SUCCESS Step 86 | Time: 19.47s | Loss: -0.0056 | Entropy: 0.2756 | Mismatch KL: 0.0007 | Grad. Norm: 0.0418 | LR: 1.00e-05 | Throughput: 3326 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  01:50:09.435
	[rank_0] 09:50:07 SUCCESS Step 86 | Time: 19.47s | Loss: -0.0056 | Entropy: 0.2756 | Mismatch KL: 0.0007 | Grad. Norm: 0.0418 | LR: 1.00e-05 | Throughput: 3326 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  01:50:42.452
	[orchestrator] 09:50:41 SUCCESS Step 87 | Time: 38.21s | Reward: 1.1792 | Throughput: 1769.6 tokens/s | Seq. Length: 1053.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 4
[orchestrator] 09:50:41    INFO Starting orchestrator step 88
Feb 15  01:50:45.996
	[default0]:09:50:45 SUCCESS Step 87 | Time: 37.49s | Loss: -0.0045 | Entropy: 0.2807 | Mismatch KL: 0.0008 | Grad. Norm: 0.0425 | LR: 1.00e-05 | Throughput: 3065 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  01:50:48.455
	[rank_0] 09:50:45 SUCCESS Step 87 | Time: 37.49s | Loss: -0.0045 | Entropy: 0.2807 | Mismatch KL: 0.0008 | Grad. Norm: 0.0425 | LR: 1.00e-05 | Throughput: 3065 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  01:51:03.463
	[orchestrator] 09:51:01 SUCCESS Step 88 | Time: 20.11s | Reward: 1.0825 | Throughput: 3419.3 tokens/s | Seq. Length: 1067.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 5
[orchestrator] 09:51:01    INFO Starting orchestrator step 89
Feb 15  01:51:06.094
	[default0]:09:51:06 SUCCESS Step 88 | Time: 19.47s | Loss: -0.0075 | Entropy: 0.2562 | Mismatch KL: 0.0007 | Grad. Norm: 0.0624 | LR: 1.00e-05 | Throughput: 3021 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  01:51:06.464
	[rank_0] 09:51:06 SUCCESS Step 88 | Time: 19.47s | Loss: -0.0075 | Entropy: 0.2562 | Mismatch KL: 0.0007 | Grad. Norm: 0.0624 | LR: 1.00e-05 | Throughput: 3021 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  01:51:21.471
	[orchestrator] 09:51:19 SUCCESS Step 89 | Time: 18.35s | Reward: 1.2080 | Throughput: 3735.1 tokens/s | Seq. Length: 1063.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 6
[orchestrator] 09:51:19    INFO Saving checkpoint at step 90
[orchestrator] 09:51:19    INFO Starting orchestrator step 90
Feb 15  01:51:24.284
	[default0]:09:51:24 SUCCESS Step 89 | Time: 17.45s | Loss: -0.0012 | Entropy: 0.2860 | Mismatch KL: 0.0007 | Grad. Norm: 0.0383 | LR: 1.00e-05 | Throughput: 4846 tokens/s | MFU: 5.4% | Peak Mem.: 44.7 GiB
Feb 15  01:51:24.472
	[rank_0] 09:51:24 SUCCESS Step 89 | Time: 17.45s | Loss: -0.0012 | Entropy: 0.2860 | Mismatch KL: 0.0007 | Grad. Norm: 0.0383 | LR: 1.00e-05 | Throughput: 4846 tokens/s | MFU: 5.4% | Peak Mem.: 44.7 GiB
Feb 15  01:51:24.988
	[default0]:09:51:24    INFO Saving checkpoint at step 90
Feb 15  01:51:27.473
	[rank_0] 09:51:24    INFO Saving checkpoint at step 90
Feb 15  01:51:48.483
	[orchestrator] 09:51:46    INFO Logging samples to W&B table at step 90
[orchestrator] 09:51:46 SUCCESS Step 90 | Time: 26.51s | Reward: 0.7605 | Throughput: 6158.8 tokens/s | Seq. Length: 2535.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:51:46    INFO Starting orchestrator step 91
Feb 15  01:52:03.493
	[orchestrator] 09:52:02 SUCCESS Step 91 | Time: 16.00s | Reward: 1.2611 | Throughput: 4276.1 tokens/s | Seq. Length: 1061.1 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:52:02    INFO Starting orchestrator step 92
[orchestrator] 09:52:03    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 91 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:52:08.895
	[default0]:09:52:08    INFO Saving weight checkpoint at step 90
Feb 15  01:52:09.495
	[rank_0] 09:52:08    INFO Saving weight checkpoint at step 90
Feb 15  01:53:18.590
	[default0]:09:53:18 SUCCESS Step 90 | Time: 7.21s | Loss: -0.0034 | Entropy: 0.3713 | Mismatch KL: 0.0010 | Grad. Norm: 0.0492 | LR: 1.00e-05 | Throughput: 3167 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  01:53:18.596
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:53:21.530
	[rank_0] 09:53:18 SUCCESS Step 90 | Time: 7.21s | Loss: -0.0034 | Entropy: 0.3713 | Mismatch KL: 0.0010 | Grad. Norm: 0.0492 | LR: 1.00e-05 | Throughput: 3167 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
[orchestrator] 09:53:20    INFO Orchestrator resumed: checkpoint 91 ready (after 77.13s)
[orchestrator] 09:53:20 SUCCESS Step 92 | Time: 77.83s | Reward: 1.2441 | Throughput: 897.6 tokens/s | Seq. Length: 1089.9 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:53:20    INFO Starting orchestrator step 93
[orchestrator] 09:53:21    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 92 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:53:23.715
	[default0]:09:53:23 SUCCESS Step 91 | Time: 4.46s | Loss: -0.0088 | Entropy: 0.2579 | Mismatch KL: 0.0007 | Grad. Norm: 0.0423 | LR: 1.00e-05 | Throughput: 3173 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  01:53:24.531
	[rank_0] 09:53:23 SUCCESS Step 91 | Time: 4.46s | Loss: -0.0088 | Entropy: 0.2579 | Mismatch KL: 0.0007 | Grad. Norm: 0.0423 | LR: 1.00e-05 | Throughput: 3173 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  01:53:27.532
	[orchestrator] 09:53:25    INFO Orchestrator resumed: checkpoint 92 ready (after 4.01s)
Feb 15  01:53:28.741
	[default0]:09:53:28 SUCCESS Step 92 | Time: 4.41s | Loss: -0.0057 | Entropy: 0.2500 | Mismatch KL: 0.0007 | Grad. Norm: 0.0500 | LR: 1.00e-05 | Throughput: 3251 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  01:53:30.533
	[rank_0] 09:53:28 SUCCESS Step 92 | Time: 4.41s | Loss: -0.0057 | Entropy: 0.2500 | Mismatch KL: 0.0007 | Grad. Norm: 0.0500 | LR: 1.00e-05 | Throughput: 3251 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  01:53:39.536
	[orchestrator] 09:53:37 SUCCESS Step 93 | Time: 16.85s | Reward: 1.2178 | Throughput: 4032.3 tokens/s | Seq. Length: 1054.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:53:37    INFO Starting orchestrator step 94
Feb 15  01:53:41.906
	[default0]:09:53:41 SUCCESS Step 93 | Time: 12.47s | Loss: -0.0055 | Entropy: 0.2425 | Mismatch KL: 0.0006 | Grad. Norm: 0.0398 | LR: 1.00e-05 | Throughput: 3604 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:53:42.538
	[rank_0] 09:53:41 SUCCESS Step 93 | Time: 12.47s | Loss: -0.0055 | Entropy: 0.2425 | Mismatch KL: 0.0006 | Grad. Norm: 0.0398 | LR: 1.00e-05 | Throughput: 3604 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:53:54.542
	[orchestrator] 09:53:54 SUCCESS Step 94 | Time: 17.15s | Reward: 1.3306 | Throughput: 3934.5 tokens/s | Seq. Length: 1052.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:53:54    INFO Starting orchestrator step 95
Feb 15  01:53:59.091
	[default0]:09:53:59 SUCCESS Step 94 | Time: 16.49s | Loss: -0.0125 | Entropy: 0.2523 | Mismatch KL: 0.0006 | Grad. Norm: 0.0436 | LR: 1.00e-05 | Throughput: 3684 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:54:00.544
	[rank_0] 09:53:59 SUCCESS Step 94 | Time: 16.49s | Loss: -0.0125 | Entropy: 0.2523 | Mismatch KL: 0.0006 | Grad. Norm: 0.0436 | LR: 1.00e-05 | Throughput: 3684 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:54:12.550
	[orchestrator] 09:54:11 SUCCESS Step 95 | Time: 17.03s | Reward: 1.4627 | Throughput: 4076.6 tokens/s | Seq. Length: 1077.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:54:11    INFO Starting orchestrator step 96
Feb 15  01:54:16.273
	[default0]:09:54:16 SUCCESS Step 95 | Time: 16.44s | Loss: -0.0095 | Entropy: 0.2422 | Mismatch KL: 0.0007 | Grad. Norm: 0.0533 | LR: 1.00e-05 | Throughput: 3734 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:54:18.552
	[rank_0] 09:54:16 SUCCESS Step 95 | Time: 16.44s | Loss: -0.0095 | Entropy: 0.2422 | Mismatch KL: 0.0007 | Grad. Norm: 0.0533 | LR: 1.00e-05 | Throughput: 3734 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:54:30.559
	[orchestrator] 09:54:28 SUCCESS Step 96 | Time: 16.85s | Reward: 1.4640 | Throughput: 4033.4 tokens/s | Seq. Length: 1054.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:54:28    INFO Starting orchestrator step 97
Feb 15  01:54:33.351
	[default0]:09:54:33 SUCCESS Step 96 | Time: 16.44s | Loss: -0.0083 | Entropy: 0.2453 | Mismatch KL: 0.0006 | Grad. Norm: 0.0334 | LR: 1.00e-05 | Throughput: 4081 tokens/s | MFU: 4.5% | Peak Mem.: 44.7 GiB
Feb 15  01:54:33.561
	[rank_0] 09:54:33 SUCCESS Step 96 | Time: 16.44s | Loss: -0.0083 | Entropy: 0.2453 | Mismatch KL: 0.0006 | Grad. Norm: 0.0334 | LR: 1.00e-05 | Throughput: 4081 tokens/s | MFU: 4.5% | Peak Mem.: 44.7 GiB
Feb 15  01:54:45.567
	[orchestrator] 09:54:45 SUCCESS Step 97 | Time: 16.88s | Reward: 1.5476 | Throughput: 4092.8 tokens/s | Seq. Length: 1072.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:54:45    INFO Starting orchestrator step 98
Feb 15  01:54:50.335
	[default0]:09:54:50 SUCCESS Step 97 | Time: 16.35s | Loss: -0.0008 | Entropy: 0.2004 | Mismatch KL: 0.0007 | Grad. Norm: 0.0376 | LR: 1.00e-05 | Throughput: 4119 tokens/s | MFU: 4.6% | Peak Mem.: 44.7 GiB
Feb 15  01:54:51.569
	[rank_0] 09:54:50 SUCCESS Step 97 | Time: 16.35s | Loss: -0.0008 | Entropy: 0.2004 | Mismatch KL: 0.0007 | Grad. Norm: 0.0376 | LR: 1.00e-05 | Throughput: 4119 tokens/s | MFU: 4.6% | Peak Mem.: 44.7 GiB
Feb 15  01:55:03.575
	[orchestrator] 09:55:02 SUCCESS Step 98 | Time: 17.28s | Reward: 1.4094 | Throughput: 3939.6 tokens/s | Seq. Length: 1057.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:55:02    INFO Starting orchestrator step 99
Feb 15  01:55:07.411
	[default0]:09:55:07 SUCCESS Step 98 | Time: 16.11s | Loss: 0.0070 | Entropy: 0.2351 | Mismatch KL: 0.0006 | Grad. Norm: 0.0651 | LR: 1.00e-05 | Throughput: 4122 tokens/s | MFU: 4.6% | Peak Mem.: 44.7 GiB
Feb 15  01:55:09.577
	[rank_0] 09:55:07 SUCCESS Step 98 | Time: 16.11s | Loss: 0.0070 | Entropy: 0.2351 | Mismatch KL: 0.0006 | Grad. Norm: 0.0651 | LR: 1.00e-05 | Throughput: 4122 tokens/s | MFU: 4.6% | Peak Mem.: 44.7 GiB
Feb 15  01:55:21.582
	[orchestrator] 09:55:19 SUCCESS Step 99 | Time: 16.74s | Reward: 1.5169 | Throughput: 3984.9 tokens/s | Seq. Length: 1036.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:55:19    INFO Saving checkpoint at step 100
[orchestrator] 09:55:19    INFO Starting orchestrator step 100
Feb 15  01:55:24.484
	[default0]:09:55:24 SUCCESS Step 99 | Time: 16.40s | Loss: -0.0043 | Entropy: 0.2462 | Mismatch KL: 0.0006 | Grad. Norm: 0.0334 | LR: 1.00e-05 | Throughput: 6892 tokens/s | MFU: 7.7% | Peak Mem.: 44.7 GiB
Feb 15  01:55:24.583
	[rank_0] 09:55:24 SUCCESS Step 99 | Time: 16.40s | Loss: -0.0043 | Entropy: 0.2462 | Mismatch KL: 0.0006 | Grad. Norm: 0.0334 | LR: 1.00e-05 | Throughput: 6892 tokens/s | MFU: 7.7% | Peak Mem.: 44.7 GiB
Feb 15  01:55:25.186
	[default0]:09:55:25    INFO Saving checkpoint at step 100
Feb 15  01:55:27.584
	[rank_0] 09:55:25    INFO Saving checkpoint at step 100
Feb 15  01:55:36.590
	[orchestrator] 09:55:36    INFO Logging samples to W&B table at step 100
[orchestrator] 09:55:36 SUCCESS Step 100 | Time: 17.05s | Reward: 1.6582 | Throughput: 4068.8 tokens/s | Seq. Length: 1077.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:55:36    INFO Starting orchestrator step 101
Feb 15  01:55:54.599
	[orchestrator] 09:55:53 SUCCESS Step 101 | Time: 16.90s | Reward: 1.5220 | Throughput: 3945.3 tokens/s | Seq. Length: 1035.1 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:55:53    INFO Starting orchestrator step 102
[orchestrator] 09:55:53    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 101 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:56:08.384
	[default0]:09:56:08    INFO Saving weight checkpoint at step 100
Feb 15  01:56:09.608
	[rank_0] 09:56:08    INFO Saving weight checkpoint at step 100
Feb 15  01:57:19.382
	[default0]:09:57:19 SUCCESS Step 100 | Time: 4.31s | Loss: -0.0000 | Entropy: 0.2168 | Mismatch KL: 0.0007 | Grad. Norm: 0.0241 | LR: 1.00e-05 | Throughput: 3626 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  01:57:21.643
	[rank_0] 09:57:19 SUCCESS Step 100 | Time: 4.31s | Loss: -0.0000 | Entropy: 0.2168 | Mismatch KL: 0.0007 | Grad. Norm: 0.0241 | LR: 1.00e-05 | Throughput: 3626 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
[orchestrator] 09:57:20    INFO Orchestrator resumed: checkpoint 101 ready (after 87.18s)
[orchestrator] 09:57:20 SUCCESS Step 102 | Time: 87.63s | Reward: 1.3648 | Throughput: 782.8 tokens/s | Seq. Length: 1070.3 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:57:20    INFO Starting orchestrator step 103
Feb 15  01:57:24.506
	[default0]:09:57:24 SUCCESS Step 101 | Time: 4.48s | Loss: -0.0013 | Entropy: 0.2225 | Mismatch KL: 0.0007 | Grad. Norm: 0.0312 | LR: 1.00e-05 | Throughput: 3623 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  01:57:24.645
	[rank_0] 09:57:24 SUCCESS Step 101 | Time: 4.48s | Loss: -0.0013 | Entropy: 0.2225 | Mismatch KL: 0.0007 | Grad. Norm: 0.0312 | LR: 1.00e-05 | Throughput: 3623 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
[orchestrator] 09:57:21    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 102 (>1 step(s) ahead). Training is progressing normally.
Feb 15  01:57:27.646
	[orchestrator] 09:57:25    INFO Orchestrator resumed: checkpoint 102 ready (after 4.00s)
Feb 15  01:57:29.627
	[default0]:09:57:29 SUCCESS Step 102 | Time: 4.40s | Loss: -0.0046 | Entropy: 0.2322 | Mismatch KL: 0.0007 | Grad. Norm: 0.0438 | LR: 1.00e-05 | Throughput: 3736 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:57:30.647
	[rank_0] 09:57:29 SUCCESS Step 102 | Time: 4.40s | Loss: -0.0046 | Entropy: 0.2322 | Mismatch KL: 0.0007 | Grad. Norm: 0.0438 | LR: 1.00e-05 | Throughput: 3736 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:57:40.126
	[orchestrator] 09:57:38 SUCCESS Step 103 | Time: 17.76s | Reward: 1.5364 | Throughput: 3919.3 tokens/s | Seq. Length: 1081.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:57:38    INFO Starting orchestrator step 104
Feb 15  01:57:42.884
	[default0]:09:57:42 SUCCESS Step 103 | Time: 12.61s | Loss: -0.0061 | Entropy: 0.1763 | Mismatch KL: 0.0005 | Grad. Norm: 0.0536 | LR: 1.00e-05 | Throughput: 3753 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:57:43.127
	[rank_0] 09:57:42 SUCCESS Step 103 | Time: 12.61s | Loss: -0.0061 | Entropy: 0.1763 | Mismatch KL: 0.0005 | Grad. Norm: 0.0536 | LR: 1.00e-05 | Throughput: 3753 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:57:58.133
	[orchestrator] 09:57:55 SUCCESS Step 104 | Time: 16.99s | Reward: 1.6266 | Throughput: 3979.6 tokens/s | Seq. Length: 1050.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:57:55    INFO Starting orchestrator step 105
Feb 15  01:58:00.663
	[default0]:09:57:59 SUCCESS Step 104 | Time: 16.42s | Loss: -0.0008 | Entropy: 0.2103 | Mismatch KL: 0.0006 | Grad. Norm: 0.0264 | LR: 1.00e-05 | Throughput: 3744 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:58:01.562
	[rank_0] 09:57:59 SUCCESS Step 104 | Time: 16.42s | Loss: -0.0008 | Entropy: 0.2103 | Mismatch KL: 0.0006 | Grad. Norm: 0.0264 | LR: 1.00e-05 | Throughput: 3744 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:58:13.568
	[orchestrator] 09:58:12 SUCCESS Step 105 | Time: 16.82s | Reward: 1.6633 | Throughput: 4083.6 tokens/s | Seq. Length: 1066.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:58:12    INFO Starting orchestrator step 106
Feb 15  01:58:17.844
	[default0]:09:58:17 SUCCESS Step 105 | Time: 15.46s | Loss: 0.0009 | Entropy: 0.2231 | Mismatch KL: 0.0006 | Grad. Norm: 0.0206 | LR: 1.00e-05 | Throughput: 3726 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:58:19.575
	[rank_0] 09:58:17 SUCCESS Step 105 | Time: 15.46s | Loss: 0.0009 | Entropy: 0.2231 | Mismatch KL: 0.0006 | Grad. Norm: 0.0206 | LR: 1.00e-05 | Throughput: 3726 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:58:33.427
	[orchestrator] 09:58:29 SUCCESS Step 106 | Time: 17.32s | Reward: 1.6861 | Throughput: 4043.8 tokens/s | Seq. Length: 1086.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:58:29    INFO Starting orchestrator step 107
Feb 15  01:58:38.540
	[default0]:09:58:38 SUCCESS Step 106 | Time: 19.60s | Loss: -0.0007 | Entropy: 0.1960 | Mismatch KL: 0.0006 | Grad. Norm: 0.0274 | LR: 1.00e-05 | Throughput: 3672 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:58:39.426
	[rank_0] 09:58:38 SUCCESS Step 106 | Time: 19.60s | Loss: -0.0007 | Entropy: 0.1960 | Mismatch KL: 0.0006 | Grad. Norm: 0.0274 | LR: 1.00e-05 | Throughput: 3672 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  01:58:48.430
	[orchestrator] 09:58:46 SUCCESS Step 107 | Time: 16.67s | Reward: 1.6094 | Throughput: 4107.2 tokens/s | Seq. Length: 1062.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:58:46    INFO Starting orchestrator step 108
Feb 15  01:58:51.701
	[default0]:09:58:51 SUCCESS Step 107 | Time: 12.48s | Loss: -0.0016 | Entropy: 0.1807 | Mismatch KL: 0.0006 | Grad. Norm: 0.0331 | LR: 1.00e-05 | Throughput: 3737 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:58:54.433
	[rank_0] 09:58:51 SUCCESS Step 107 | Time: 12.48s | Loss: -0.0016 | Entropy: 0.1807 | Mismatch KL: 0.0006 | Grad. Norm: 0.0331 | LR: 1.00e-05 | Throughput: 3737 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:59:03.436
	[orchestrator] 09:59:03 SUCCESS Step 108 | Time: 16.67s | Reward: 1.6064 | Throughput: 4104.2 tokens/s | Seq. Length: 1061.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:59:03    INFO Starting orchestrator step 109
Feb 15  01:59:07.779
	[default0]:09:59:07 SUCCESS Step 108 | Time: 15.27s | Loss: -0.0029 | Entropy: 0.1825 | Mismatch KL: 0.0005 | Grad. Norm: 0.0328 | LR: 1.00e-05 | Throughput: 3740 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:59:09.439
	[rank_0] 09:59:07 SUCCESS Step 108 | Time: 15.27s | Loss: -0.0029 | Entropy: 0.1825 | Mismatch KL: 0.0005 | Grad. Norm: 0.0328 | LR: 1.00e-05 | Throughput: 3740 tokens/s | MFU: 4.2% | Peak Mem.: 44.7 GiB
Feb 15  01:59:21.444
	[orchestrator] 09:59:19 SUCCESS Step 109 | Time: 16.67s | Reward: 1.7638 | Throughput: 4085.3 tokens/s | Seq. Length: 1056.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:59:19    INFO Saving checkpoint at step 110
[orchestrator] 09:59:19    INFO Starting orchestrator step 110
Feb 15  01:59:24.964
	[default0]:09:59:24 SUCCESS Step 109 | Time: 16.48s | Loss: 0.0004 | Entropy: 0.1728 | Mismatch KL: 0.0005 | Grad. Norm: 0.0178 | LR: 1.00e-05 | Throughput: 6765 tokens/s | MFU: 7.5% | Peak Mem.: 44.7 GiB
Feb 15  01:59:25.568
	[default0]:09:59:25    INFO Saving checkpoint at step 110
Feb 15  01:59:27.447
	[rank_0] 09:59:24 SUCCESS Step 109 | Time: 16.48s | Loss: 0.0004 | Entropy: 0.1728 | Mismatch KL: 0.0005 | Grad. Norm: 0.0178 | LR: 1.00e-05 | Throughput: 6765 tokens/s | MFU: 7.5% | Peak Mem.: 44.7 GiB
[rank_0] 09:59:25    INFO Saving checkpoint at step 110
Feb 15  01:59:39.454
	[orchestrator] 09:59:37    INFO Logging samples to W&B table at step 110
[orchestrator] 09:59:37 SUCCESS Step 110 | Time: 17.12s | Reward: 1.5765 | Throughput: 4024.3 tokens/s | Seq. Length: 1069.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 09:59:37    INFO Starting orchestrator step 111
Feb 15  01:59:54.462
	[orchestrator] 09:59:53 SUCCESS Step 111 | Time: 16.75s | Reward: 1.6606 | Throughput: 3916.1 tokens/s | Seq. Length: 1017.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 09:59:53    INFO Starting orchestrator step 112
[orchestrator] 09:59:53    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 111 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:00:11.193
	[default0]:10:00:11    INFO Saving weight checkpoint at step 110
Feb 15  02:00:12.472
	[rank_0] 10:00:11    INFO Saving weight checkpoint at step 110
Feb 15  02:01:29.866
	[default0]:10:01:29 SUCCESS Step 110 | Time: 4.25s | Loss: 0.0008 | Entropy: 0.1656 | Mismatch KL: 0.0006 | Grad. Norm: 0.0288 | LR: 1.00e-05 | Throughput: 3454 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:01:29.900
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:01:30.513
	[rank_0] 10:01:29 SUCCESS Step 110 | Time: 4.25s | Loss: 0.0008 | Entropy: 0.1656 | Mismatch KL: 0.0006 | Grad. Norm: 0.0288 | LR: 1.00e-05 | Throughput: 3454 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:01:33.525
	[orchestrator] 10:01:31    INFO Orchestrator resumed: checkpoint 111 ready (after 97.13s)
[orchestrator] 10:01:31 SUCCESS Step 112 | Time: 97.58s | Reward: 1.6902 | Throughput: 708.8 tokens/s | Seq. Length: 1079.5 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:01:31    INFO Starting orchestrator step 113
[orchestrator] 10:01:32    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 112 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:01:34.991
	[default0]:10:01:34 SUCCESS Step 111 | Time: 4.47s | Loss: -0.0031 | Entropy: 0.1809 | Mismatch KL: 0.0005 | Grad. Norm: 0.0256 | LR: 1.00e-05 | Throughput: 3465 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:01:36.525
	[rank_0] 10:01:34 SUCCESS Step 111 | Time: 4.47s | Loss: -0.0031 | Entropy: 0.1809 | Mismatch KL: 0.0005 | Grad. Norm: 0.0256 | LR: 1.00e-05 | Throughput: 3465 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
[orchestrator] 10:01:36    INFO Orchestrator resumed: checkpoint 112 ready (after 4.01s)
Feb 15  02:01:39.813
	[default0]:10:01:39 SUCCESS Step 112 | Time: 4.13s | Loss: -0.0033 | Entropy: 0.1749 | Mismatch KL: 0.0006 | Grad. Norm: 0.0272 | LR: 1.00e-05 | Throughput: 3581 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:01:42.529
	[rank_0] 10:01:39 SUCCESS Step 112 | Time: 4.13s | Loss: -0.0033 | Entropy: 0.1749 | Mismatch KL: 0.0006 | Grad. Norm: 0.0272 | LR: 1.00e-05 | Throughput: 3581 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:01:48.532
	[orchestrator] 10:01:48 SUCCESS Step 113 | Time: 16.98s | Reward: 1.6282 | Throughput: 4088.8 tokens/s | Seq. Length: 1075.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:01:48    INFO Starting orchestrator step 114
Feb 15  02:01:52.876
	[default0]:10:01:52 SUCCESS Step 113 | Time: 12.35s | Loss: -0.0005 | Entropy: 0.1584 | Mismatch KL: 0.0005 | Grad. Norm: 0.0311 | LR: 1.00e-05 | Throughput: 3637 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:01:54.534
	[rank_0] 10:01:52 SUCCESS Step 113 | Time: 12.35s | Loss: -0.0005 | Entropy: 0.1584 | Mismatch KL: 0.0005 | Grad. Norm: 0.0311 | LR: 1.00e-05 | Throughput: 3637 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:02:06.540
	[orchestrator] 10:02:05 SUCCESS Step 114 | Time: 17.38s | Reward: 1.6072 | Throughput: 3983.3 tokens/s | Seq. Length: 1075.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:02:05    INFO Starting orchestrator step 115
Feb 15  02:02:10.762
	[default0]:10:02:10 SUCCESS Step 114 | Time: 17.23s | Loss: 0.0035 | Entropy: 0.2039 | Mismatch KL: 0.0005 | Grad. Norm: 0.0339 | LR: 1.00e-05 | Throughput: 3604 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:02:12.543
	[rank_0] 10:02:10 SUCCESS Step 114 | Time: 17.23s | Loss: 0.0035 | Entropy: 0.2039 | Mismatch KL: 0.0005 | Grad. Norm: 0.0339 | LR: 1.00e-05 | Throughput: 3604 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:02:24.548
	[orchestrator] 10:02:22 SUCCESS Step 115 | Time: 17.15s | Reward: 1.6558 | Throughput: 4060.1 tokens/s | Seq. Length: 1081.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:02:22    INFO Starting orchestrator step 116
Feb 15  02:02:27.960
	[default0]:10:02:27 SUCCESS Step 115 | Time: 16.36s | Loss: 0.0021 | Entropy: 0.1891 | Mismatch KL: 0.0006 | Grad. Norm: 0.0228 | LR: 1.00e-05 | Throughput: 3673 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  02:02:30.550
	[rank_0] 10:02:27 SUCCESS Step 115 | Time: 16.36s | Loss: 0.0021 | Entropy: 0.1891 | Mismatch KL: 0.0006 | Grad. Norm: 0.0228 | LR: 1.00e-05 | Throughput: 3673 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  02:02:42.557
	[orchestrator] 10:02:39 SUCCESS Step 116 | Time: 16.89s | Reward: 1.7148 | Throughput: 4028.4 tokens/s | Seq. Length: 1056.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:02:39    INFO Starting orchestrator step 117
Feb 15  02:02:45.054
	[default0]:10:02:45 SUCCESS Step 116 | Time: 16.34s | Loss: -0.0041 | Entropy: 0.1904 | Mismatch KL: 0.0006 | Grad. Norm: 0.0202 | LR: 1.00e-05 | Throughput: 3624 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:02:45.559
	[rank_0] 10:02:45 SUCCESS Step 116 | Time: 16.34s | Loss: -0.0041 | Entropy: 0.1904 | Mismatch KL: 0.0006 | Grad. Norm: 0.0202 | LR: 1.00e-05 | Throughput: 3624 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:02:57.564
	[orchestrator] 10:02:56 SUCCESS Step 117 | Time: 16.99s | Reward: 1.6863 | Throughput: 3992.4 tokens/s | Seq. Length: 1053.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:02:56    INFO Starting orchestrator step 118
Feb 15  02:03:02.637
	[default0]:10:03:02 SUCCESS Step 117 | Time: 16.90s | Loss: -0.0047 | Entropy: 0.1751 | Mismatch KL: 0.0005 | Grad. Norm: 0.0225 | LR: 1.00e-05 | Throughput: 3624 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:03:03.566
	[rank_0] 10:03:02 SUCCESS Step 117 | Time: 16.90s | Loss: -0.0047 | Entropy: 0.1751 | Mismatch KL: 0.0005 | Grad. Norm: 0.0225 | LR: 1.00e-05 | Throughput: 3624 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:03:15.572
	[orchestrator] 10:03:13 SUCCESS Step 118 | Time: 16.71s | Reward: 1.6843 | Throughput: 4093.9 tokens/s | Seq. Length: 1062.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:03:13    INFO Starting orchestrator step 119
Feb 15  02:03:18.812
	[default0]:10:03:18 SUCCESS Step 118 | Time: 15.46s | Loss: -0.0008 | Entropy: 0.1638 | Mismatch KL: 0.0005 | Grad. Norm: 0.0232 | LR: 1.00e-05 | Throughput: 3637 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:03:21.574
	[rank_0] 10:03:18 SUCCESS Step 118 | Time: 15.46s | Loss: -0.0008 | Entropy: 0.1638 | Mismatch KL: 0.0005 | Grad. Norm: 0.0232 | LR: 1.00e-05 | Throughput: 3637 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:03:33.579
	[orchestrator] 10:03:30 SUCCESS Step 119 | Time: 17.04s | Reward: 1.7426 | Throughput: 4048.9 tokens/s | Seq. Length: 1071.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:03:30    INFO Saving checkpoint at step 120
[orchestrator] 10:03:30    INFO Starting orchestrator step 120
Feb 15  02:03:35.892
	[default0]:10:03:35 SUCCESS Step 119 | Time: 16.45s | Loss: 0.0020 | Entropy: 0.1571 | Mismatch KL: 0.0005 | Grad. Norm: 0.0157 | LR: 1.00e-05 | Throughput: 6766 tokens/s | MFU: 7.5% | Peak Mem.: 44.7 GiB
Feb 15  02:03:36.581
	[rank_0] 10:03:35 SUCCESS Step 119 | Time: 16.45s | Loss: 0.0020 | Entropy: 0.1571 | Mismatch KL: 0.0005 | Grad. Norm: 0.0157 | LR: 1.00e-05 | Throughput: 6766 tokens/s | MFU: 7.5% | Peak Mem.: 44.7 GiB
[rank_0] 10:03:36    INFO Saving checkpoint at step 120
Feb 15  02:03:36.596
	[default0]:10:03:36    INFO Saving checkpoint at step 120
Feb 15  02:03:48.586
	[orchestrator] 10:03:47    INFO Logging samples to W&B table at step 120
[orchestrator] 10:03:47 SUCCESS Step 120 | Time: 16.60s | Reward: 1.7144 | Throughput: 4018.9 tokens/s | Seq. Length: 1035.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:03:47    INFO Starting orchestrator step 121
Feb 15  02:04:06.595
	[orchestrator] 10:04:04 SUCCESS Step 121 | Time: 16.69s | Reward: 1.7398 | Throughput: 4138.7 tokens/s | Seq. Length: 1070.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:04:04    INFO Starting orchestrator step 122
[orchestrator] 10:04:04    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 121 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:04:24.129
	[default0]:10:04:24    INFO Saving weight checkpoint at step 120
Feb 15  02:04:24.604
	[rank_0] 10:04:24    INFO Saving weight checkpoint at step 120
Feb 15  02:06:01.845
	[rank_0] 10:06:01 SUCCESS Step 120 | Time: 5.03s | Loss: -0.0004 | Entropy: 0.1911 | Mismatch KL: 0.0005 | Grad. Norm: 0.0155 | LR: 1.00e-05 | Throughput: 3192 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  02:06:01.861
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:10:06:01 SUCCESS Step 120 | Time: 5.03s | Loss: -0.0004 | Entropy: 0.1911 | Mismatch KL: 0.0005 | Grad. Norm: 0.0155 | LR: 1.00e-05 | Throughput: 3192 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:06:04.848
	[orchestrator] 10:06:02    INFO Orchestrator resumed: checkpoint 121 ready (after 118.45s)
[orchestrator] 10:06:03 SUCCESS Step 122 | Time: 119.10s | Reward: 1.6895 | Throughput: 577.1 tokens/s | Seq. Length: 1072.9 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:06:03    INFO Starting orchestrator step 123
[orchestrator] 10:06:04    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 122 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:06:06.887
	[default0]:10:06:06 SUCCESS Step 121 | Time: 4.24s | Loss: -0.0006 | Entropy: 0.1901 | Mismatch KL: 0.0006 | Grad. Norm: 0.0171 | LR: 1.00e-05 | Throughput: 3227 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:06:07.849
	[rank_0] 10:06:06 SUCCESS Step 121 | Time: 4.24s | Loss: -0.0006 | Entropy: 0.1901 | Mismatch KL: 0.0006 | Grad. Norm: 0.0171 | LR: 1.00e-05 | Throughput: 3227 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:06:10.851
	[orchestrator] 10:06:08    INFO Orchestrator resumed: checkpoint 122 ready (after 4.01s)
Feb 15  02:06:12.006
	[default0]:10:06:11 SUCCESS Step 122 | Time: 4.45s | Loss: -0.0027 | Entropy: 0.1960 | Mismatch KL: 0.0007 | Grad. Norm: 0.0289 | LR: 1.00e-05 | Throughput: 3338 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:06:13.851
	[rank_0] 10:06:11 SUCCESS Step 122 | Time: 4.45s | Loss: -0.0027 | Entropy: 0.1960 | Mismatch KL: 0.0007 | Grad. Norm: 0.0289 | LR: 1.00e-05 | Throughput: 3338 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:06:22.855
	[orchestrator] 10:06:20 SUCCESS Step 123 | Time: 17.14s | Reward: 1.7431 | Throughput: 4047.1 tokens/s | Seq. Length: 1076.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:06:20    INFO Starting orchestrator step 124
Feb 15  02:06:25.273
	[default0]:10:06:25 SUCCESS Step 123 | Time: 12.43s | Loss: 0.0022 | Entropy: 0.1726 | Mismatch KL: 0.0005 | Grad. Norm: 0.0156 | LR: 1.00e-05 | Throughput: 3434 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:06:25.857
	[rank_0] 10:06:25 SUCCESS Step 123 | Time: 12.43s | Loss: 0.0022 | Entropy: 0.1726 | Mismatch KL: 0.0005 | Grad. Norm: 0.0156 | LR: 1.00e-05 | Throughput: 3434 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:06:37.862
	[orchestrator] 10:06:37 SUCCESS Step 124 | Time: 17.28s | Reward: 1.7709 | Throughput: 3966.3 tokens/s | Seq. Length: 1063.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:06:37    INFO Starting orchestrator step 125
Feb 15  02:06:42.354
	[default0]:10:06:42 SUCCESS Step 124 | Time: 16.41s | Loss: -0.0025 | Entropy: 0.1535 | Mismatch KL: 0.0005 | Grad. Norm: 0.0143 | LR: 1.00e-05 | Throughput: 3423 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:06:43.865
	[rank_0] 10:06:42 SUCCESS Step 124 | Time: 16.41s | Loss: -0.0025 | Entropy: 0.1535 | Mismatch KL: 0.0005 | Grad. Norm: 0.0143 | LR: 1.00e-05 | Throughput: 3423 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:06:55.873
	[orchestrator] 10:06:54 SUCCESS Step 125 | Time: 16.95s | Reward: 1.7135 | Throughput: 3911.9 tokens/s | Seq. Length: 1029.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:06:54    INFO Starting orchestrator step 126
Feb 15  02:06:59.539
	[default0]:10:06:59 SUCCESS Step 125 | Time: 16.51s | Loss: -0.0019 | Entropy: 0.1827 | Mismatch KL: 0.0005 | Grad. Norm: 0.0246 | LR: 1.00e-05 | Throughput: 3423 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:07:01.875
	[rank_0] 10:06:59 SUCCESS Step 125 | Time: 16.51s | Loss: -0.0019 | Entropy: 0.1827 | Mismatch KL: 0.0005 | Grad. Norm: 0.0246 | LR: 1.00e-05 | Throughput: 3423 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:07:13.880
	[orchestrator] 10:07:11 SUCCESS Step 126 | Time: 16.66s | Reward: 1.7663 | Throughput: 3989.0 tokens/s | Seq. Length: 1032.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:07:11    INFO Starting orchestrator step 127
Feb 15  02:07:15.718
	[default0]:10:07:15 SUCCESS Step 126 | Time: 15.48s | Loss: 0.0002 | Entropy: 0.1625 | Mismatch KL: 0.0004 | Grad. Norm: 0.0083 | LR: 1.00e-05 | Throughput: 3444 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:07:16.888
	[rank_0] 10:07:15 SUCCESS Step 126 | Time: 15.48s | Loss: 0.0002 | Entropy: 0.1625 | Mismatch KL: 0.0004 | Grad. Norm: 0.0083 | LR: 1.00e-05 | Throughput: 3444 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:07:28.895
	[orchestrator] 10:07:28 SUCCESS Step 127 | Time: 17.35s | Reward: 1.7706 | Throughput: 3886.9 tokens/s | Seq. Length: 1047.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:07:28    INFO Starting orchestrator step 128
Feb 15  02:07:33.906
	[default0]:10:07:33 SUCCESS Step 127 | Time: 17.50s | Loss: 0.0000 | Entropy: 0.1247 | Mismatch KL: 0.0004 | Grad. Norm: 0.0090 | LR: 1.00e-05 | Throughput: 3418 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:07:34.898
	[rank_0] 10:07:33 SUCCESS Step 127 | Time: 17.50s | Loss: 0.0000 | Entropy: 0.1247 | Mismatch KL: 0.0004 | Grad. Norm: 0.0090 | LR: 1.00e-05 | Throughput: 3418 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:07:46.904
	[orchestrator] 10:07:45 SUCCESS Step 128 | Time: 16.91s | Reward: 1.7428 | Throughput: 4008.9 tokens/s | Seq. Length: 1052.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:07:45    INFO Starting orchestrator step 129
Feb 15  02:07:49.905
	[rank_0] 10:07:49 SUCCESS Step 128 | Time: 15.26s | Loss: 0.0004 | Entropy: 0.1626 | Mismatch KL: 0.0005 | Grad. Norm: 0.0121 | LR: 1.00e-05 | Throughput: 3420 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:07:49.984
	[default0]:10:07:49 SUCCESS Step 128 | Time: 15.26s | Loss: 0.0004 | Entropy: 0.1626 | Mismatch KL: 0.0005 | Grad. Norm: 0.0121 | LR: 1.00e-05 | Throughput: 3420 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:08:04.913
	[orchestrator] 10:08:02 SUCCESS Step 129 | Time: 17.20s | Reward: 1.7080 | Throughput: 4035.1 tokens/s | Seq. Length: 1077.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:08:02    INFO Saving checkpoint at step 130
[orchestrator] 10:08:02    INFO Starting orchestrator step 130
Feb 15  02:08:06.768
	[default0]:10:08:06 SUCCESS Step 129 | Time: 16.10s | Loss: 0.0013 | Entropy: 0.1674 | Mismatch KL: 0.0005 | Grad. Norm: 0.0208 | LR: 1.00e-05 | Throughput: 6854 tokens/s | MFU: 7.6% | Peak Mem.: 44.7 GiB
Feb 15  02:08:07.472
	[default0]:10:08:07    INFO Saving checkpoint at step 130
Feb 15  02:08:07.915
	[rank_0] 10:08:06 SUCCESS Step 129 | Time: 16.10s | Loss: 0.0013 | Entropy: 0.1674 | Mismatch KL: 0.0005 | Grad. Norm: 0.0208 | LR: 1.00e-05 | Throughput: 6854 tokens/s | MFU: 7.6% | Peak Mem.: 44.7 GiB
[rank_0] 10:08:07    INFO Saving checkpoint at step 130
Feb 15  02:08:19.937
	[orchestrator] 10:08:19    INFO Logging samples to W&B table at step 130
[orchestrator] 10:08:19 SUCCESS Step 130 | Time: 16.86s | Reward: 1.7987 | Throughput: 3852.7 tokens/s | Seq. Length: 1009.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:08:19    INFO Starting orchestrator step 131
Feb 15  02:08:37.946
	[orchestrator] 10:08:36 SUCCESS Step 131 | Time: 17.20s | Reward: 1.7162 | Throughput: 4017.7 tokens/s | Seq. Length: 1072.3 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:08:36    INFO Starting orchestrator step 132
[orchestrator] 10:08:37    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 131 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:08:55.999
	[default0]:10:08:55    INFO Saving weight checkpoint at step 130
Feb 15  02:08:58.958
	[rank_0] 10:08:55    INFO Saving weight checkpoint at step 130
Feb 15  02:10:15.232
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:10:10:15 SUCCESS Step 130 | Time: 3.60s | Loss: -0.0000 | Entropy: 0.1815 | Mismatch KL: 0.0007 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3358 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:10:17.003
	[rank_0] 10:10:15 SUCCESS Step 130 | Time: 3.60s | Loss: -0.0000 | Entropy: 0.1815 | Mismatch KL: 0.0007 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3358 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:10:17.016
	[orchestrator] 10:10:15    INFO Orchestrator resumed: checkpoint 131 ready (after 98.52s)
[orchestrator] 10:10:16 SUCCESS Step 132 | Time: 99.25s | Reward: 1.7693 | Throughput: 685.6 tokens/s | Seq. Length: 1062.0 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:10:16    INFO Starting orchestrator step 133
Feb 15  02:10:20.014
	[orchestrator] 10:10:17    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 132 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:10:20.667
	[default0]:10:10:20 SUCCESS Step 131 | Time: 4.81s | Loss: -0.0043 | Entropy: 0.1856 | Mismatch KL: 0.0005 | Grad. Norm: 0.0185 | LR: 1.00e-05 | Throughput: 3342 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:10:23.016
	[rank_0] 10:10:20 SUCCESS Step 131 | Time: 4.81s | Loss: -0.0043 | Entropy: 0.1856 | Mismatch KL: 0.0005 | Grad. Norm: 0.0185 | LR: 1.00e-05 | Throughput: 3342 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
[orchestrator] 10:10:22    INFO Orchestrator resumed: checkpoint 132 ready (after 5.01s)
Feb 15  02:10:25.690
	[default0]:10:10:25 SUCCESS Step 132 | Time: 4.33s | Loss: 0.0005 | Entropy: 0.1526 | Mismatch KL: 0.0006 | Grad. Norm: 0.0064 | LR: 1.00e-05 | Throughput: 3443 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:10:26.017
	[rank_0] 10:10:25 SUCCESS Step 132 | Time: 4.33s | Loss: 0.0005 | Entropy: 0.1526 | Mismatch KL: 0.0006 | Grad. Norm: 0.0064 | LR: 1.00e-05 | Throughput: 3443 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:10:35.021
	[orchestrator] 10:10:32 SUCCESS Step 133 | Time: 16.81s | Reward: 1.7209 | Throughput: 4034.7 tokens/s | Seq. Length: 1052.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:10:32    INFO Starting orchestrator step 134
Feb 15  02:10:38.248
	[default0]:10:10:38 SUCCESS Step 133 | Time: 11.88s | Loss: 0.0000 | Entropy: 0.1513 | Mismatch KL: 0.0005 | Grad. Norm: 0.0153 | LR: 1.00e-05 | Throughput: 3515 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:10:41.024
	[rank_0] 10:10:38 SUCCESS Step 133 | Time: 11.88s | Loss: 0.0000 | Entropy: 0.1513 | Mismatch KL: 0.0005 | Grad. Norm: 0.0153 | LR: 1.00e-05 | Throughput: 3515 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:10:53.029
	[orchestrator] 10:10:50 SUCCESS Step 134 | Time: 17.50s | Reward: 1.7986 | Throughput: 3898.0 tokens/s | Seq. Length: 1060.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:10:50    INFO Starting orchestrator step 135
Feb 15  02:10:55.326
	[default0]:10:10:55 SUCCESS Step 134 | Time: 16.40s | Loss: 0.0000 | Entropy: 0.1302 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3514 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:10:56.031
	[rank_0] 10:10:55 SUCCESS Step 134 | Time: 16.40s | Loss: 0.0000 | Entropy: 0.1302 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3514 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:11:08.215
	[orchestrator] 10:11:07 SUCCESS Step 135 | Time: 17.25s | Reward: 1.7151 | Throughput: 3874.4 tokens/s | Seq. Length: 1038.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:11:07    INFO Starting orchestrator step 136
Feb 15  02:11:12.106
	[default0]:10:11:12 SUCCESS Step 135 | Time: 16.10s | Loss: -0.0009 | Entropy: 0.1745 | Mismatch KL: 0.0005 | Grad. Norm: 0.0188 | LR: 1.00e-05 | Throughput: 3493 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:11:14.219
	[rank_0] 10:11:12 SUCCESS Step 135 | Time: 16.10s | Loss: -0.0009 | Entropy: 0.1745 | Mismatch KL: 0.0005 | Grad. Norm: 0.0188 | LR: 1.00e-05 | Throughput: 3493 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:11:29.227
	[orchestrator] 10:11:26 SUCCESS Step 136 | Time: 18.91s | Reward: 1.6868 | Throughput: 3489.5 tokens/s | Seq. Length: 1024.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:11:26    INFO Starting orchestrator step 137
Feb 15  02:11:31.310
	[default0]:10:11:31 SUCCESS Step 136 | Time: 18.35s | Loss: 0.0001 | Entropy: 0.1652 | Mismatch KL: 0.0004 | Grad. Norm: 0.0243 | LR: 1.00e-05 | Throughput: 3466 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:11:32.229
	[rank_0] 10:11:31 SUCCESS Step 136 | Time: 18.35s | Loss: 0.0001 | Entropy: 0.1652 | Mismatch KL: 0.0004 | Grad. Norm: 0.0243 | LR: 1.00e-05 | Throughput: 3466 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:11:44.233
	[orchestrator] 10:11:43 SUCCESS Step 137 | Time: 17.04s | Reward: 1.7989 | Throughput: 3972.7 tokens/s | Seq. Length: 1050.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:11:43    INFO Starting orchestrator step 138
Feb 15  02:11:48.484
	[default0]:10:11:48 SUCCESS Step 137 | Time: 16.48s | Loss: 0.0000 | Entropy: 0.1942 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3467 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:11:50.254
	[rank_0] 10:11:48 SUCCESS Step 137 | Time: 16.48s | Loss: 0.0000 | Entropy: 0.1942 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3467 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:12:02.260
	[orchestrator] 10:12:00 SUCCESS Step 138 | Time: 16.86s | Reward: 1.7708 | Throughput: 3928.4 tokens/s | Seq. Length: 1028.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:12:00    INFO Starting orchestrator step 139
Feb 15  02:12:05.666
	[default0]:10:12:05 SUCCESS Step 138 | Time: 16.49s | Loss: 0.0006 | Entropy: 0.1529 | Mismatch KL: 0.0004 | Grad. Norm: 0.0066 | LR: 1.00e-05 | Throughput: 3513 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:12:08.262
	[rank_0] 10:12:05 SUCCESS Step 138 | Time: 16.49s | Loss: 0.0006 | Entropy: 0.1529 | Mismatch KL: 0.0004 | Grad. Norm: 0.0066 | LR: 1.00e-05 | Throughput: 3513 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:12:20.268
	[orchestrator] 10:12:17 SUCCESS Step 139 | Time: 17.33s | Reward: 1.7704 | Throughput: 3867.8 tokens/s | Seq. Length: 1040.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:12:17    INFO Saving checkpoint at step 140
[orchestrator] 10:12:17    INFO Starting orchestrator step 140
Feb 15  02:12:22.858
	[default0]:10:12:22 SUCCESS Step 139 | Time: 16.50s | Loss: 0.0001 | Entropy: 0.1670 | Mismatch KL: 0.0005 | Grad. Norm: 0.0127 | LR: 1.00e-05 | Throughput: 6774 tokens/s | MFU: 7.5% | Peak Mem.: 44.7 GiB
Feb 15  02:12:23.270
	[rank_0] 10:12:22 SUCCESS Step 139 | Time: 16.50s | Loss: 0.0001 | Entropy: 0.1670 | Mismatch KL: 0.0005 | Grad. Norm: 0.0127 | LR: 1.00e-05 | Throughput: 6774 tokens/s | MFU: 7.5% | Peak Mem.: 44.7 GiB
Feb 15  02:12:23.562
	[default0]:10:12:23    INFO Saving checkpoint at step 140
Feb 15  02:12:26.272
	[rank_0] 10:12:23    INFO Saving checkpoint at step 140
Feb 15  02:12:35.277
	[orchestrator] 10:12:35    INFO Logging samples to W&B table at step 140
[orchestrator] 10:12:35 SUCCESS Step 140 | Time: 17.13s | Reward: 1.7422 | Throughput: 3918.5 tokens/s | Seq. Length: 1042.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:12:35    INFO Starting orchestrator step 141
Feb 15  02:12:53.297
	[orchestrator] 10:12:51 SUCCESS Step 141 | Time: 16.86s | Reward: 1.7678 | Throughput: 3960.4 tokens/s | Seq. Length: 1035.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:12:51    INFO Starting orchestrator step 142
[orchestrator] 10:12:52    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 141 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:13:11.306
	[default0]:10:13:11    INFO Saving weight checkpoint at step 140
[rank_0] 10:13:11    INFO Saving weight checkpoint at step 140
Feb 15  02:14:43.667
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:10:14:43 SUCCESS Step 140 | Time: 5.13s | Loss: -0.0005 | Entropy: 0.1490 | Mismatch KL: 0.0004 | Grad. Norm: 0.0103 | LR: 1.00e-05 | Throughput: 3288 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:14:44.486
	[rank_0] 10:14:43 SUCCESS Step 140 | Time: 5.13s | Loss: -0.0005 | Entropy: 0.1490 | Mismatch KL: 0.0004 | Grad. Norm: 0.0103 | LR: 1.00e-05 | Throughput: 3288 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:14:47.488
	[orchestrator] 10:14:45    INFO Orchestrator resumed: checkpoint 141 ready (after 113.29s)
[orchestrator] 10:14:45 SUCCESS Step 142 | Time: 113.87s | Reward: 1.3776 | Throughput: 607.0 tokens/s | Seq. Length: 1078.8 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:14:45    INFO Starting orchestrator step 143
[orchestrator] 10:14:46    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 142 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:14:50.602
	[default0]:10:14:50 SUCCESS Step 141 | Time: 6.17s | Loss: -0.0007 | Entropy: 0.1684 | Mismatch KL: 0.0005 | Grad. Norm: 0.0137 | LR: 1.00e-05 | Throughput: 3272 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:14:53.491
	[rank_0] 10:14:50 SUCCESS Step 141 | Time: 6.17s | Loss: -0.0007 | Entropy: 0.1684 | Mismatch KL: 0.0005 | Grad. Norm: 0.0137 | LR: 1.00e-05 | Throughput: 3272 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
[orchestrator] 10:14:51    INFO Orchestrator resumed: checkpoint 142 ready (after 5.01s)
Feb 15  02:14:55.622
	[default0]:10:14:55 SUCCESS Step 142 | Time: 4.40s | Loss: 0.0051 | Entropy: 0.1852 | Mismatch KL: 0.0007 | Grad. Norm: 0.0546 | LR: 1.00e-05 | Throughput: 3361 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:14:56.492
	[rank_0] 10:14:55 SUCCESS Step 142 | Time: 4.40s | Loss: 0.0051 | Entropy: 0.1852 | Mismatch KL: 0.0007 | Grad. Norm: 0.0546 | LR: 1.00e-05 | Throughput: 3361 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:15:05.495
	[orchestrator] 10:15:02 SUCCESS Step 143 | Time: 16.87s | Reward: 1.7983 | Throughput: 3993.2 tokens/s | Seq. Length: 1046.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:15:02    INFO Starting orchestrator step 144
Feb 15  02:15:07.776
	[default0]:10:15:07 SUCCESS Step 143 | Time: 11.42s | Loss: 0.0000 | Entropy: 0.1428 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3412 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:15:08.497
	[rank_0] 10:15:07 SUCCESS Step 143 | Time: 11.42s | Loss: 0.0000 | Entropy: 0.1428 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3412 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:15:20.502
	[orchestrator] 10:15:19 SUCCESS Step 144 | Time: 16.59s | Reward: 1.7989 | Throughput: 3916.5 tokens/s | Seq. Length: 1009.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:15:19    INFO Starting orchestrator step 145
Feb 15  02:15:22.951
	[default0]:10:15:22 SUCCESS Step 144 | Time: 14.53s | Loss: -0.0000 | Entropy: 0.1348 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3346 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:15:23.503
	[rank_0] 10:15:22 SUCCESS Step 144 | Time: 14.53s | Loss: -0.0000 | Entropy: 0.1348 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3346 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:15:38.510
	[orchestrator] 10:15:36 SUCCESS Step 145 | Time: 17.01s | Reward: 1.7681 | Throughput: 3721.4 tokens/s | Seq. Length: 983.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:15:36    INFO Starting orchestrator step 146
Feb 15  02:15:40.228
	[default0]:10:15:40 SUCCESS Step 145 | Time: 16.59s | Loss: 0.0019 | Entropy: 0.1380 | Mismatch KL: 0.0006 | Grad. Norm: 0.0146 | LR: 1.00e-05 | Throughput: 3285 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:15:41.512
	[rank_0] 10:15:40 SUCCESS Step 145 | Time: 16.59s | Loss: 0.0019 | Entropy: 0.1380 | Mismatch KL: 0.0006 | Grad. Norm: 0.0146 | LR: 1.00e-05 | Throughput: 3285 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:15:53.516
	[orchestrator] 10:15:53 SUCCESS Step 146 | Time: 16.89s | Reward: 1.7421 | Throughput: 4036.7 tokens/s | Seq. Length: 1058.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:15:53    INFO Starting orchestrator step 147
Feb 15  02:15:58.322
	[default0]:10:15:58 SUCCESS Step 146 | Time: 17.33s | Loss: -0.0007 | Entropy: 0.1553 | Mismatch KL: 0.0005 | Grad. Norm: 0.0160 | LR: 1.00e-05 | Throughput: 3257 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:15:59.520
	[rank_0] 10:15:58 SUCCESS Step 146 | Time: 17.33s | Loss: -0.0007 | Entropy: 0.1553 | Mismatch KL: 0.0005 | Grad. Norm: 0.0160 | LR: 1.00e-05 | Throughput: 3257 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:16:11.525
	[orchestrator] 10:16:10 SUCCESS Step 147 | Time: 17.21s | Reward: 1.7460 | Throughput: 4095.9 tokens/s | Seq. Length: 1093.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:16:10    INFO Starting orchestrator step 148
Feb 15  02:16:15.504
	[default0]:10:16:15 SUCCESS Step 147 | Time: 16.47s | Loss: 0.0027 | Entropy: 0.1715 | Mismatch KL: 0.0006 | Grad. Norm: 0.0135 | LR: 1.00e-05 | Throughput: 3191 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  02:16:17.529
	[rank_0] 10:16:15 SUCCESS Step 147 | Time: 16.47s | Loss: 0.0027 | Entropy: 0.1715 | Mismatch KL: 0.0006 | Grad. Norm: 0.0135 | LR: 1.00e-05 | Throughput: 3191 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  02:16:29.533
	[orchestrator] 10:16:27 SUCCESS Step 148 | Time: 16.76s | Reward: 1.7993 | Throughput: 4005.5 tokens/s | Seq. Length: 1042.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:16:27    INFO Starting orchestrator step 149
Feb 15  02:16:31.583
	[default0]:10:16:31 SUCCESS Step 148 | Time: 15.41s | Loss: 0.0000 | Entropy: 0.1343 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3199 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:16:32.535
	[rank_0] 10:16:31 SUCCESS Step 148 | Time: 15.41s | Loss: 0.0000 | Entropy: 0.1343 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3199 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:16:47.542
	[orchestrator] 10:16:44 SUCCESS Step 149 | Time: 17.47s | Reward: 1.7148 | Throughput: 3977.3 tokens/s | Seq. Length: 1078.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:16:44    INFO Saving checkpoint at step 150
[orchestrator] 10:16:44    INFO Starting orchestrator step 150
Feb 15  02:16:49.671
	[default0]:10:16:49 SUCCESS Step 149 | Time: 17.44s | Loss: 0.0014 | Entropy: 0.1623 | Mismatch KL: 0.0005 | Grad. Norm: 0.0175 | LR: 1.00e-05 | Throughput: 6341 tokens/s | MFU: 7.0% | Peak Mem.: 44.7 GiB
Feb 15  02:16:50.374
	[default0]:10:16:50    INFO Saving checkpoint at step 150
Feb 15  02:16:50.545
	[rank_0] 10:16:49 SUCCESS Step 149 | Time: 17.44s | Loss: 0.0014 | Entropy: 0.1623 | Mismatch KL: 0.0005 | Grad. Norm: 0.0175 | LR: 1.00e-05 | Throughput: 6341 tokens/s | MFU: 7.0% | Peak Mem.: 44.7 GiB
[rank_0] 10:16:50    INFO Saving checkpoint at step 150
Feb 15  02:17:02.551
	[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:01 WARNING No trajectory steps for example 8. Skipping rollout.
[orchestrator] 10:17:02    INFO Logging samples to W&B table at step 150
[orchestrator] 10:17:02 SUCCESS Step 150 | Time: 17.25s | Reward: 1.3190 | Throughput: 2986.5 tokens/s | Seq. Length: 799.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:17:02    INFO Starting orchestrator step 151
Feb 15  02:17:20.559
	[orchestrator] 10:17:19 SUCCESS Step 151 | Time: 17.00s | Reward: 1.7176 | Throughput: 4097.0 tokens/s | Seq. Length: 1075.0 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:17:19    INFO Starting orchestrator step 152
[orchestrator] 10:17:19    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 151 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:17:37.206
	[default0]:10:17:37    INFO Saving weight checkpoint at step 150
Feb 15  02:17:38.571
	[rank_0] 10:17:37    INFO Saving weight checkpoint at step 150
Feb 15  02:18:58.975
	[default0]:10:18:58 SUCCESS Step 150 | Time: 3.80s | Loss: 0.0017 | Entropy: 0.1663 | Mismatch KL: 0.0005 | Grad. Norm: 0.0121 | LR: 1.00e-05 | Throughput: 3117 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  02:18:59.069
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:19:00.110
	[rank_0] 10:18:58 SUCCESS Step 150 | Time: 3.80s | Loss: 0.0017 | Entropy: 0.1663 | Mismatch KL: 0.0005 | Grad. Norm: 0.0121 | LR: 1.00e-05 | Throughput: 3117 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  02:19:03.111
	[orchestrator] 10:19:01    INFO Orchestrator resumed: checkpoint 151 ready (after 101.99s)
[orchestrator] 10:19:01 SUCCESS Step 152 | Time: 102.33s | Reward: 1.7989 | Throughput: 632.3 tokens/s | Seq. Length: 1009.8 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:19:01    INFO Starting orchestrator step 153
[orchestrator] 10:19:02    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 152 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:19:05.008
	[default0]:10:19:04 SUCCESS Step 151 | Time: 4.90s | Loss: -0.0013 | Entropy: 0.1462 | Mismatch KL: 0.0005 | Grad. Norm: 0.0180 | LR: 1.00e-05 | Throughput: 3091 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  02:19:06.112
	[rank_0] 10:19:04 SUCCESS Step 151 | Time: 4.90s | Loss: -0.0013 | Entropy: 0.1462 | Mismatch KL: 0.0005 | Grad. Norm: 0.0180 | LR: 1.00e-05 | Throughput: 3091 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  02:19:09.114
	[orchestrator] 10:19:06    INFO Orchestrator resumed: checkpoint 152 ready (after 4.01s)
Feb 15  02:19:10.231
	[default0]:10:19:10 SUCCESS Step 152 | Time: 4.43s | Loss: 0.0000 | Entropy: 0.1441 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3197 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:19:12.115
	[rank_0] 10:19:10 SUCCESS Step 152 | Time: 4.43s | Loss: 0.0000 | Entropy: 0.1441 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3197 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:19:21.210
	[orchestrator] 10:19:18 SUCCESS Step 153 | Time: 16.89s | Reward: 1.7958 | Throughput: 3889.3 tokens/s | Seq. Length: 1019.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:19:18    INFO Starting orchestrator step 154
Feb 15  02:19:23.392
	[default0]:10:19:23 SUCCESS Step 153 | Time: 12.50s | Loss: -0.0003 | Entropy: 0.1446 | Mismatch KL: 0.0005 | Grad. Norm: 0.0021 | LR: 1.00e-05 | Throughput: 3324 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:19:24.212
	[rank_0] 10:19:23 SUCCESS Step 153 | Time: 12.50s | Loss: -0.0003 | Entropy: 0.1446 | Mismatch KL: 0.0005 | Grad. Norm: 0.0021 | LR: 1.00e-05 | Throughput: 3324 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:19:36.218
	[orchestrator] 10:19:35 SUCCESS Step 154 | Time: 17.38s | Reward: 1.4618 | Throughput: 3844.9 tokens/s | Seq. Length: 1037.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:19:35    INFO Starting orchestrator step 155
Feb 15  02:19:40.583
	[default0]:10:19:40 SUCCESS Step 154 | Time: 16.48s | Loss: -0.0000 | Entropy: 0.1944 | Mismatch KL: 0.0005 | Grad. Norm: 0.0240 | LR: 1.00e-05 | Throughput: 3420 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:19:42.221
	[rank_0] 10:19:40 SUCCESS Step 154 | Time: 16.48s | Loss: -0.0000 | Entropy: 0.1944 | Mismatch KL: 0.0005 | Grad. Norm: 0.0240 | LR: 1.00e-05 | Throughput: 3420 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:19:54.226
	[orchestrator] 10:19:52 SUCCESS Step 155 | Time: 16.83s | Reward: 1.7713 | Throughput: 3938.7 tokens/s | Seq. Length: 1029.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:19:52    INFO Starting orchestrator step 156
Feb 15  02:19:57.767
	[default0]:10:19:57 SUCCESS Step 155 | Time: 16.46s | Loss: -0.0021 | Entropy: 0.1582 | Mismatch KL: 0.0005 | Grad. Norm: 0.0157 | LR: 1.00e-05 | Throughput: 3439 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:20:00.234
	[rank_0] 10:19:57 SUCCESS Step 155 | Time: 16.46s | Loss: -0.0021 | Entropy: 0.1582 | Mismatch KL: 0.0005 | Grad. Norm: 0.0157 | LR: 1.00e-05 | Throughput: 3439 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:20:12.238
	[orchestrator] 10:20:09 SUCCESS Step 156 | Time: 16.83s | Reward: 1.7148 | Throughput: 4064.7 tokens/s | Seq. Length: 1062.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:20:09    INFO Starting orchestrator step 157
Feb 15  02:20:13.845
	[default0]:10:20:13 SUCCESS Step 156 | Time: 15.45s | Loss: -0.0010 | Entropy: 0.1787 | Mismatch KL: 0.0005 | Grad. Norm: 0.0208 | LR: 1.00e-05 | Throughput: 3534 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:20:15.239
	[rank_0] 10:20:13 SUCCESS Step 156 | Time: 15.45s | Loss: -0.0010 | Entropy: 0.1787 | Mismatch KL: 0.0005 | Grad. Norm: 0.0208 | LR: 1.00e-05 | Throughput: 3534 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:20:27.244
	[orchestrator] 10:20:25 SUCCESS Step 157 | Time: 16.57s | Reward: 1.7429 | Throughput: 3965.9 tokens/s | Seq. Length: 1020.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:20:25    INFO Starting orchestrator step 158
Feb 15  02:20:30.938
	[default0]:10:20:30 SUCCESS Step 157 | Time: 16.46s | Loss: -0.0012 | Entropy: 0.1638 | Mismatch KL: 0.0005 | Grad. Norm: 0.0206 | LR: 1.00e-05 | Throughput: 3504 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:20:33.250
	[rank_0] 10:20:30 SUCCESS Step 157 | Time: 16.46s | Loss: -0.0012 | Entropy: 0.1638 | Mismatch KL: 0.0005 | Grad. Norm: 0.0206 | LR: 1.00e-05 | Throughput: 3504 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:20:45.256
	[orchestrator] 10:20:42 SUCCESS Step 158 | Time: 16.50s | Reward: 1.7398 | Throughput: 3971.4 tokens/s | Seq. Length: 1017.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:20:42    INFO Starting orchestrator step 159
Feb 15  02:20:47.215
	[default0]:10:20:47 SUCCESS Step 158 | Time: 15.50s | Loss: -0.0026 | Entropy: 0.1629 | Mismatch KL: 0.0005 | Grad. Norm: 0.0204 | LR: 1.00e-05 | Throughput: 3529 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:20:48.257
	[rank_0] 10:20:47 SUCCESS Step 158 | Time: 15.50s | Loss: -0.0026 | Entropy: 0.1629 | Mismatch KL: 0.0005 | Grad. Norm: 0.0204 | LR: 1.00e-05 | Throughput: 3529 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:21:00.268
	[orchestrator] 10:20:58 SUCCESS Step 159 | Time: 16.38s | Reward: 1.7985 | Throughput: 4073.2 tokens/s | Seq. Length: 1035.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:20:58    INFO Saving checkpoint at step 160
[orchestrator] 10:20:58    INFO Starting orchestrator step 160
Feb 15  02:21:03.265
	[rank_0] 10:21:03 SUCCESS Step 159 | Time: 15.39s | Loss: -0.0000 | Entropy: 0.1719 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 6926 tokens/s | MFU: 7.7% | Peak Mem.: 44.7 GiB
Feb 15  02:21:03.295
	[default0]:10:21:03 SUCCESS Step 159 | Time: 15.39s | Loss: -0.0000 | Entropy: 0.1719 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 6926 tokens/s | MFU: 7.7% | Peak Mem.: 44.7 GiB
Feb 15  02:21:03.900
	[default0]:10:21:03    INFO Saving checkpoint at step 160
Feb 15  02:21:06.266
	[rank_0] 10:21:03    INFO Saving checkpoint at step 160
Feb 15  02:21:18.271
	[orchestrator] 10:21:15    INFO Logging samples to W&B table at step 160
[orchestrator] 10:21:15 SUCCESS Step 160 | Time: 16.73s | Reward: 1.7995 | Throughput: 4028.1 tokens/s | Seq. Length: 1046.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:21:15    INFO Starting orchestrator step 161
Feb 15  02:21:33.280
	[orchestrator] 10:21:31 SUCCESS Step 161 | Time: 16.21s | Reward: 1.7920 | Throughput: 4097.2 tokens/s | Seq. Length: 1030.0 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:21:31    INFO Starting orchestrator step 162
[orchestrator] 10:21:31    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 161 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:21:49.429
	[default0]:10:21:49    INFO Saving weight checkpoint at step 160
Feb 15  02:21:51.290
	[rank_0] 10:21:49    INFO Saving weight checkpoint at step 160
Feb 15  02:23:18.256
	[default0]:10:23:18 SUCCESS Step 160 | Time: 4.65s | Loss: 0.0000 | Entropy: 0.1500 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3419 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:23:18.282
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:23:18.931
	[rank_0] 10:23:18 SUCCESS Step 160 | Time: 4.65s | Loss: 0.0000 | Entropy: 0.1500 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3419 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:23:21.933
	[orchestrator] 10:23:19    INFO Orchestrator resumed: checkpoint 161 ready (after 107.29s)
[orchestrator] 10:23:19 SUCCESS Step 162 | Time: 107.69s | Reward: 1.7991 | Throughput: 608.1 tokens/s | Seq. Length: 1022.2 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:23:19    INFO Starting orchestrator step 163
[orchestrator] 10:23:20    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 162 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:23:23.377
	[default0]:10:23:23 SUCCESS Step 161 | Time: 4.43s | Loss: 0.0001 | Entropy: 0.1798 | Mismatch KL: 0.0004 | Grad. Norm: 0.0014 | LR: 1.00e-05 | Throughput: 3413 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:23:24.935
	[rank_0] 10:23:23 SUCCESS Step 161 | Time: 4.43s | Loss: 0.0001 | Entropy: 0.1798 | Mismatch KL: 0.0004 | Grad. Norm: 0.0014 | LR: 1.00e-05 | Throughput: 3413 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
[orchestrator] 10:23:24    INFO Orchestrator resumed: checkpoint 162 ready (after 4.01s)
Feb 15  02:23:28.899
	[default0]:10:23:28 SUCCESS Step 162 | Time: 4.86s | Loss: -0.0000 | Entropy: 0.1431 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3516 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:23:30.939
	[rank_0] 10:23:28 SUCCESS Step 162 | Time: 4.86s | Loss: -0.0000 | Entropy: 0.1431 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3516 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:23:36.942
	[orchestrator] 10:23:36 SUCCESS Step 163 | Time: 16.81s | Reward: 1.7683 | Throughput: 3952.5 tokens/s | Seq. Length: 1032.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:23:36    INFO Starting orchestrator step 164
Feb 15  02:23:41.462
	[default0]:10:23:41 SUCCESS Step 163 | Time: 11.80s | Loss: 0.0004 | Entropy: 0.1418 | Mismatch KL: 0.0004 | Grad. Norm: 0.0085 | LR: 1.00e-05 | Throughput: 3590 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:23:42.944
	[rank_0] 10:23:41 SUCCESS Step 163 | Time: 11.80s | Loss: 0.0004 | Entropy: 0.1418 | Mismatch KL: 0.0004 | Grad. Norm: 0.0085 | LR: 1.00e-05 | Throughput: 3590 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:23:54.951
	[orchestrator] 10:23:53 SUCCESS Step 164 | Time: 17.07s | Reward: 1.7989 | Throughput: 3727.4 tokens/s | Seq. Length: 988.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:23:53    INFO Starting orchestrator step 165
Feb 15  02:23:57.650
	[default0]:10:23:57 SUCCESS Step 164 | Time: 15.50s | Loss: -0.0000 | Entropy: 0.1551 | Mismatch KL: 0.0006 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3511 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:23:57.952
	[rank_0] 10:23:57 SUCCESS Step 164 | Time: 15.50s | Loss: -0.0000 | Entropy: 0.1551 | Mismatch KL: 0.0006 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3511 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:24:12.960
	[orchestrator] 10:24:10 SUCCESS Step 165 | Time: 17.06s | Reward: 1.7422 | Throughput: 3827.5 tokens/s | Seq. Length: 1013.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:24:10    INFO Starting orchestrator step 166
Feb 15  02:24:14.835
	[default0]:10:24:14 SUCCESS Step 165 | Time: 16.44s | Loss: -0.0027 | Entropy: 0.1451 | Mismatch KL: 0.0004 | Grad. Norm: 0.0173 | LR: 1.00e-05 | Throughput: 3487 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:24:15.962
	[rank_0] 10:24:14 SUCCESS Step 165 | Time: 16.44s | Loss: -0.0027 | Entropy: 0.1451 | Mismatch KL: 0.0004 | Grad. Norm: 0.0173 | LR: 1.00e-05 | Throughput: 3487 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:24:27.966
	[orchestrator] 10:24:27 SUCCESS Step 166 | Time: 16.78s | Reward: 1.7927 | Throughput: 3889.7 tokens/s | Seq. Length: 1013.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:24:27    INFO Starting orchestrator step 167
Feb 15  02:24:32.013
	[default0]:10:24:31 SUCCESS Step 166 | Time: 16.46s | Loss: -0.0001 | Entropy: 0.1728 | Mismatch KL: 0.0005 | Grad. Norm: 0.0024 | LR: 1.00e-05 | Throughput: 3494 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:24:33.969
	[rank_0] 10:24:31 SUCCESS Step 166 | Time: 16.46s | Loss: -0.0001 | Entropy: 0.1728 | Mismatch KL: 0.0005 | Grad. Norm: 0.0024 | LR: 1.00e-05 | Throughput: 3494 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:24:45.973
	[orchestrator] 10:24:44 SUCCESS Step 167 | Time: 16.84s | Reward: 1.7990 | Throughput: 3792.6 tokens/s | Seq. Length: 991.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:24:44    INFO Starting orchestrator step 168
Feb 15  02:24:48.091
	[default0]:10:24:48 SUCCESS Step 167 | Time: 15.48s | Loss: 0.0000 | Entropy: 0.1362 | Mismatch KL: 0.0006 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3387 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:24:48.974
	[rank_0] 10:24:48 SUCCESS Step 167 | Time: 15.48s | Loss: 0.0000 | Entropy: 0.1362 | Mismatch KL: 0.0006 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3387 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:25:00.980
	[orchestrator] 10:25:00 SUCCESS Step 168 | Time: 16.57s | Reward: 1.7991 | Throughput: 3899.5 tokens/s | Seq. Length: 1003.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:25:00    INFO Starting orchestrator step 169
Feb 15  02:25:05.291
	[default0]:10:25:05 SUCCESS Step 168 | Time: 16.50s | Loss: -0.0000 | Entropy: 0.1261 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3378 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:25:06.983
	[rank_0] 10:25:05 SUCCESS Step 168 | Time: 16.50s | Loss: -0.0000 | Entropy: 0.1261 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3378 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:25:18.988
	[orchestrator] 10:25:17 SUCCESS Step 169 | Time: 17.06s | Reward: 1.7987 | Throughput: 3818.6 tokens/s | Seq. Length: 1012.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:25:17    INFO Saving checkpoint at step 170
[orchestrator] 10:25:17    INFO Starting orchestrator step 170
Feb 15  02:25:22.380
	[default0]:10:25:22 SUCCESS Step 169 | Time: 16.36s | Loss: 0.0000 | Entropy: 0.1214 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 6572 tokens/s | MFU: 7.3% | Peak Mem.: 44.7 GiB
Feb 15  02:25:23.085
	[default0]:10:25:22    INFO Saving checkpoint at step 170
Feb 15  02:25:24.992
	[rank_0] 10:25:22 SUCCESS Step 169 | Time: 16.36s | Loss: 0.0000 | Entropy: 0.1214 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 6572 tokens/s | MFU: 7.3% | Peak Mem.: 44.7 GiB
[rank_0] 10:25:22    INFO Saving checkpoint at step 170
Feb 15  02:25:36.998
	[orchestrator] 10:25:35    INFO Logging samples to W&B table at step 170
[orchestrator] 10:25:35 SUCCESS Step 170 | Time: 17.22s | Reward: 1.7992 | Throughput: 3990.7 tokens/s | Seq. Length: 1066.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:25:35    INFO Starting orchestrator step 171
Feb 15  02:25:52.003
	[orchestrator] 10:25:51 SUCCESS Step 171 | Time: 16.84s | Reward: 1.7152 | Throughput: 3953.8 tokens/s | Seq. Length: 1033.2 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:25:51    INFO Starting orchestrator step 172
Feb 15  02:25:55.006
	[orchestrator] 10:25:52    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 171 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:26:09.824
	[default0]:10:26:09    INFO Saving weight checkpoint at step 170
Feb 15  02:26:10.013
	[rank_0] 10:26:09    INFO Saving weight checkpoint at step 170
Feb 15  02:27:36.580
	[default0]:10:27:36 SUCCESS Step 170 | Time: 4.76s | Loss: -0.0000 | Entropy: 0.1446 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3220 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:27:36.617
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:27:37.855
	[rank_0] 10:27:36 SUCCESS Step 170 | Time: 4.76s | Loss: -0.0000 | Entropy: 0.1446 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3220 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
[orchestrator] 10:27:37    INFO Orchestrator resumed: checkpoint 171 ready (after 105.12s)
Feb 15  02:27:40.857
	[orchestrator] 10:27:38 SUCCESS Step 172 | Time: 106.14s | Reward: 1.7963 | Throughput: 625.0 tokens/s | Seq. Length: 1035.3 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:27:38    INFO Starting orchestrator step 173
[orchestrator] 10:27:38    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 172 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:27:41.801
	[default0]:10:27:41 SUCCESS Step 171 | Time: 4.52s | Loss: 0.0009 | Entropy: 0.1593 | Mismatch KL: 0.0004 | Grad. Norm: 0.0169 | LR: 1.00e-05 | Throughput: 3228 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:27:43.859
	[rank_0] 10:27:41 SUCCESS Step 171 | Time: 4.52s | Loss: 0.0009 | Entropy: 0.1593 | Mismatch KL: 0.0004 | Grad. Norm: 0.0169 | LR: 1.00e-05 | Throughput: 3228 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
[orchestrator] 10:27:42    INFO Orchestrator resumed: checkpoint 172 ready (after 4.01s)
Feb 15  02:27:46.921
	[default0]:10:27:46 SUCCESS Step 172 | Time: 4.39s | Loss: -0.0002 | Entropy: 0.1389 | Mismatch KL: 0.0005 | Grad. Norm: 0.0013 | LR: 1.00e-05 | Throughput: 3322 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:27:49.862
	[rank_0] 10:27:46 SUCCESS Step 172 | Time: 4.39s | Loss: -0.0002 | Entropy: 0.1389 | Mismatch KL: 0.0005 | Grad. Norm: 0.0013 | LR: 1.00e-05 | Throughput: 3322 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:27:55.865
	[orchestrator] 10:27:54 SUCCESS Step 173 | Time: 16.60s | Reward: 1.3765 | Throughput: 3901.5 tokens/s | Seq. Length: 1004.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:27:54    INFO Starting orchestrator step 174
Feb 15  02:27:59.078
	[default0]:10:27:59 SUCCESS Step 173 | Time: 11.19s | Loss: -0.0003 | Entropy: 0.1966 | Mismatch KL: 0.0005 | Grad. Norm: 0.0210 | LR: 1.00e-05 | Throughput: 3467 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:28:01.867
	[rank_0] 10:27:59 SUCCESS Step 173 | Time: 11.19s | Loss: -0.0003 | Entropy: 0.1966 | Mismatch KL: 0.0005 | Grad. Norm: 0.0210 | LR: 1.00e-05 | Throughput: 3467 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  02:28:13.874
	[orchestrator] 10:28:11 SUCCESS Step 174 | Time: 16.49s | Reward: 1.7714 | Throughput: 3978.8 tokens/s | Seq. Length: 1018.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:28:11    INFO Starting orchestrator step 175
Feb 15  02:28:16.262
	[default0]:10:28:16 SUCCESS Step 174 | Time: 16.31s | Loss: -0.0004 | Entropy: 0.1325 | Mismatch KL: 0.0004 | Grad. Norm: 0.0107 | LR: 1.00e-05 | Throughput: 3462 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:28:16.875
	[rank_0] 10:28:16 SUCCESS Step 174 | Time: 16.31s | Loss: -0.0004 | Entropy: 0.1325 | Mismatch KL: 0.0004 | Grad. Norm: 0.0107 | LR: 1.00e-05 | Throughput: 3462 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:28:28.879
	[orchestrator] 10:28:28 SUCCESS Step 175 | Time: 17.03s | Reward: 1.7704 | Throughput: 3837.5 tokens/s | Seq. Length: 1015.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:28:28    INFO Starting orchestrator step 176
Feb 15  02:28:33.348
	[default0]:10:28:33 SUCCESS Step 175 | Time: 16.47s | Loss: 0.0002 | Entropy: 0.1451 | Mismatch KL: 0.0004 | Grad. Norm: 0.0060 | LR: 1.00e-05 | Throughput: 3457 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:28:34.881
	[rank_0] 10:28:33 SUCCESS Step 175 | Time: 16.47s | Loss: 0.0002 | Entropy: 0.1451 | Mismatch KL: 0.0004 | Grad. Norm: 0.0060 | LR: 1.00e-05 | Throughput: 3457 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:28:46.887
	[orchestrator] 10:28:45 SUCCESS Step 176 | Time: 17.09s | Reward: 1.7430 | Throughput: 3812.7 tokens/s | Seq. Length: 1011.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:28:45    INFO Starting orchestrator step 177
Feb 15  02:28:50.529
	[default0]:10:28:50 SUCCESS Step 176 | Time: 16.48s | Loss: -0.0016 | Entropy: 0.1543 | Mismatch KL: 0.0004 | Grad. Norm: 0.0203 | LR: 1.00e-05 | Throughput: 3554 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:28:52.889
	[rank_0] 10:28:50 SUCCESS Step 176 | Time: 16.48s | Loss: -0.0016 | Entropy: 0.1543 | Mismatch KL: 0.0004 | Grad. Norm: 0.0203 | LR: 1.00e-05 | Throughput: 3554 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:29:04.895
	[orchestrator] 10:29:02 SUCCESS Step 177 | Time: 16.71s | Reward: 1.7447 | Throughput: 4021.3 tokens/s | Seq. Length: 1043.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:29:02    INFO Starting orchestrator step 178
Feb 15  02:29:06.606
	[default0]:10:29:06 SUCCESS Step 177 | Time: 15.45s | Loss: 0.0001 | Entropy: 0.1292 | Mismatch KL: 0.0004 | Grad. Norm: 0.0133 | LR: 1.00e-05 | Throughput: 3578 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:29:07.901
	[rank_0] 10:29:06 SUCCESS Step 177 | Time: 15.45s | Loss: 0.0001 | Entropy: 0.1292 | Mismatch KL: 0.0004 | Grad. Norm: 0.0133 | LR: 1.00e-05 | Throughput: 3578 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:29:19.905
	[orchestrator] 10:29:18 SUCCESS Step 178 | Time: 16.56s | Reward: 1.7989 | Throughput: 3877.6 tokens/s | Seq. Length: 996.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:29:18    INFO Starting orchestrator step 179
Feb 15  02:29:23.797
	[default0]:10:29:23 SUCCESS Step 178 | Time: 16.47s | Loss: -0.0000 | Entropy: 0.1570 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3586 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:29:25.907
	[rank_0] 10:29:23 SUCCESS Step 178 | Time: 16.47s | Loss: -0.0000 | Entropy: 0.1570 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3586 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:29:37.912
	[orchestrator] 10:29:35 SUCCESS Step 179 | Time: 16.65s | Reward: 1.7993 | Throughput: 4121.9 tokens/s | Seq. Length: 1065.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:29:35    INFO Saving checkpoint at step 180
[orchestrator] 10:29:35    INFO Starting orchestrator step 180
Feb 15  02:29:40.371
	[default0]:10:29:40 SUCCESS Step 179 | Time: 15.89s | Loss: -0.0000 | Entropy: 0.1471 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 7010 tokens/s | MFU: 7.8% | Peak Mem.: 44.7 GiB
Feb 15  02:29:40.914
	[rank_0] 10:29:40 SUCCESS Step 179 | Time: 15.89s | Loss: -0.0000 | Entropy: 0.1471 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 7010 tokens/s | MFU: 7.8% | Peak Mem.: 44.7 GiB
Feb 15  02:29:41.074
	[default0]:10:29:40    INFO Saving checkpoint at step 180
Feb 15  02:29:43.916
	[rank_0] 10:29:40    INFO Saving checkpoint at step 180
Feb 15  02:30:04.925
	[orchestrator] 10:30:04    INFO Logging samples to W&B table at step 180
[orchestrator] 10:30:04 SUCCESS Step 180 | Time: 29.14s | Reward: 1.3773 | Throughput: 2348.1 tokens/s | Seq. Length: 1065.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:30:04    INFO Starting orchestrator step 181
Feb 15  02:30:25.936
	[orchestrator] 10:30:23 SUCCESS Step 181 | Time: 18.84s | Reward: 1.7995 | Throughput: 3475.5 tokens/s | Seq. Length: 1016.6 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 1
[orchestrator] 10:30:23    INFO Starting orchestrator step 182
[orchestrator] 10:30:23    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 181 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:30:36.968
	[default0]:10:30:36    INFO Saving weight checkpoint at step 180
Feb 15  02:30:37.942
	[rank_0] 10:30:36    INFO Saving weight checkpoint at step 180
Feb 15  02:32:04.289
	[default0]:10:32:04 SUCCESS Step 180 | Time: 4.56s | Loss: -0.0002 | Entropy: 0.1976 | Mismatch KL: 0.0005 | Grad. Norm: 0.0100 | LR: 1.00e-05 | Throughput: 3290 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:32:05.308
	[rank_0] 10:32:04 SUCCESS Step 180 | Time: 4.56s | Loss: -0.0002 | Entropy: 0.1976 | Mismatch KL: 0.0005 | Grad. Norm: 0.0100 | LR: 1.00e-05 | Throughput: 3290 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
[orchestrator] 10:32:04    INFO Orchestrator resumed: checkpoint 181 ready (after 101.14s)
[orchestrator] 10:32:05 SUCCESS Step 182 | Time: 101.78s | Reward: 1.7992 | Throughput: 650.7 tokens/s | Seq. Length: 1033.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 2
[orchestrator] 10:32:05    INFO Starting orchestrator step 183
Feb 15  02:32:08.309
	[orchestrator] 10:32:06    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 182 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:32:09.412
	[default0]:10:32:09 SUCCESS Step 181 | Time: 4.45s | Loss: -0.0000 | Entropy: 0.1448 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3290 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:32:11.311
	[rank_0] 10:32:09 SUCCESS Step 181 | Time: 4.45s | Loss: -0.0000 | Entropy: 0.1448 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3290 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
[orchestrator] 10:32:10    INFO Orchestrator resumed: checkpoint 182 ready (after 4.01s)
Feb 15  02:32:14.438
	[default0]:10:32:14 SUCCESS Step 182 | Time: 4.39s | Loss: 0.0000 | Entropy: 0.1336 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3391 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:32:17.313
	[rank_0] 10:32:14 SUCCESS Step 182 | Time: 4.39s | Loss: 0.0000 | Entropy: 0.1336 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3391 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:32:23.315
	[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 10:32:21 SUCCESS Step 183 | Time: 16.27s | Reward: 0.9556 | Throughput: 3135.9 tokens/s | Seq. Length: 792.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 4
[orchestrator] 10:32:21    INFO Starting orchestrator step 184
Feb 15  02:32:25.595
	[default0]:10:32:25 SUCCESS Step 183 | Time: 10.43s | Loss: -0.0028 | Entropy: 0.1725 | Mismatch KL: 0.0006 | Grad. Norm: 0.0163 | LR: 1.00e-05 | Throughput: 3376 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:32:26.317
	[rank_0] 10:32:25 SUCCESS Step 183 | Time: 10.43s | Loss: -0.0028 | Entropy: 0.1725 | Mismatch KL: 0.0006 | Grad. Norm: 0.0163 | LR: 1.00e-05 | Throughput: 3376 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:32:53.330
	[orchestrator] 10:32:52 SUCCESS Step 184 | Time: 31.44s | Reward: 1.7986 | Throughput: 2133.2 tokens/s | Seq. Length: 1044.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 5
[orchestrator] 10:32:52    INFO Starting orchestrator step 185
Feb 15  02:32:57.659
	[default0]:10:32:57 SUCCESS Step 184 | Time: 31.46s | Loss: -0.0001 | Entropy: 0.1349 | Mismatch KL: 0.0004 | Grad. Norm: 0.0005 | LR: 1.00e-05 | Throughput: 3193 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  02:32:59.334
	[rank_0] 10:32:57 SUCCESS Step 184 | Time: 31.46s | Loss: -0.0001 | Entropy: 0.1349 | Mismatch KL: 0.0004 | Grad. Norm: 0.0005 | LR: 1.00e-05 | Throughput: 3193 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  02:33:26.347
	[orchestrator] 10:33:23 SUCCESS Step 185 | Time: 30.76s | Reward: 1.7709 | Throughput: 2061.4 tokens/s | Seq. Length: 987.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 6
[orchestrator] 10:33:23    INFO Starting orchestrator step 186
Feb 15  02:33:27.945
	[default0]:10:33:27 SUCCESS Step 185 | Time: 29.51s | Loss: -0.0062 | Entropy: 0.1574 | Mismatch KL: 0.0006 | Grad. Norm: 0.0127 | LR: 1.00e-05 | Throughput: 2953 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  02:33:29.348
	[rank_0] 10:33:27 SUCCESS Step 185 | Time: 29.51s | Loss: -0.0062 | Entropy: 0.1574 | Mismatch KL: 0.0006 | Grad. Norm: 0.0127 | LR: 1.00e-05 | Throughput: 2953 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  02:34:35.734
	[orchestrator] 10:34:33 SUCCESS Step 186 | Time: 69.51s | Reward: 1.7461 | Throughput: 918.8 tokens/s | Seq. Length: 996.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 7
[orchestrator] 10:34:33    INFO Starting orchestrator step 187
Feb 15  02:34:37.794
	[default0]:10:34:37 SUCCESS Step 186 | Time: 69.08s | Loss: 0.0013 | Entropy: 0.1556 | Mismatch KL: 0.0015 | Grad. Norm: 0.0089 | LR: 1.00e-05 | Throughput: 2474 tokens/s | MFU: 2.8% | Peak Mem.: 44.7 GiB
Feb 15  02:34:38.735
	[rank_0] 10:34:37 SUCCESS Step 186 | Time: 69.08s | Loss: 0.0013 | Entropy: 0.1556 | Mismatch KL: 0.0015 | Grad. Norm: 0.0089 | LR: 1.00e-05 | Throughput: 2474 tokens/s | MFU: 2.8% | Peak Mem.: 44.7 GiB
Feb 15  02:35:46.726
	[orchestrator] 10:35:44 SUCCESS Step 187 | Time: 71.38s | Reward: 1.7710 | Throughput: 917.1 tokens/s | Seq. Length: 1021.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 8
[orchestrator] 10:35:44    INFO Starting orchestrator step 188
Feb 15  02:35:49.728
	[rank_0] 10:35:49 SUCCESS Step 187 | Time: 71.28s | Loss: 0.0006 | Entropy: 0.1469 | Mismatch KL: 0.0004 | Grad. Norm: 0.0082 | LR: 1.00e-05 | Throughput: 2122 tokens/s | MFU: 2.4% | Peak Mem.: 44.7 GiB
Feb 15  02:35:49.754
	[default0]:10:35:49 SUCCESS Step 187 | Time: 71.28s | Loss: 0.0006 | Entropy: 0.1469 | Mismatch KL: 0.0004 | Grad. Norm: 0.0082 | LR: 1.00e-05 | Throughput: 2122 tokens/s | MFU: 2.4% | Peak Mem.: 44.7 GiB
Feb 15  02:36:55.757
	[orchestrator] 10:36:53 SUCCESS Step 188 | Time: 68.78s | Reward: 1.7987 | Throughput: 928.2 tokens/s | Seq. Length: 996.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 9
[orchestrator] 10:36:53    INFO Starting orchestrator step 189
Feb 15  02:36:56.922
	[default0]:10:36:56 SUCCESS Step 188 | Time: 66.57s | Loss: -0.0000 | Entropy: 0.1636 | Mismatch KL: 0.0008 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 1815 tokens/s | MFU: 2.0% | Peak Mem.: 44.7 GiB
Feb 15  02:36:58.759
	[rank_0] 10:36:56 SUCCESS Step 188 | Time: 66.57s | Loss: -0.0000 | Entropy: 0.1636 | Mismatch KL: 0.0008 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 1815 tokens/s | MFU: 2.0% | Peak Mem.: 44.7 GiB
[orchestrator] 10:36:58 WARNING Cancelled 1 old rollout requests (will refill naturally). Consider increasing max_off_policy_steps to avoid this.
Feb 15  02:38:07.790
	[orchestrator] 10:38:05 SUCCESS Step 189 | Time: 71.94s | Reward: 1.7424 | Throughput: 869.5 tokens/s | Seq. Length: 976.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 5
[orchestrator] 10:38:05    INFO Saving checkpoint at step 190
[orchestrator] 10:38:05    INFO Starting orchestrator step 190
Feb 15  02:38:09.032
	[default0]:10:38:09 SUCCESS Step 189 | Time: 71.59s | Loss: -0.0003 | Entropy: 0.1074 | Mismatch KL: 0.0005 | Grad. Norm: 0.0232 | LR: 1.00e-05 | Throughput: 2117 tokens/s | MFU: 2.4% | Peak Mem.: 44.7 GiB
Feb 15  02:38:09.736
	[default0]:10:38:09    INFO Saving checkpoint at step 190
Feb 15  02:38:10.791
	[rank_0] 10:38:09 SUCCESS Step 189 | Time: 71.59s | Loss: -0.0003 | Entropy: 0.1074 | Mismatch KL: 0.0005 | Grad. Norm: 0.0232 | LR: 1.00e-05 | Throughput: 2117 tokens/s | MFU: 2.4% | Peak Mem.: 44.7 GiB
[rank_0] 10:38:09    INFO Saving checkpoint at step 190
Feb 15  02:38:46.809
	[orchestrator] 10:38:43    INFO Logging samples to W&B table at step 190
[orchestrator] 10:38:43 SUCCESS Step 190 | Time: 38.49s | Reward: 1.7981 | Throughput: 1772.1 tokens/s | Seq. Length: 1062.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 6
[orchestrator] 10:38:43    INFO Starting orchestrator step 191
Feb 15  02:39:02.315
	[default0]:10:39:02    INFO Saving weight checkpoint at step 190
Feb 15  02:39:04.820
	[rank_0] 10:39:02    INFO Saving weight checkpoint at step 190
Feb 15  02:39:22.827
	[orchestrator] 10:39:22 SUCCESS Step 191 | Time: 38.53s | Reward: 1.7439 | Throughput: 1715.3 tokens/s | Seq. Length: 1029.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 6
[orchestrator] 10:39:22    INFO Starting orchestrator step 192
Feb 15  02:39:25.828
	[orchestrator] 10:39:23    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 191 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:40:22.806
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:40:22.855
	[default0]:10:40:22 SUCCESS Step 190 | Time: 5.53s | Loss: -0.0000 | Entropy: 0.1553 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 1569 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
[rank_0] 10:40:22 SUCCESS Step 190 | Time: 5.53s | Loss: -0.0000 | Entropy: 0.1553 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 1569 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:40:25.858
	[orchestrator] 10:40:24    INFO Orchestrator resumed: checkpoint 191 ready (after 61.10s)
Feb 15  02:40:27.979
	[default0]:10:40:27 SUCCESS Step 191 | Time: 4.31s | Loss: 0.0009 | Entropy: 0.1374 | Mismatch KL: 0.0004 | Grad. Norm: 0.0114 | LR: 1.00e-05 | Throughput: 1569 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:40:28.859
	[rank_0] 10:40:27 SUCCESS Step 191 | Time: 4.31s | Loss: 0.0009 | Entropy: 0.1374 | Mismatch KL: 0.0004 | Grad. Norm: 0.0114 | LR: 1.00e-05 | Throughput: 1569 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:40:46.868
	[orchestrator] 10:40:45 SUCCESS Step 192 | Time: 82.63s | Reward: 1.7710 | Throughput: 769.7 tokens/s | Seq. Length: 992.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 8
[orchestrator] 10:40:45    INFO Starting orchestrator step 193
Feb 15  02:40:49.103
	[default0]:10:40:49 SUCCESS Step 192 | Time: 20.52s | Loss: -0.0023 | Entropy: 0.1565 | Mismatch KL: 0.0005 | Grad. Norm: 0.0147 | LR: 1.00e-05 | Throughput: 1543 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:40:49.869
	[rank_0] 10:40:49 SUCCESS Step 192 | Time: 20.52s | Loss: -0.0023 | Entropy: 0.1565 | Mismatch KL: 0.0005 | Grad. Norm: 0.0147 | LR: 1.00e-05 | Throughput: 1543 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:41:28.888
	[orchestrator] 10:41:26 SUCCESS Step 193 | Time: 41.87s | Reward: 1.4618 | Throughput: 1653.5 tokens/s | Seq. Length: 1078.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 9
[orchestrator] 10:41:26    INFO Starting orchestrator step 194
Feb 15  02:41:31.227
	[default0]:10:41:31 SUCCESS Step 193 | Time: 41.36s | Loss: 0.0066 | Entropy: 0.1798 | Mismatch KL: 0.0005 | Grad. Norm: 0.0778 | LR: 1.00e-05 | Throughput: 1496 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:41:31.890
	[rank_0] 10:41:31 SUCCESS Step 193 | Time: 41.36s | Loss: 0.0066 | Entropy: 0.1798 | Mismatch KL: 0.0005 | Grad. Norm: 0.0778 | LR: 1.00e-05 | Throughput: 1496 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:41:34.891
	[orchestrator] 10:41:32 WARNING Cancelled 1 old rollout requests (will refill naturally). Consider increasing max_off_policy_steps to avoid this.
Feb 15  02:42:11.210
	[orchestrator] 10:42:08 SUCCESS Step 194 | Time: 42.01s | Reward: 1.8000 | Throughput: 1527.8 tokens/s | Seq. Length: 1000.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 9
[orchestrator] 10:42:08    INFO Starting orchestrator step 195
Feb 15  02:42:12.273
	[default0]:10:42:12 SUCCESS Step 194 | Time: 40.45s | Loss: -0.0000 | Entropy: 0.1315 | Mismatch KL: 0.0005 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 1463 tokens/s | MFU: 1.6% | Peak Mem.: 44.7 GiB
Feb 15  02:42:14.212
	[rank_0] 10:42:12 SUCCESS Step 194 | Time: 40.45s | Loss: -0.0000 | Entropy: 0.1315 | Mismatch KL: 0.0005 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 1463 tokens/s | MFU: 1.6% | Peak Mem.: 44.7 GiB
[orchestrator] 10:42:13 WARNING Cancelled 1 old rollout requests (will refill naturally). Consider increasing max_off_policy_steps to avoid this.
Feb 15  02:42:53.230
	[orchestrator] 10:42:52 SUCCESS Step 195 | Time: 43.26s | Reward: 1.7992 | Throughput: 1548.2 tokens/s | Seq. Length: 1043.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:42:52    INFO Starting orchestrator step 196
Feb 15  02:42:57.504
	[default0]:10:42:57 SUCCESS Step 195 | Time: 44.39s | Loss: -0.0000 | Entropy: 0.1304 | Mismatch KL: 0.0006 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 1535 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:42:59.232
	[rank_0] 10:42:57 SUCCESS Step 195 | Time: 44.39s | Loss: -0.0000 | Entropy: 0.1304 | Mismatch KL: 0.0006 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 1535 tokens/s | MFU: 1.7% | Peak Mem.: 44.7 GiB
Feb 15  02:43:17.241
	[orchestrator] 10:43:15 SUCCESS Step 196 | Time: 22.94s | Reward: 1.7524 | Throughput: 2843.0 tokens/s | Seq. Length: 1014.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:43:15    INFO Starting orchestrator step 197
Feb 15  02:43:20.125
	[default0]:10:43:20 SUCCESS Step 196 | Time: 21.41s | Loss: -0.0018 | Entropy: 0.1468 | Mismatch KL: 0.0004 | Grad. Norm: 0.0142 | LR: 1.00e-05 | Throughput: 1707 tokens/s | MFU: 1.9% | Peak Mem.: 44.7 GiB
Feb 15  02:43:20.243
	[rank_0] 10:43:20 SUCCESS Step 196 | Time: 21.41s | Loss: -0.0018 | Entropy: 0.1468 | Mismatch KL: 0.0004 | Grad. Norm: 0.0142 | LR: 1.00e-05 | Throughput: 1707 tokens/s | MFU: 1.9% | Peak Mem.: 44.7 GiB
Feb 15  02:43:38.251
	[orchestrator] 10:43:38 SUCCESS Step 197 | Time: 22.85s | Reward: 1.7714 | Throughput: 2905.6 tokens/s | Seq. Length: 1032.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:43:38    INFO Starting orchestrator step 198
Feb 15  02:43:43.248
	[default0]:10:43:43 SUCCESS Step 197 | Time: 22.48s | Loss: -0.0012 | Entropy: 0.1243 | Mismatch KL: 0.0004 | Grad. Norm: 0.0129 | LR: 1.00e-05 | Throughput: 1951 tokens/s | MFU: 2.2% | Peak Mem.: 44.7 GiB
Feb 15  02:43:44.264
	[rank_0] 10:43:43 SUCCESS Step 197 | Time: 22.48s | Loss: -0.0012 | Entropy: 0.1243 | Mismatch KL: 0.0004 | Grad. Norm: 0.0129 | LR: 1.00e-05 | Throughput: 1951 tokens/s | MFU: 2.2% | Peak Mem.: 44.7 GiB
Feb 15  02:44:02.274
	[orchestrator] 10:44:01 SUCCESS Step 198 | Time: 23.35s | Reward: 1.7992 | Throughput: 2593.0 tokens/s | Seq. Length: 942.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:44:01    INFO Starting orchestrator step 199
Feb 15  02:44:05.470
	[default0]:10:44:05 SUCCESS Step 198 | Time: 21.54s | Loss: 0.0000 | Entropy: 0.1413 | Mismatch KL: 0.0006 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2222 tokens/s | MFU: 2.5% | Peak Mem.: 44.7 GiB
Feb 15  02:44:08.275
	[rank_0] 10:44:05 SUCCESS Step 198 | Time: 21.54s | Loss: 0.0000 | Entropy: 0.1413 | Mismatch KL: 0.0006 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2222 tokens/s | MFU: 2.5% | Peak Mem.: 44.7 GiB
Feb 15  02:44:26.285
	[orchestrator] 10:44:25 SUCCESS Step 199 | Time: 23.70s | Reward: 1.7991 | Throughput: 2825.2 tokens/s | Seq. Length: 1041.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:44:25    INFO Saving checkpoint at step 200
[orchestrator] 10:44:25    INFO Starting orchestrator step 200
Feb 15  02:44:29.498
	[default0]:10:44:29 SUCCESS Step 199 | Time: 23.36s | Loss: 0.0000 | Entropy: 0.1489 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3195 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:44:30.202
	[default0]:10:44:30    INFO Saving checkpoint at step 200
Feb 15  02:44:32.287
	[rank_0] 10:44:29 SUCCESS Step 199 | Time: 23.36s | Loss: 0.0000 | Entropy: 0.1489 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3195 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
[rank_0] 10:44:30    INFO Saving checkpoint at step 200
Feb 15  02:44:50.295
	[orchestrator] 10:44:48    INFO Logging samples to W&B table at step 200
[orchestrator] 10:44:49 SUCCESS Step 200 | Time: 23.85s | Reward: 1.7993 | Throughput: 2630.5 tokens/s | Seq. Length: 975.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:44:49    INFO Starting orchestrator step 201
Feb 15  02:45:14.670
	[orchestrator] 10:45:13 SUCCESS Step 201 | Time: 24.03s | Reward: 1.7984 | Throughput: 2787.2 tokens/s | Seq. Length: 1040.6 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:45:13    INFO Starting orchestrator step 202
[orchestrator] 10:45:13    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 201 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:45:26.403
	[default0]:10:45:26    INFO Saving weight checkpoint at step 200
Feb 15  02:45:26.676
	[rank_0] 10:45:26    INFO Saving weight checkpoint at step 200
Feb 15  02:46:44.811
	[default0]:10:46:44 SUCCESS Step 200 | Time: 4.88s | Loss: -0.0000 | Entropy: 0.1340 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2094 tokens/s | MFU: 2.3% | Peak Mem.: 44.7 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:46:47.717
	[rank_0] 10:46:44 SUCCESS Step 200 | Time: 4.88s | Loss: -0.0000 | Entropy: 0.1340 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2094 tokens/s | MFU: 2.3% | Peak Mem.: 44.7 GiB
[orchestrator] 10:46:46    INFO Orchestrator resumed: checkpoint 201 ready (after 93.10s)
[orchestrator] 10:46:46 SUCCESS Step 202 | Time: 93.48s | Reward: 1.7715 | Throughput: 690.3 tokens/s | Seq. Length: 1007.1 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 1
[orchestrator] 10:46:46    INFO Starting orchestrator step 203
[orchestrator] 10:46:47    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 202 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:46:49.834
	[default0]:10:46:49 SUCCESS Step 201 | Time: 4.19s | Loss: -0.0000 | Entropy: 0.1224 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2248 tokens/s | MFU: 2.5% | Peak Mem.: 44.7 GiB
Feb 15  02:46:50.721
	[rank_0] 10:46:49 SUCCESS Step 201 | Time: 4.19s | Loss: -0.0000 | Entropy: 0.1224 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2248 tokens/s | MFU: 2.5% | Peak Mem.: 44.7 GiB
Feb 15  02:46:53.723
	[orchestrator] 10:46:51    INFO Orchestrator resumed: checkpoint 202 ready (after 4.01s)
Feb 15  02:46:54.960
	[default0]:10:46:54 SUCCESS Step 202 | Time: 4.42s | Loss: 0.0005 | Entropy: 0.1593 | Mismatch KL: 0.0006 | Grad. Norm: 0.0086 | LR: 1.00e-05 | Throughput: 2537 tokens/s | MFU: 2.8% | Peak Mem.: 44.7 GiB
Feb 15  02:46:56.725
	[rank_0] 10:46:54 SUCCESS Step 202 | Time: 4.42s | Loss: 0.0005 | Entropy: 0.1593 | Mismatch KL: 0.0006 | Grad. Norm: 0.0086 | LR: 1.00e-05 | Throughput: 2537 tokens/s | MFU: 2.8% | Peak Mem.: 44.7 GiB
Feb 15  02:47:11.733
	[orchestrator] 10:47:11 SUCCESS Step 203 | Time: 24.84s | Reward: 1.8000 | Throughput: 2671.8 tokens/s | Seq. Length: 1032.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 2
[orchestrator] 10:47:11    INFO Starting orchestrator step 204
Feb 15  02:47:16.078
	[default0]:10:47:16 SUCCESS Step 203 | Time: 20.44s | Loss: -0.0000 | Entropy: 0.1400 | Mismatch KL: 0.0004 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 2788 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:47:17.735
	[rank_0] 10:47:16 SUCCESS Step 203 | Time: 20.44s | Loss: -0.0000 | Entropy: 0.1400 | Mismatch KL: 0.0004 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 2788 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:47:38.744
	[orchestrator] 10:47:37 SUCCESS Step 204 | Time: 26.01s | Reward: 1.7995 | Throughput: 2489.1 tokens/s | Seq. Length: 1005.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:47:37    INFO Starting orchestrator step 205
Feb 15  02:47:42.208
	[default0]:10:47:42 SUCCESS Step 204 | Time: 25.50s | Loss: -0.0000 | Entropy: 0.1622 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2968 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  02:47:44.747
	[rank_0] 10:47:42 SUCCESS Step 204 | Time: 25.50s | Loss: -0.0000 | Entropy: 0.1622 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2968 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  02:48:05.755
	[orchestrator] 10:48:03 SUCCESS Step 205 | Time: 26.26s | Reward: 1.7991 | Throughput: 2491.2 tokens/s | Seq. Length: 1018.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:48:03    INFO Starting orchestrator step 206
Feb 15  02:48:08.333
	[default0]:10:48:08 SUCCESS Step 205 | Time: 25.47s | Loss: -0.0000 | Entropy: 0.1428 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2931 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  02:48:08.757
	[rank_0] 10:48:08 SUCCESS Step 205 | Time: 25.47s | Loss: -0.0000 | Entropy: 0.1428 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2931 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  02:48:32.767
	[orchestrator] 10:48:30 SUCCESS Step 206 | Time: 26.81s | Reward: 1.7431 | Throughput: 2462.4 tokens/s | Seq. Length: 1026.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:48:30    INFO Starting orchestrator step 207
Feb 15  02:48:35.383
	[default0]:10:48:35 SUCCESS Step 206 | Time: 26.34s | Loss: -0.0010 | Entropy: 0.1231 | Mismatch KL: 0.0003 | Grad. Norm: 0.0136 | LR: 1.00e-05 | Throughput: 2888 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  02:48:35.769
	[rank_0] 10:48:35 SUCCESS Step 206 | Time: 26.34s | Loss: -0.0010 | Entropy: 0.1231 | Mismatch KL: 0.0003 | Grad. Norm: 0.0136 | LR: 1.00e-05 | Throughput: 2888 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  02:48:56.777
	[orchestrator] 10:48:56 SUCCESS Step 207 | Time: 26.23s | Reward: 1.7681 | Throughput: 2583.8 tokens/s | Seq. Length: 1054.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:48:56    INFO Starting orchestrator step 208
Feb 15  02:49:01.519
	[default0]:10:49:01 SUCCESS Step 207 | Time: 25.44s | Loss: 0.0000 | Entropy: 0.1473 | Mismatch KL: 0.0004 | Grad. Norm: 0.0110 | LR: 1.00e-05 | Throughput: 2928 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  02:49:02.781
	[rank_0] 10:49:01 SUCCESS Step 207 | Time: 25.44s | Loss: 0.0000 | Entropy: 0.1473 | Mismatch KL: 0.0004 | Grad. Norm: 0.0110 | LR: 1.00e-05 | Throughput: 2928 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  02:49:23.789
	[orchestrator] 10:49:23 SUCCESS Step 208 | Time: 26.78s | Reward: 1.7991 | Throughput: 2341.9 tokens/s | Seq. Length: 973.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:49:23    INFO Starting orchestrator step 209
Feb 15  02:49:27.753
	[default0]:10:49:27 SUCCESS Step 208 | Time: 25.50s | Loss: -0.0001 | Entropy: 0.1223 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2834 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  02:49:29.792
	[rank_0] 10:49:27 SUCCESS Step 208 | Time: 25.50s | Loss: -0.0001 | Entropy: 0.1223 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2834 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  02:49:53.807
	[orchestrator] 10:49:50 SUCCESS Step 209 | Time: 27.35s | Reward: 1.7711 | Throughput: 2436.0 tokens/s | Seq. Length: 1036.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:49:50    INFO Saving checkpoint at step 210
[orchestrator] 10:49:50    INFO Starting orchestrator step 210
Feb 15  02:49:56.203
	[default0]:10:49:56 SUCCESS Step 209 | Time: 27.77s | Loss: -0.0020 | Entropy: 0.1313 | Mismatch KL: 0.0005 | Grad. Norm: 0.0122 | LR: 1.00e-05 | Throughput: 4414 tokens/s | MFU: 4.9% | Peak Mem.: 44.7 GiB
Feb 15  02:49:56.806
	[default0]:10:49:56    INFO Saving checkpoint at step 210
[rank_0] 10:49:56 SUCCESS Step 209 | Time: 27.77s | Loss: -0.0020 | Entropy: 0.1313 | Mismatch KL: 0.0005 | Grad. Norm: 0.0122 | LR: 1.00e-05 | Throughput: 4414 tokens/s | MFU: 4.9% | Peak Mem.: 44.7 GiB
[rank_0] 10:49:56    INFO Saving checkpoint at step 210
Feb 15  02:50:17.818
	[orchestrator] 10:50:17    INFO Logging samples to W&B table at step 210
[orchestrator] 10:50:17 SUCCESS Step 210 | Time: 26.29s | Reward: 1.7992 | Throughput: 2527.3 tokens/s | Seq. Length: 1031.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 10:50:17    INFO Starting orchestrator step 211
Feb 15  02:50:44.481
	[default0]:10:50:44    INFO Saving weight checkpoint at step 210
Feb 15  02:50:44.832
	[rank_0] 10:50:44    INFO Saving weight checkpoint at step 210
[orchestrator] 10:50:44 SUCCESS Step 211 | Time: 27.00s | Reward: 1.7715 | Throughput: 2304.5 tokens/s | Seq. Length: 968.4 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:50:44    INFO Starting orchestrator step 212
[orchestrator] 10:50:44    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 211 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:52:06.796
	[default0]:10:52:06 SUCCESS Step 210 | Time: 4.36s | Loss: -0.0000 | Entropy: 0.1520 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2667 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:52:08.868
	[rank_0] 10:52:06 SUCCESS Step 210 | Time: 4.36s | Loss: -0.0000 | Entropy: 0.1520 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2667 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
[orchestrator] 10:52:07    INFO Orchestrator resumed: checkpoint 211 ready (after 83.63s)
[orchestrator] 10:52:08 SUCCESS Step 212 | Time: 84.08s | Reward: 1.4622 | Throughput: 803.7 tokens/s | Seq. Length: 1053.8 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:52:08    INFO Starting orchestrator step 213
Feb 15  02:52:11.016
	[default0]:10:52:10 SUCCESS Step 211 | Time: 3.60s | Loss: -0.0010 | Entropy: 0.1534 | Mismatch KL: 0.0007 | Grad. Norm: 0.0137 | LR: 1.00e-05 | Throughput: 2597 tokens/s | MFU: 2.9% | Peak Mem.: 44.7 GiB
Feb 15  02:52:11.870
	[rank_0] 10:52:10 SUCCESS Step 211 | Time: 3.60s | Loss: -0.0010 | Entropy: 0.1534 | Mismatch KL: 0.0007 | Grad. Norm: 0.0137 | LR: 1.00e-05 | Throughput: 2597 tokens/s | MFU: 2.9% | Peak Mem.: 44.7 GiB
[orchestrator] 10:52:09    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 212 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:52:14.872
	[orchestrator] 10:52:12    INFO Orchestrator resumed: checkpoint 212 ready (after 3.00s)
Feb 15  02:52:16.141
	[default0]:10:52:16 SUCCESS Step 212 | Time: 4.33s | Loss: -0.0003 | Entropy: 0.1505 | Mismatch KL: 0.0005 | Grad. Norm: 0.0170 | LR: 1.00e-05 | Throughput: 2727 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  02:52:17.886
	[rank_0] 10:52:16 SUCCESS Step 212 | Time: 4.33s | Loss: -0.0003 | Entropy: 0.1505 | Mismatch KL: 0.0005 | Grad. Norm: 0.0170 | LR: 1.00e-05 | Throughput: 2727 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  02:52:44.887
	[orchestrator] 10:52:42 SUCCESS Step 213 | Time: 33.86s | Reward: 1.7933 | Throughput: 1957.4 tokens/s | Seq. Length: 1032.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:52:42    INFO Starting orchestrator step 214
Feb 15  02:52:47.308
	[default0]:10:52:47 SUCCESS Step 213 | Time: 30.47s | Loss: -0.0001 | Entropy: 0.1326 | Mismatch KL: 0.0004 | Grad. Norm: 0.0026 | LR: 1.00e-05 | Throughput: 2683 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  02:52:47.888
	[rank_0] 10:52:47 SUCCESS Step 213 | Time: 30.47s | Loss: -0.0001 | Entropy: 0.1326 | Mismatch KL: 0.0004 | Grad. Norm: 0.0026 | LR: 1.00e-05 | Throughput: 2683 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  02:53:14.899
	[orchestrator] 10:53:14 SUCCESS Step 214 | Time: 32.26s | Reward: 1.7927 | Throughput: 2054.1 tokens/s | Seq. Length: 1030.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:53:14    INFO Starting orchestrator step 215
Feb 15  02:53:19.390
	[default0]:10:53:19 SUCCESS Step 214 | Time: 31.48s | Loss: -0.0003 | Entropy: 0.1573 | Mismatch KL: 0.0005 | Grad. Norm: 0.0031 | LR: 1.00e-05 | Throughput: 2626 tokens/s | MFU: 2.9% | Peak Mem.: 44.7 GiB
Feb 15  02:53:20.902
	[rank_0] 10:53:19 SUCCESS Step 214 | Time: 31.48s | Loss: -0.0003 | Entropy: 0.1573 | Mismatch KL: 0.0005 | Grad. Norm: 0.0031 | LR: 1.00e-05 | Throughput: 2626 tokens/s | MFU: 2.9% | Peak Mem.: 44.7 GiB
Feb 15  02:53:41.911
	[orchestrator] 10:53:39 SUCCESS Step 215 | Time: 25.37s | Reward: 1.7988 | Throughput: 2573.6 tokens/s | Seq. Length: 1015.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:53:39    INFO Starting orchestrator step 216
Feb 15  02:53:44.625
	[default0]:10:53:44 SUCCESS Step 215 | Time: 24.48s | Loss: -0.0000 | Entropy: 0.1303 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2655 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  02:53:44.912
	[rank_0] 10:53:44 SUCCESS Step 215 | Time: 24.48s | Loss: -0.0000 | Entropy: 0.1303 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2655 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  02:54:05.920
	[orchestrator] 10:54:04 SUCCESS Step 216 | Time: 24.60s | Reward: 1.7993 | Throughput: 2829.0 tokens/s | Seq. Length: 1080.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:54:04    INFO Starting orchestrator step 217
Feb 15  02:54:08.754
	[default0]:10:54:08 SUCCESS Step 216 | Time: 22.81s | Loss: -0.0000 | Entropy: 0.1327 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2670 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  02:54:08.921
	[rank_0] 10:54:08 SUCCESS Step 216 | Time: 22.81s | Loss: -0.0000 | Entropy: 0.1327 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2670 tokens/s | MFU: 3.0% | Peak Mem.: 44.7 GiB
Feb 15  02:54:29.930
	[orchestrator] 10:54:28 SUCCESS Step 217 | Time: 24.10s | Reward: 1.7992 | Throughput: 2703.2 tokens/s | Seq. Length: 1013.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:54:28    INFO Starting orchestrator step 218
Feb 15  02:54:34.183
	[default0]:10:54:33 SUCCESS Step 217 | Time: 24.34s | Loss: -0.0000 | Entropy: 0.1106 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2757 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:54:36.459
	[rank_0] 10:54:33 SUCCESS Step 217 | Time: 24.34s | Loss: -0.0000 | Entropy: 0.1106 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2757 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:54:55.753
	[orchestrator] 10:54:52 SUCCESS Step 218 | Time: 23.94s | Reward: 1.7678 | Throughput: 2693.1 tokens/s | Seq. Length: 995.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:54:52    INFO Starting orchestrator step 219
Feb 15  02:54:57.625
	[default0]:10:54:57 SUCCESS Step 218 | Time: 22.83s | Loss: -0.0004 | Entropy: 0.1330 | Mismatch KL: 0.0004 | Grad. Norm: 0.0089 | LR: 1.00e-05 | Throughput: 2801 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:54:58.753
	[rank_0] 10:54:57 SUCCESS Step 218 | Time: 22.83s | Loss: -0.0004 | Entropy: 0.1330 | Mismatch KL: 0.0004 | Grad. Norm: 0.0089 | LR: 1.00e-05 | Throughput: 2801 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:55:13.759
	[orchestrator] 10:55:12 SUCCESS Step 219 | Time: 20.05s | Reward: 1.7998 | Throughput: 3307.9 tokens/s | Seq. Length: 1030.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:55:12    INFO Saving checkpoint at step 220
[orchestrator] 10:55:12    INFO Starting orchestrator step 220
Feb 15  02:55:17.727
	[default0]:10:55:17 SUCCESS Step 219 | Time: 19.36s | Loss: 0.0000 | Entropy: 0.1231 | Mismatch KL: 0.0004 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 4418 tokens/s | MFU: 4.9% | Peak Mem.: 44.7 GiB
Feb 15  02:55:18.332
	[default0]:10:55:18    INFO Saving checkpoint at step 220
Feb 15  02:55:19.762
	[rank_0] 10:55:17 SUCCESS Step 219 | Time: 19.36s | Loss: 0.0000 | Entropy: 0.1231 | Mismatch KL: 0.0004 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 4418 tokens/s | MFU: 4.9% | Peak Mem.: 44.7 GiB
[rank_0] 10:55:18    INFO Saving checkpoint at step 220
Feb 15  02:55:34.769
	[orchestrator] 10:55:33    INFO Logging samples to W&B table at step 220
[orchestrator] 10:55:33 SUCCESS Step 220 | Time: 20.74s | Reward: 1.7994 | Throughput: 3273.1 tokens/s | Seq. Length: 1027.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:55:33    INFO Starting orchestrator step 221
Feb 15  02:55:52.780
	[orchestrator] 10:55:51 SUCCESS Step 221 | Time: 18.38s | Reward: 1.7712 | Throughput: 3503.4 tokens/s | Seq. Length: 1000.0 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:55:51    INFO Starting orchestrator step 222
[orchestrator] 10:55:52    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 221 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:56:04.050
	[default0]:10:56:03    INFO Saving weight checkpoint at step 220
Feb 15  02:56:04.785
	[rank_0] 10:56:03    INFO Saving weight checkpoint at step 220
Feb 15  02:57:23.380
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  02:57:23.418
	[default0]:10:57:23 SUCCESS Step 220 | Time: 5.13s | Loss: -0.0000 | Entropy: 0.1226 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2774 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:57:25.827
	[rank_0] 10:57:23 SUCCESS Step 220 | Time: 5.13s | Loss: -0.0000 | Entropy: 0.1226 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2774 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
[orchestrator] 10:57:24    INFO Orchestrator resumed: checkpoint 221 ready (after 92.15s)
[orchestrator] 10:57:24 SUCCESS Step 222 | Time: 93.06s | Reward: 1.8000 | Throughput: 718.5 tokens/s | Seq. Length: 1042.9 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:57:24    INFO Starting orchestrator step 223
[orchestrator] 10:57:25    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 222 (>1 step(s) ahead). Training is progressing normally.
Feb 15  02:57:28.543
	[default0]:10:57:28 SUCCESS Step 221 | Time: 4.45s | Loss: -0.0003 | Entropy: 0.1291 | Mismatch KL: 0.0004 | Grad. Norm: 0.0141 | LR: 1.00e-05 | Throughput: 2780 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:57:28.829
	[rank_0] 10:57:28 SUCCESS Step 221 | Time: 4.45s | Loss: -0.0003 | Entropy: 0.1291 | Mismatch KL: 0.0004 | Grad. Norm: 0.0141 | LR: 1.00e-05 | Throughput: 2780 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  02:57:31.831
	[orchestrator] 10:57:29    INFO Orchestrator resumed: checkpoint 222 ready (after 4.01s)
Feb 15  02:57:34.070
	[default0]:10:57:34 SUCCESS Step 222 | Time: 4.91s | Loss: -0.0000 | Entropy: 0.1063 | Mismatch KL: 0.0004 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3023 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  02:57:34.832
	[rank_0] 10:57:34 SUCCESS Step 222 | Time: 4.91s | Loss: -0.0000 | Entropy: 0.1063 | Mismatch KL: 0.0004 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3023 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  02:57:43.838
	[orchestrator] 10:57:42 SUCCESS Step 223 | Time: 17.19s | Reward: 1.7991 | Throughput: 3894.0 tokens/s | Seq. Length: 1038.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:57:42    INFO Starting orchestrator step 224
Feb 15  02:57:47.238
	[default0]:10:57:47 SUCCESS Step 223 | Time: 12.50s | Loss: -0.0000 | Entropy: 0.1332 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3243 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:57:49.839
	[rank_0] 10:57:47 SUCCESS Step 223 | Time: 12.50s | Loss: -0.0000 | Entropy: 0.1332 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3243 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  02:58:01.843
	[orchestrator] 10:57:59 SUCCESS Step 224 | Time: 17.12s | Reward: 1.7963 | Throughput: 3910.8 tokens/s | Seq. Length: 1036.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:57:59    INFO Starting orchestrator step 225
Feb 15  02:58:04.414
	[default0]:10:58:04 SUCCESS Step 224 | Time: 16.43s | Loss: -0.0001 | Entropy: 0.1270 | Mismatch KL: 0.0004 | Grad. Norm: 0.0015 | LR: 1.00e-05 | Throughput: 3340 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:58:04.846
	[rank_0] 10:58:04 SUCCESS Step 224 | Time: 16.43s | Loss: -0.0001 | Entropy: 0.1270 | Mismatch KL: 0.0004 | Grad. Norm: 0.0015 | LR: 1.00e-05 | Throughput: 3340 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  02:58:16.851
	[orchestrator] 10:58:16 SUCCESS Step 225 | Time: 16.85s | Reward: 1.7683 | Throughput: 3946.4 tokens/s | Seq. Length: 1032.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:58:16    INFO Starting orchestrator step 226
Feb 15  02:58:20.486
	[default0]:10:58:20 SUCCESS Step 225 | Time: 15.47s | Loss: -0.0014 | Entropy: 0.1419 | Mismatch KL: 0.0005 | Grad. Norm: 0.0151 | LR: 1.00e-05 | Throughput: 3453 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:58:22.854
	[rank_0] 10:58:20 SUCCESS Step 225 | Time: 15.47s | Loss: -0.0014 | Entropy: 0.1419 | Mismatch KL: 0.0005 | Grad. Norm: 0.0151 | LR: 1.00e-05 | Throughput: 3453 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  02:58:34.861
	[orchestrator] 10:58:33 SUCCESS Step 226 | Time: 16.94s | Reward: 1.7995 | Throughput: 3954.8 tokens/s | Seq. Length: 1037.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:58:33    INFO Starting orchestrator step 227
Feb 15  02:58:37.671
	[default0]:10:58:37 SUCCESS Step 226 | Time: 16.47s | Loss: 0.0000 | Entropy: 0.1167 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3570 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:58:37.861
	[rank_0] 10:58:37 SUCCESS Step 226 | Time: 16.47s | Loss: 0.0000 | Entropy: 0.1167 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3570 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  02:58:49.866
	[orchestrator] 10:58:49 SUCCESS Step 227 | Time: 16.75s | Reward: 1.7674 | Throughput: 3816.2 tokens/s | Seq. Length: 992.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:58:49    INFO Starting orchestrator step 228
Feb 15  02:58:54.861
	[default0]:10:58:54 SUCCESS Step 227 | Time: 16.04s | Loss: -0.0001 | Entropy: 0.1012 | Mismatch KL: 0.0003 | Grad. Norm: 0.0070 | LR: 1.00e-05 | Throughput: 3660 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  02:58:55.868
	[rank_0] 10:58:54 SUCCESS Step 227 | Time: 16.04s | Loss: -0.0001 | Entropy: 0.1012 | Mismatch KL: 0.0003 | Grad. Norm: 0.0070 | LR: 1.00e-05 | Throughput: 3660 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  02:59:07.873
	[orchestrator] 10:59:07 SUCCESS Step 228 | Time: 17.22s | Reward: 1.7429 | Throughput: 3951.6 tokens/s | Seq. Length: 1053.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:59:07    INFO Starting orchestrator step 229
Feb 15  02:59:11.941
	[default0]:10:59:11 SUCCESS Step 228 | Time: 16.45s | Loss: -0.0029 | Entropy: 0.1301 | Mismatch KL: 0.0003 | Grad. Norm: 0.0171 | LR: 1.00e-05 | Throughput: 3715 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  02:59:13.876
	[rank_0] 10:59:11 SUCCESS Step 228 | Time: 16.45s | Loss: -0.0029 | Entropy: 0.1301 | Mismatch KL: 0.0003 | Grad. Norm: 0.0171 | LR: 1.00e-05 | Throughput: 3715 tokens/s | MFU: 4.1% | Peak Mem.: 44.7 GiB
Feb 15  02:59:25.882
	[orchestrator] 10:59:23 SUCCESS Step 229 | Time: 16.69s | Reward: 1.7996 | Throughput: 3913.5 tokens/s | Seq. Length: 1014.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:59:23    INFO Saving checkpoint at step 230
[orchestrator] 10:59:23    INFO Starting orchestrator step 230
Feb 15  02:59:28.122
	[default0]:10:59:28 SUCCESS Step 229 | Time: 15.48s | Loss: -0.0000 | Entropy: 0.1062 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 6988 tokens/s | MFU: 7.8% | Peak Mem.: 44.7 GiB
Feb 15  02:59:28.725
	[default0]:10:59:28    INFO Saving checkpoint at step 230
Feb 15  02:59:28.883
	[rank_0] 10:59:28 SUCCESS Step 229 | Time: 15.48s | Loss: -0.0000 | Entropy: 0.1062 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 6988 tokens/s | MFU: 7.8% | Peak Mem.: 44.7 GiB
[rank_0] 10:59:28    INFO Saving checkpoint at step 230
Feb 15  02:59:41.015
	[orchestrator] 10:59:40    INFO Logging samples to W&B table at step 230
[orchestrator] 10:59:40 SUCCESS Step 230 | Time: 16.57s | Reward: 1.7997 | Throughput: 3956.8 tokens/s | Seq. Length: 1014.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 10:59:40    INFO Starting orchestrator step 231
Feb 15  02:59:59.022
	[orchestrator] 10:59:56 SUCCESS Step 231 | Time: 16.49s | Reward: 1.7995 | Throughput: 4092.3 tokens/s | Seq. Length: 1046.9 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 10:59:56    INFO Starting orchestrator step 232
[orchestrator] 10:59:56    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 231 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:00:23.833
	[default0]:11:00:23    INFO Saving weight checkpoint at step 230
Feb 15  03:00:26.569
	[rank_0] 11:00:23    INFO Saving weight checkpoint at step 230
Feb 15  03:01:43.209
	[default0]:11:01:43 SUCCESS Step 230 | Time: 5.14s | Loss: 0.0000 | Entropy: 0.1551 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3422 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:01:43.287
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  03:01:44.609
	[rank_0] 11:01:43 SUCCESS Step 230 | Time: 5.14s | Loss: 0.0000 | Entropy: 0.1551 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3422 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:01:47.610
	[orchestrator] 11:01:44    INFO Orchestrator resumed: checkpoint 231 ready (after 107.76s)
[orchestrator] 11:01:45 SUCCESS Step 232 | Time: 108.17s | Reward: 1.7995 | Throughput: 615.0 tokens/s | Seq. Length: 1038.0 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:01:45    INFO Starting orchestrator step 233
[orchestrator] 11:01:45    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 232 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:01:48.436
	[default0]:11:01:48 SUCCESS Step 231 | Time: 4.49s | Loss: 0.0000 | Entropy: 0.1158 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3439 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:01:50.612
	[rank_0] 11:01:48 SUCCESS Step 231 | Time: 4.49s | Loss: 0.0000 | Entropy: 0.1158 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3439 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
[orchestrator] 11:01:49    INFO Orchestrator resumed: checkpoint 232 ready (after 4.01s)
Feb 15  03:01:53.463
	[default0]:11:01:53 SUCCESS Step 232 | Time: 4.43s | Loss: -0.0000 | Entropy: 0.1356 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3545 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:01:53.613
	[rank_0] 11:01:53 SUCCESS Step 232 | Time: 4.43s | Loss: -0.0000 | Entropy: 0.1356 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3545 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:02:02.616
	[orchestrator] 11:02:02 SUCCESS Step 233 | Time: 17.21s | Reward: 1.7989 | Throughput: 3799.6 tokens/s | Seq. Length: 1016.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:02:02    INFO Starting orchestrator step 234
Feb 15  03:02:06.622
	[default0]:11:02:06 SUCCESS Step 233 | Time: 12.48s | Loss: -0.0000 | Entropy: 0.1201 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3608 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  03:02:08.619
	[rank_0] 11:02:06 SUCCESS Step 233 | Time: 12.48s | Loss: -0.0000 | Entropy: 0.1201 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3608 tokens/s | MFU: 4.0% | Peak Mem.: 44.7 GiB
Feb 15  03:02:20.624
	[orchestrator] 11:02:19 SUCCESS Step 234 | Time: 16.80s | Reward: 1.7728 | Throughput: 3731.7 tokens/s | Seq. Length: 971.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:02:19    INFO Starting orchestrator step 235
Feb 15  03:02:22.792
	[default0]:11:02:22 SUCCESS Step 234 | Time: 15.50s | Loss: -0.0021 | Entropy: 0.1071 | Mismatch KL: 0.0004 | Grad. Norm: 0.0209 | LR: 1.00e-05 | Throughput: 3511 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:02:23.625
	[rank_0] 11:02:22 SUCCESS Step 234 | Time: 15.50s | Loss: -0.0021 | Entropy: 0.1071 | Mismatch KL: 0.0004 | Grad. Norm: 0.0209 | LR: 1.00e-05 | Throughput: 3511 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:02:38.637
	[orchestrator] 11:02:35 SUCCESS Step 235 | Time: 16.73s | Reward: 1.7404 | Throughput: 3837.5 tokens/s | Seq. Length: 996.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:02:35    INFO Starting orchestrator step 236
Feb 15  03:02:40.973
	[default0]:11:02:40 SUCCESS Step 235 | Time: 17.52s | Loss: -0.0017 | Entropy: 0.1159 | Mismatch KL: 0.0004 | Grad. Norm: 0.0249 | LR: 1.00e-05 | Throughput: 3491 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:02:41.635
	[rank_0] 11:02:40 SUCCESS Step 235 | Time: 17.52s | Loss: -0.0017 | Entropy: 0.1159 | Mismatch KL: 0.0004 | Grad. Norm: 0.0249 | LR: 1.00e-05 | Throughput: 3491 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:02:53.640
	[orchestrator] 11:02:52 SUCCESS Step 236 | Time: 16.66s | Reward: 1.7686 | Throughput: 3970.8 tokens/s | Seq. Length: 1023.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:02:52    INFO Starting orchestrator step 237
Feb 15  03:02:57.146
	[default0]:11:02:57 SUCCESS Step 236 | Time: 15.47s | Loss: -0.0008 | Entropy: 0.0925 | Mismatch KL: 0.0004 | Grad. Norm: 0.0131 | LR: 1.00e-05 | Throughput: 3515 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:02:59.642
	[rank_0] 11:02:57 SUCCESS Step 236 | Time: 15.47s | Loss: -0.0008 | Entropy: 0.0925 | Mismatch KL: 0.0004 | Grad. Norm: 0.0131 | LR: 1.00e-05 | Throughput: 3515 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:03:11.648
	[orchestrator] 11:03:09 SUCCESS Step 237 | Time: 16.70s | Reward: 1.7430 | Throughput: 3738.3 tokens/s | Seq. Length: 969.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:03:09    INFO Starting orchestrator step 238
Feb 15  03:03:13.316
	[default0]:11:03:13 SUCCESS Step 237 | Time: 15.47s | Loss: -0.0005 | Entropy: 0.1224 | Mismatch KL: 0.0005 | Grad. Norm: 0.0215 | LR: 1.00e-05 | Throughput: 3426 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:03:14.649
	[rank_0] 11:03:13 SUCCESS Step 237 | Time: 15.47s | Loss: -0.0005 | Entropy: 0.1224 | Mismatch KL: 0.0005 | Grad. Norm: 0.0215 | LR: 1.00e-05 | Throughput: 3426 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:03:26.655
	[orchestrator] 11:03:25 SUCCESS Step 238 | Time: 16.49s | Reward: 1.7998 | Throughput: 3866.1 tokens/s | Seq. Length: 986.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:03:25    INFO Starting orchestrator step 239
Feb 15  03:03:29.489
	[default0]:11:03:29 SUCCESS Step 238 | Time: 15.51s | Loss: -0.0000 | Entropy: 0.0928 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3319 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:03:29.657
	[rank_0] 11:03:29 SUCCESS Step 238 | Time: 15.51s | Loss: -0.0000 | Entropy: 0.0928 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3319 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:03:44.663
	[orchestrator] 11:03:42 SUCCESS Step 239 | Time: 16.55s | Reward: 1.7994 | Throughput: 3976.0 tokens/s | Seq. Length: 1021.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:03:42    INFO Saving checkpoint at step 240
[orchestrator] 11:03:42    INFO Starting orchestrator step 240
Feb 15  03:03:46.671
	[default0]:11:03:46 SUCCESS Step 239 | Time: 16.46s | Loss: 0.0000 | Entropy: 0.1207 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 6481 tokens/s | MFU: 7.2% | Peak Mem.: 44.7 GiB
Feb 15  03:03:47.274
	[default0]:11:03:47    INFO Saving checkpoint at step 240
Feb 15  03:03:47.665
	[rank_0] 11:03:46 SUCCESS Step 239 | Time: 16.46s | Loss: 0.0000 | Entropy: 0.1207 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 6481 tokens/s | MFU: 7.2% | Peak Mem.: 44.7 GiB
[rank_0] 11:03:47    INFO Saving checkpoint at step 240
Feb 15  03:03:59.670
	[orchestrator] 11:03:58    INFO Logging samples to W&B table at step 240
[orchestrator] 11:03:58 SUCCESS Step 240 | Time: 16.60s | Reward: 1.7745 | Throughput: 4006.3 tokens/s | Seq. Length: 1029.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:03:58    INFO Starting orchestrator step 241
Feb 15  03:04:17.953
	[orchestrator] 11:04:15 SUCCESS Step 241 | Time: 16.39s | Reward: 1.7964 | Throughput: 4028.0 tokens/s | Seq. Length: 1024.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:04:15    INFO Starting orchestrator step 242
[orchestrator] 11:04:16    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 241 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:04:52.722
	[default0]:11:04:52    INFO Saving weight checkpoint at step 240
Feb 15  03:04:54.216
	[rank_0] 11:04:52    INFO Saving weight checkpoint at step 240
Feb 15  03:06:11.761
	[default0]:11:06:11 SUCCESS Step 240 | Time: 4.90s | Loss: -0.0011 | Entropy: 0.1154 | Mismatch KL: 0.0004 | Grad. Norm: 0.0144 | LR: 1.00e-05 | Throughput: 3024 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  03:06:12.253
	[rank_0] 11:06:11 SUCCESS Step 240 | Time: 4.90s | Loss: -0.0011 | Entropy: 0.1154 | Mismatch KL: 0.0004 | Grad. Norm: 0.0144 | LR: 1.00e-05 | Throughput: 3024 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:06:15.254
	[orchestrator] 11:06:12    INFO Orchestrator resumed: checkpoint 241 ready (after 116.39s)
[orchestrator] 11:06:12 SUCCESS Step 242 | Time: 117.62s | Reward: 1.4081 | Throughput: 579.8 tokens/s | Seq. Length: 1063.9 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:06:12    INFO Starting orchestrator step 243
[orchestrator] 11:06:13    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 242 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:06:16.882
	[default0]:11:06:16 SUCCESS Step 241 | Time: 4.47s | Loss: 0.0000 | Entropy: 0.1248 | Mismatch KL: 0.0004 | Grad. Norm: 0.0009 | LR: 1.00e-05 | Throughput: 3022 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:06:18.256
	[rank_0] 11:06:16 SUCCESS Step 241 | Time: 4.47s | Loss: 0.0000 | Entropy: 0.1248 | Mismatch KL: 0.0004 | Grad. Norm: 0.0009 | LR: 1.00e-05 | Throughput: 3022 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
[orchestrator] 11:06:17    INFO Orchestrator resumed: checkpoint 242 ready (after 4.01s)
Feb 15  03:06:22.007
	[default0]:11:06:21 SUCCESS Step 242 | Time: 4.38s | Loss: -0.0023 | Entropy: 0.1713 | Mismatch KL: 0.0005 | Grad. Norm: 0.0216 | LR: 1.00e-05 | Throughput: 3103 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:06:24.260
	[rank_0] 11:06:21 SUCCESS Step 242 | Time: 4.38s | Loss: -0.0023 | Entropy: 0.1713 | Mismatch KL: 0.0005 | Grad. Norm: 0.0216 | LR: 1.00e-05 | Throughput: 3103 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:06:33.263
	[orchestrator] 11:06:30 SUCCESS Step 243 | Time: 17.41s | Reward: 1.7997 | Throughput: 3638.7 tokens/s | Seq. Length: 983.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:06:30    INFO Starting orchestrator step 244
Feb 15  03:06:34.166
	[default0]:11:06:34 SUCCESS Step 243 | Time: 11.51s | Loss: -0.0000 | Entropy: 0.1157 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3153 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:06:36.265
	[rank_0] 11:06:34 SUCCESS Step 243 | Time: 11.51s | Loss: -0.0000 | Entropy: 0.1157 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3153 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:06:48.272
	[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:06:47 SUCCESS Step 244 | Time: 17.09s | Reward: 1.2933 | Throughput: 2912.5 tokens/s | Seq. Length: 771.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:06:47    INFO Starting orchestrator step 245
Feb 15  03:06:51.348
	[default0]:11:06:51 SUCCESS Step 244 | Time: 16.28s | Loss: 0.0006 | Entropy: 0.1171 | Mismatch KL: 0.0003 | Grad. Norm: 0.0178 | LR: 1.00e-05 | Throughput: 3076 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:06:54.274
	[rank_0] 11:06:51 SUCCESS Step 244 | Time: 16.28s | Loss: 0.0006 | Entropy: 0.1171 | Mismatch KL: 0.0003 | Grad. Norm: 0.0178 | LR: 1.00e-05 | Throughput: 3076 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:07:06.282
	[orchestrator] 11:07:04 SUCCESS Step 245 | Time: 16.79s | Reward: 1.7997 | Throughput: 3913.5 tokens/s | Seq. Length: 1019.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:07:04    INFO Starting orchestrator step 246
Feb 15  03:07:09.549
	[default0]:11:07:09 SUCCESS Step 245 | Time: 17.55s | Loss: 0.0000 | Entropy: 0.1025 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3044 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:07:12.285
	[rank_0] 11:07:09 SUCCESS Step 245 | Time: 17.55s | Loss: 0.0000 | Entropy: 0.1025 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3044 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:07:21.289
	[orchestrator] 11:07:21 SUCCESS Step 246 | Time: 16.88s | Reward: 1.7992 | Throughput: 3985.0 tokens/s | Seq. Length: 1040.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:07:21    INFO Starting orchestrator step 247
Feb 15  03:07:25.722
	[default0]:11:07:25 SUCCESS Step 246 | Time: 15.41s | Loss: 0.0000 | Entropy: 0.1208 | Mismatch KL: 0.0003 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3147 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:07:27.291
	[rank_0] 11:07:25 SUCCESS Step 246 | Time: 15.41s | Loss: 0.0000 | Entropy: 0.1208 | Mismatch KL: 0.0003 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3147 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:07:39.297
	[orchestrator] 11:07:37 SUCCESS Step 247 | Time: 16.62s | Reward: 1.7654 | Throughput: 3689.9 tokens/s | Seq. Length: 951.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:07:37    INFO Starting orchestrator step 248
Feb 15  03:07:41.893
	[default0]:11:07:41 SUCCESS Step 247 | Time: 15.47s | Loss: -0.0038 | Entropy: 0.1003 | Mismatch KL: 0.0005 | Grad. Norm: 0.0186 | LR: 1.00e-05 | Throughput: 3147 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:07:42.299
	[rank_0] 11:07:41 SUCCESS Step 247 | Time: 15.47s | Loss: -0.0038 | Entropy: 0.1003 | Mismatch KL: 0.0005 | Grad. Norm: 0.0186 | LR: 1.00e-05 | Throughput: 3147 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:07:58.315
	[orchestrator] 11:07:55 SUCCESS Step 248 | Time: 17.22s | Reward: 1.7997 | Throughput: 3814.4 tokens/s | Seq. Length: 1018.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:07:55    INFO Starting orchestrator step 249
Feb 15  03:08:01.288
	[default0]:11:08:01 SUCCESS Step 248 | Time: 18.78s | Loss: 0.0000 | Entropy: 0.1154 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3124 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:08:01.317
	[rank_0] 11:08:01 SUCCESS Step 248 | Time: 18.78s | Loss: 0.0000 | Entropy: 0.1154 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3124 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:08:13.322
	[orchestrator] 11:08:11 SUCCESS Step 249 | Time: 16.96s | Reward: 1.7505 | Throughput: 3772.8 tokens/s | Seq. Length: 993.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:08:11    INFO Saving checkpoint at step 250
[orchestrator] 11:08:11    INFO Starting orchestrator step 250
Feb 15  03:08:15.557
	[default0]:11:08:15 SUCCESS Step 249 | Time: 13.53s | Loss: -0.0005 | Entropy: 0.1280 | Mismatch KL: 0.0005 | Grad. Norm: 0.0204 | LR: 1.00e-05 | Throughput: 6257 tokens/s | MFU: 7.0% | Peak Mem.: 44.7 GiB
Feb 15  03:08:16.261
	[default0]:11:08:16    INFO Saving checkpoint at step 250
Feb 15  03:08:16.324
	[rank_0] 11:08:15 SUCCESS Step 249 | Time: 13.53s | Loss: -0.0005 | Entropy: 0.1280 | Mismatch KL: 0.0005 | Grad. Norm: 0.0204 | LR: 1.00e-05 | Throughput: 6257 tokens/s | MFU: 7.0% | Peak Mem.: 44.7 GiB
[rank_0] 11:08:16    INFO Saving checkpoint at step 250
Feb 15  03:08:31.332
	[orchestrator] 11:08:28    INFO Logging samples to W&B table at step 250
[orchestrator] 11:08:28 SUCCESS Step 250 | Time: 16.67s | Reward: 1.7426 | Throughput: 3631.6 tokens/s | Seq. Length: 940.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:08:28    INFO Starting orchestrator step 251
Feb 15  03:08:46.340
	[orchestrator] 11:08:45 SUCCESS Step 251 | Time: 16.55s | Reward: 1.7989 | Throughput: 3921.5 tokens/s | Seq. Length: 1006.8 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:08:45    INFO Starting orchestrator step 252
[orchestrator] 11:08:45    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 251 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:09:02.375
	[default0]:11:09:02    INFO Saving weight checkpoint at step 250
Feb 15  03:09:04.348
	[rank_0] 11:09:02    INFO Saving weight checkpoint at step 250
Feb 15  03:10:19.015
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:11:10:18 SUCCESS Step 250 | Time: 4.14s | Loss: -0.0004 | Entropy: 0.1246 | Mismatch KL: 0.0005 | Grad. Norm: 0.0181 | LR: 1.00e-05 | Throughput: 3101 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  03:10:19.386
	[rank_0] 11:10:18 SUCCESS Step 250 | Time: 4.14s | Loss: -0.0004 | Entropy: 0.1246 | Mismatch KL: 0.0005 | Grad. Norm: 0.0181 | LR: 1.00e-05 | Throughput: 3101 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:10:22.388
	[orchestrator] 11:10:20    INFO Orchestrator resumed: checkpoint 251 ready (after 94.17s)
[orchestrator] 11:10:20 SUCCESS Step 252 | Time: 95.09s | Reward: 1.7994 | Throughput: 696.8 tokens/s | Seq. Length: 1034.1 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 1
[orchestrator] 11:10:20    INFO Starting orchestrator step 253
[orchestrator] 11:10:21    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 252 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:10:24.237
	[default0]:11:10:24 SUCCESS Step 251 | Time: 4.49s | Loss: -0.0000 | Entropy: 0.0924 | Mismatch KL: 0.0004 | Grad. Norm: 0.0003 | LR: 1.00e-05 | Throughput: 3106 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:10:25.390
	[rank_0] 11:10:24 SUCCESS Step 251 | Time: 4.49s | Loss: -0.0000 | Entropy: 0.0924 | Mismatch KL: 0.0004 | Grad. Norm: 0.0003 | LR: 1.00e-05 | Throughput: 3106 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
[orchestrator] 11:10:25    INFO Orchestrator resumed: checkpoint 252 ready (after 4.01s)
Feb 15  03:10:29.257
	[default0]:11:10:29 SUCCESS Step 252 | Time: 4.40s | Loss: -0.0000 | Entropy: 0.1029 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3293 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:10:31.394
	[rank_0] 11:10:29 SUCCESS Step 252 | Time: 4.40s | Loss: -0.0000 | Entropy: 0.1029 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3293 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:10:37.396
	[orchestrator] 11:10:37 SUCCESS Step 253 | Time: 16.96s | Reward: 1.7996 | Throughput: 3753.4 tokens/s | Seq. Length: 988.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 2
[orchestrator] 11:10:37    INFO Starting orchestrator step 254
Feb 15  03:10:42.409
	[default0]:11:10:42 SUCCESS Step 253 | Time: 12.45s | Loss: 0.0000 | Entropy: 0.1300 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3440 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:10:43.399
	[rank_0] 11:10:42 SUCCESS Step 253 | Time: 12.45s | Loss: 0.0000 | Entropy: 0.1300 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3440 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:10:55.404
	[orchestrator] 11:10:54 SUCCESS Step 254 | Time: 16.91s | Reward: 1.7992 | Throughput: 3898.2 tokens/s | Seq. Length: 1022.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:10:54    INFO Starting orchestrator step 255
Feb 15  03:10:59.893
	[default0]:11:10:59 SUCCESS Step 254 | Time: 16.89s | Loss: -0.0000 | Entropy: 0.1199 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3455 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:11:01.407
	[rank_0] 11:10:59 SUCCESS Step 254 | Time: 16.89s | Loss: -0.0000 | Entropy: 0.1199 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3455 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:11:13.494
	[orchestrator] 11:11:11 SUCCESS Step 255 | Time: 16.99s | Reward: 1.7997 | Throughput: 3921.4 tokens/s | Seq. Length: 1034.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:11:11    INFO Starting orchestrator step 256
Feb 15  03:11:16.064
	[default0]:11:11:15 SUCCESS Step 255 | Time: 15.48s | Loss: 0.0000 | Entropy: 0.0887 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3455 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:11:16.496
	[rank_0] 11:11:15 SUCCESS Step 255 | Time: 15.48s | Loss: 0.0000 | Entropy: 0.0887 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3455 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:11:28.501
	[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:11:27 SUCCESS Step 256 | Time: 16.21s | Reward: 1.3495 | Throughput: 2882.4 tokens/s | Seq. Length: 725.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:11:27    INFO Starting orchestrator step 257
Feb 15  03:11:31.231
	[default0]:11:11:31 SUCCESS Step 256 | Time: 14.52s | Loss: -0.0000 | Entropy: 0.1152 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3469 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:11:31.502
	[rank_0] 11:11:31 SUCCESS Step 256 | Time: 14.52s | Loss: -0.0000 | Entropy: 0.1152 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3469 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:11:46.509
	[orchestrator] 11:11:44 SUCCESS Step 257 | Time: 16.86s | Reward: 1.7678 | Throughput: 3860.0 tokens/s | Seq. Length: 1005.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:11:44    INFO Starting orchestrator step 258
Feb 15  03:11:49.412
	[default0]:11:11:49 SUCCESS Step 257 | Time: 17.51s | Loss: 0.0004 | Entropy: 0.1089 | Mismatch KL: 0.0003 | Grad. Norm: 0.0065 | LR: 1.00e-05 | Throughput: 3481 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:11:49.510
	[rank_0] 11:11:49 SUCCESS Step 257 | Time: 17.51s | Loss: 0.0004 | Entropy: 0.1089 | Mismatch KL: 0.0003 | Grad. Norm: 0.0065 | LR: 1.00e-05 | Throughput: 3481 tokens/s | MFU: 3.9% | Peak Mem.: 44.7 GiB
Feb 15  03:12:01.515
	[orchestrator] 11:12:01 SUCCESS Step 258 | Time: 16.70s | Reward: 1.7994 | Throughput: 3626.8 tokens/s | Seq. Length: 940.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:12:01    INFO Starting orchestrator step 259
Feb 15  03:12:04.982
	[default0]:11:12:04 SUCCESS Step 258 | Time: 14.88s | Loss: 0.0000 | Entropy: 0.1308 | Mismatch KL: 0.0006 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3456 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:12:07.518
	[rank_0] 11:12:04 SUCCESS Step 258 | Time: 14.88s | Loss: 0.0000 | Entropy: 0.1308 | Mismatch KL: 0.0006 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3456 tokens/s | MFU: 3.8% | Peak Mem.: 44.7 GiB
Feb 15  03:12:20.350
	[orchestrator] 11:12:17 SUCCESS Step 259 | Time: 16.65s | Reward: 1.7996 | Throughput: 3708.1 tokens/s | Seq. Length: 953.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:12:17    INFO Saving checkpoint at step 260
[orchestrator] 11:12:17    INFO Starting orchestrator step 260
Feb 15  03:12:21.456
	[default0]:11:12:21 SUCCESS Step 259 | Time: 15.76s | Loss: 0.0000 | Entropy: 0.1448 | Mismatch KL: 0.0007 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 6486 tokens/s | MFU: 7.2% | Peak Mem.: 44.7 GiB
Feb 15  03:12:22.375
	[default0]:11:12:22    INFO Saving checkpoint at step 260
Feb 15  03:12:23.352
	[rank_0] 11:12:21 SUCCESS Step 259 | Time: 15.76s | Loss: 0.0000 | Entropy: 0.1448 | Mismatch KL: 0.0007 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 6486 tokens/s | MFU: 7.2% | Peak Mem.: 44.7 GiB
[rank_0] 11:12:22    INFO Saving checkpoint at step 260
Feb 15  03:12:35.357
	[orchestrator] 11:12:33    INFO Logging samples to W&B table at step 260
[orchestrator] 11:12:33 SUCCESS Step 260 | Time: 16.14s | Reward: 1.7966 | Throughput: 4079.5 tokens/s | Seq. Length: 1021.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:12:33    INFO Starting orchestrator step 261
Feb 15  03:12:50.365
	[orchestrator] 11:12:50 SUCCESS Step 261 | Time: 16.18s | Reward: 1.7998 | Throughput: 3900.8 tokens/s | Seq. Length: 975.9 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:12:50    INFO Starting orchestrator step 262
Feb 15  03:12:53.367
	[orchestrator] 11:12:50    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 261 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:13:09.315
	[default0]:11:13:09    INFO Saving weight checkpoint at step 260
Feb 15  03:13:11.376
	[rank_0] 11:13:09    INFO Saving weight checkpoint at step 260
Feb 15  03:14:27.257
	[default0]:11:14:27 SUCCESS Step 260 | Time: 4.61s | Loss: 0.0000 | Entropy: 0.1130 | Mismatch KL: 0.0004 | Grad. Norm: 0.0005 | LR: 1.00e-05 | Throughput: 3267 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:14:27.272
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  03:14:29.413
	[rank_0] 11:14:27 SUCCESS Step 260 | Time: 4.61s | Loss: 0.0000 | Entropy: 0.1130 | Mismatch KL: 0.0004 | Grad. Norm: 0.0005 | LR: 1.00e-05 | Throughput: 3267 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
[orchestrator] 11:14:28    INFO Orchestrator resumed: checkpoint 261 ready (after 98.13s)
[orchestrator] 11:14:29 SUCCESS Step 262 | Time: 98.99s | Reward: 1.7997 | Throughput: 667.9 tokens/s | Seq. Length: 1032.0 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 1
[orchestrator] 11:14:29    INFO Starting orchestrator step 263
Feb 15  03:14:31.376
	[default0]:11:14:31 SUCCESS Step 261 | Time: 3.47s | Loss: 0.0000 | Entropy: 0.1110 | Mismatch KL: 0.0005 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3176 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:14:32.414
	[rank_0] 11:14:31 SUCCESS Step 261 | Time: 3.47s | Loss: 0.0000 | Entropy: 0.1110 | Mismatch KL: 0.0005 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3176 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
[orchestrator] 11:14:29    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 262 (>1 step(s) ahead). Training is progressing normally.
[orchestrator] 11:14:32    INFO Orchestrator resumed: checkpoint 262 ready (after 2.00s)
Feb 15  03:14:36.500
	[default0]:11:14:36 SUCCESS Step 262 | Time: 4.45s | Loss: 0.0000 | Entropy: 0.0992 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3298 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:14:38.419
	[rank_0] 11:14:36 SUCCESS Step 262 | Time: 4.45s | Loss: 0.0000 | Entropy: 0.0992 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3298 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:14:47.422
	[orchestrator] 11:14:45 SUCCESS Step 263 | Time: 16.27s | Reward: 1.7714 | Throughput: 3753.2 tokens/s | Seq. Length: 946.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 2
[orchestrator] 11:14:45    INFO Starting orchestrator step 264
Feb 15  03:14:49.664
	[default0]:11:14:49 SUCCESS Step 263 | Time: 12.48s | Loss: 0.0001 | Entropy: 0.1061 | Mismatch KL: 0.0006 | Grad. Norm: 0.0090 | LR: 1.00e-05 | Throughput: 3254 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:14:50.423
	[rank_0] 11:14:49 SUCCESS Step 263 | Time: 12.48s | Loss: 0.0001 | Entropy: 0.1061 | Mismatch KL: 0.0006 | Grad. Norm: 0.0090 | LR: 1.00e-05 | Throughput: 3254 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:15:02.428
	[orchestrator] 11:15:01 SUCCESS Step 264 | Time: 16.28s | Reward: 1.7994 | Throughput: 3711.0 tokens/s | Seq. Length: 938.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:15:01    INFO Starting orchestrator step 265
Feb 15  03:15:05.834
	[default0]:11:15:05 SUCCESS Step 264 | Time: 15.46s | Loss: -0.0000 | Entropy: 0.1268 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3140 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:15:08.431
	[rank_0] 11:15:05 SUCCESS Step 264 | Time: 15.46s | Loss: -0.0000 | Entropy: 0.1268 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3140 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:15:20.438
	[orchestrator] 11:15:19 SUCCESS Step 265 | Time: 17.41s | Reward: 1.7997 | Throughput: 3967.5 tokens/s | Seq. Length: 1034.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:15:19    INFO Starting orchestrator step 266
Feb 15  03:15:23.917
	[default0]:11:15:23 SUCCESS Step 265 | Time: 17.38s | Loss: -0.0000 | Entropy: 0.1263 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3199 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:15:26.440
	[rank_0] 11:15:23 SUCCESS Step 265 | Time: 17.38s | Loss: -0.0000 | Entropy: 0.1263 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3199 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:15:35.445
	[orchestrator] 11:15:34 SUCCESS Step 266 | Time: 15.48s | Reward: 1.7997 | Throughput: 4062.7 tokens/s | Seq. Length: 975.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:15:34    INFO Starting orchestrator step 267
Feb 15  03:15:38.094
	[default0]:11:15:38 SUCCESS Step 266 | Time: 13.55s | Loss: 0.0000 | Entropy: 0.0824 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3156 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:15:38.446
	[rank_0] 11:15:38 SUCCESS Step 266 | Time: 13.55s | Loss: 0.0000 | Entropy: 0.0824 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3156 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:15:53.452
	[orchestrator] 11:15:50 SUCCESS Step 267 | Time: 16.24s | Reward: 1.7994 | Throughput: 4015.6 tokens/s | Seq. Length: 1009.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:15:50    INFO Starting orchestrator step 268
Feb 15  03:15:55.181
	[default0]:11:15:55 SUCCESS Step 267 | Time: 16.43s | Loss: -0.0000 | Entropy: 0.1206 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3237 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:15:56.453
	[rank_0] 11:15:55 SUCCESS Step 267 | Time: 16.43s | Loss: -0.0000 | Entropy: 0.1206 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3237 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:16:08.459
	[orchestrator] 11:16:06 SUCCESS Step 268 | Time: 15.99s | Reward: 1.7997 | Throughput: 4031.0 tokens/s | Seq. Length: 1000.1 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:16:06    INFO Starting orchestrator step 269
Feb 15  03:16:11.359
	[default0]:11:16:11 SUCCESS Step 268 | Time: 15.48s | Loss: -0.0000 | Entropy: 0.1174 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3349 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:16:11.460
	[rank_0] 11:16:11 SUCCESS Step 268 | Time: 15.48s | Loss: -0.0000 | Entropy: 0.1174 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3349 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:16:23.466
	[orchestrator] 11:16:23 SUCCESS Step 269 | Time: 16.17s | Reward: 1.3747 | Throughput: 4034.6 tokens/s | Seq. Length: 1009.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:16:23    INFO Saving checkpoint at step 270
[orchestrator] 11:16:23    INFO Starting orchestrator step 270
Feb 15  03:16:27.443
	[default0]:11:16:27 SUCCESS Step 269 | Time: 15.48s | Loss: -0.0002 | Entropy: 0.1682 | Mismatch KL: 0.0004 | Grad. Norm: 0.0106 | LR: 1.00e-05 | Throughput: 6409 tokens/s | MFU: 7.1% | Peak Mem.: 44.7 GiB
Feb 15  03:16:28.147
	[default0]:11:16:28    INFO Saving checkpoint at step 270
Feb 15  03:16:29.468
	[rank_0] 11:16:27 SUCCESS Step 269 | Time: 15.48s | Loss: -0.0002 | Entropy: 0.1682 | Mismatch KL: 0.0004 | Grad. Norm: 0.0106 | LR: 1.00e-05 | Throughput: 6409 tokens/s | MFU: 7.1% | Peak Mem.: 44.7 GiB
[rank_0] 11:16:28    INFO Saving checkpoint at step 270
Feb 15  03:16:41.475
	[orchestrator] 11:16:39    INFO Logging samples to W&B table at step 270
[orchestrator] 11:16:39 SUCCESS Step 270 | Time: 16.07s | Reward: 1.7995 | Throughput: 3938.7 tokens/s | Seq. Length: 982.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:16:39    INFO Starting orchestrator step 271
Feb 15  03:16:57.259
	[orchestrator] 11:16:55 SUCCESS Step 271 | Time: 15.94s | Reward: 1.7715 | Throughput: 4118.6 tokens/s | Seq. Length: 1015.3 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:16:55    INFO Starting orchestrator step 272
[orchestrator] 11:16:55    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 271 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:17:26.377
	[default0]:11:17:26    INFO Saving weight checkpoint at step 270
Feb 15  03:17:27.711
	[rank_0] 11:17:26    INFO Saving weight checkpoint at step 270
Feb 15  03:18:46.413
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  03:18:46.432
	[default0]:11:18:46 SUCCESS Step 270 | Time: 3.64s | Loss: 0.0000 | Entropy: 0.1148 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3029 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:18:48.750
	[rank_0] 11:18:46 SUCCESS Step 270 | Time: 3.64s | Loss: 0.0000 | Entropy: 0.1148 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3029 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
[orchestrator] 11:18:47    INFO Orchestrator resumed: checkpoint 271 ready (after 112.13s)
[orchestrator] 11:18:47 SUCCESS Step 272 | Time: 112.58s | Reward: 1.7761 | Throughput: 571.1 tokens/s | Seq. Length: 1003.8 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:18:47    INFO Starting orchestrator step 273
[orchestrator] 11:18:48    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 272 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:18:51.559
	[default0]:11:18:51 SUCCESS Step 271 | Time: 4.45s | Loss: 0.0004 | Entropy: 0.1221 | Mismatch KL: 0.0004 | Grad. Norm: 0.0067 | LR: 1.00e-05 | Throughput: 3021 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:18:51.752
	[rank_0] 11:18:51 SUCCESS Step 271 | Time: 4.45s | Loss: 0.0004 | Entropy: 0.1221 | Mismatch KL: 0.0004 | Grad. Norm: 0.0067 | LR: 1.00e-05 | Throughput: 3021 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:18:54.754
	[orchestrator] 11:18:52    INFO Orchestrator resumed: checkpoint 272 ready (after 4.01s)
Feb 15  03:18:56.580
	[default0]:11:18:56 SUCCESS Step 272 | Time: 4.41s | Loss: 0.0001 | Entropy: 0.1110 | Mismatch KL: 0.0003 | Grad. Norm: 0.0068 | LR: 1.00e-05 | Throughput: 3211 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:18:57.756
	[rank_0] 11:18:56 SUCCESS Step 272 | Time: 4.41s | Loss: 0.0001 | Entropy: 0.1110 | Mismatch KL: 0.0003 | Grad. Norm: 0.0068 | LR: 1.00e-05 | Throughput: 3211 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:19:06.760
	[orchestrator] 11:19:04 SUCCESS Step 273 | Time: 16.78s | Reward: 1.7995 | Throughput: 3793.0 tokens/s | Seq. Length: 984.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:19:04    INFO Starting orchestrator step 274
Feb 15  03:19:09.743
	[default0]:11:19:09 SUCCESS Step 273 | Time: 12.46s | Loss: 0.0000 | Entropy: 0.1053 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3344 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:19:09.761
	[rank_0] 11:19:09 SUCCESS Step 273 | Time: 12.46s | Loss: 0.0000 | Entropy: 0.1053 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3344 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:19:21.768
	[orchestrator] 11:19:21 SUCCESS Step 274 | Time: 17.09s | Reward: 1.7997 | Throughput: 3727.5 tokens/s | Seq. Length: 989.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:19:21    INFO Starting orchestrator step 275
Feb 15  03:19:26.920
	[default0]:11:19:26 SUCCESS Step 274 | Time: 16.51s | Loss: 0.0000 | Entropy: 0.1029 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3370 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:19:27.771
	[rank_0] 11:19:26 SUCCESS Step 274 | Time: 16.51s | Loss: 0.0000 | Entropy: 0.1029 | Mismatch KL: 0.0003 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3370 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:19:39.775
	[orchestrator] 11:19:38 SUCCESS Step 275 | Time: 16.92s | Reward: 1.7988 | Throughput: 3463.6 tokens/s | Seq. Length: 907.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:19:38    INFO Starting orchestrator step 276
Feb 15  03:19:42.093
	[default0]:11:19:42 SUCCESS Step 275 | Time: 14.48s | Loss: 0.0000 | Entropy: 0.1016 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3358 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:19:42.777
	[rank_0] 11:19:42 SUCCESS Step 275 | Time: 14.48s | Loss: 0.0000 | Entropy: 0.1016 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3358 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:19:57.782
	[orchestrator] 11:19:55 SUCCESS Step 276 | Time: 16.65s | Reward: 1.7715 | Throughput: 3796.7 tokens/s | Seq. Length: 981.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:19:55    INFO Starting orchestrator step 277
Feb 15  03:19:59.276
	[default0]:11:19:59 SUCCESS Step 276 | Time: 16.48s | Loss: 0.0004 | Entropy: 0.1169 | Mismatch KL: 0.0005 | Grad. Norm: 0.0062 | LR: 1.00e-05 | Throughput: 3264 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:20:00.783
	[rank_0] 11:19:59 SUCCESS Step 276 | Time: 16.48s | Loss: 0.0004 | Entropy: 0.1169 | Mismatch KL: 0.0005 | Grad. Norm: 0.0062 | LR: 1.00e-05 | Throughput: 3264 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:20:12.790
	[orchestrator] 11:20:11 SUCCESS Step 277 | Time: 16.66s | Reward: 1.8000 | Throughput: 3543.8 tokens/s | Seq. Length: 914.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:20:11    INFO Starting orchestrator step 278
Feb 15  03:20:15.459
	[default0]:11:20:15 SUCCESS Step 277 | Time: 15.52s | Loss: -0.0000 | Entropy: 0.0956 | Mismatch KL: 0.0004 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3163 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:20:15.792
	[rank_0] 11:20:15 SUCCESS Step 277 | Time: 15.52s | Loss: -0.0000 | Entropy: 0.0956 | Mismatch KL: 0.0004 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3163 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:20:30.798
	[orchestrator] 11:20:28 SUCCESS Step 278 | Time: 16.29s | Reward: 1.8000 | Throughput: 3738.5 tokens/s | Seq. Length: 945.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:20:28    INFO Starting orchestrator step 279
Feb 15  03:20:31.535
	[default0]:11:20:31 SUCCESS Step 278 | Time: 15.49s | Loss: -0.0000 | Entropy: 0.1108 | Mismatch KL: 0.0005 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3062 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:20:33.799
	[rank_0] 11:20:31 SUCCESS Step 278 | Time: 15.49s | Loss: -0.0000 | Entropy: 0.1108 | Mismatch KL: 0.0005 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3062 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:20:45.804
	[orchestrator] 11:20:44 SUCCESS Step 279 | Time: 16.46s | Reward: 1.5212 | Throughput: 4047.0 tokens/s | Seq. Length: 1031.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:20:44    INFO Saving checkpoint at step 280
[orchestrator] 11:20:44    INFO Starting orchestrator step 280
Feb 15  03:20:49.721
	[default0]:11:20:49 SUCCESS Step 279 | Time: 17.50s | Loss: -0.0023 | Entropy: 0.1724 | Mismatch KL: 0.0004 | Grad. Norm: 0.0184 | LR: 1.00e-05 | Throughput: 6259 tokens/s | MFU: 7.0% | Peak Mem.: 44.7 GiB
Feb 15  03:20:50.427
	[default0]:11:20:50    INFO Saving checkpoint at step 280
Feb 15  03:20:52.274
	[rank_0] 11:20:49 SUCCESS Step 279 | Time: 17.50s | Loss: -0.0023 | Entropy: 0.1724 | Mismatch KL: 0.0004 | Grad. Norm: 0.0184 | LR: 1.00e-05 | Throughput: 6259 tokens/s | MFU: 7.0% | Peak Mem.: 44.7 GiB
[rank_0] 11:20:50    INFO Saving checkpoint at step 280
Feb 15  03:21:02.004
	[orchestrator] 11:21:01    INFO Logging samples to W&B table at step 280
[orchestrator] 11:21:01 SUCCESS Step 280 | Time: 16.62s | Reward: 1.7998 | Throughput: 3671.1 tokens/s | Seq. Length: 947.9 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:21:01    INFO Starting orchestrator step 281
Feb 15  03:21:20.427
	[orchestrator] 11:21:18 SUCCESS Step 281 | Time: 17.05s | Reward: 1.7992 | Throughput: 3664.4 tokens/s | Seq. Length: 966.3 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:21:18    INFO Starting orchestrator step 282
[orchestrator] 11:21:18    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 281 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:21:39.582
	[default0]:11:21:39    INFO Saving weight checkpoint at step 280
Feb 15  03:21:41.438
	[rank_0] 11:21:39    INFO Saving weight checkpoint at step 280
Feb 15  03:22:57.311
	[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  03:22:57.412
	[default0]:11:22:57 SUCCESS Step 280 | Time: 3.72s | Loss: -0.0000 | Entropy: 0.1297 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3047 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:22:59.474
	[rank_0] 11:22:57 SUCCESS Step 280 | Time: 3.72s | Loss: -0.0000 | Entropy: 0.1297 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3047 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
[orchestrator] 11:22:57    INFO Orchestrator resumed: checkpoint 281 ready (after 99.13s)
[orchestrator] 11:22:58 SUCCESS Step 282 | Time: 99.89s | Reward: 1.7966 | Throughput: 590.7 tokens/s | Seq. Length: 921.1 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:22:58    INFO Starting orchestrator step 283
[orchestrator] 11:22:59    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 282 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:23:01.530
	[default0]:11:23:01 SUCCESS Step 281 | Time: 3.49s | Loss: 0.0000 | Entropy: 0.1361 | Mismatch KL: 0.0007 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2968 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  03:23:02.475
	[rank_0] 11:23:01 SUCCESS Step 281 | Time: 3.49s | Loss: 0.0000 | Entropy: 0.1361 | Mismatch KL: 0.0007 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2968 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
[orchestrator] 11:23:02    INFO Orchestrator resumed: checkpoint 282 ready (after 3.00s)
Feb 15  03:23:05.646
	[default0]:11:23:05 SUCCESS Step 282 | Time: 3.51s | Loss: -0.0008 | Entropy: 0.1448 | Mismatch KL: 0.0005 | Grad. Norm: 0.0037 | LR: 1.00e-05 | Throughput: 2992 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  03:23:08.478
	[rank_0] 11:23:05 SUCCESS Step 282 | Time: 3.51s | Loss: -0.0008 | Entropy: 0.1448 | Mismatch KL: 0.0005 | Grad. Norm: 0.0037 | LR: 1.00e-05 | Throughput: 2992 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  03:23:17.482
	[orchestrator] 11:23:15 SUCCESS Step 283 | Time: 16.76s | Reward: 1.7992 | Throughput: 3877.6 tokens/s | Seq. Length: 1006.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:23:15    INFO Starting orchestrator step 284
Feb 15  03:23:19.814
	[default0]:11:23:19 SUCCESS Step 283 | Time: 13.52s | Loss: 0.0000 | Entropy: 0.1002 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3023 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:23:20.483
	[rank_0] 11:23:19 SUCCESS Step 283 | Time: 13.52s | Loss: 0.0000 | Entropy: 0.1002 | Mismatch KL: 0.0004 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 3023 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:23:32.489
	[orchestrator] 11:23:31 SUCCESS Step 284 | Time: 16.85s | Reward: 1.7992 | Throughput: 3986.9 tokens/s | Seq. Length: 1043.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:23:31    INFO Starting orchestrator step 285
Feb 15  03:23:36.895
	[default0]:11:23:36 SUCCESS Step 284 | Time: 16.39s | Loss: -0.0000 | Entropy: 0.1188 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3088 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:23:38.492
	[rank_0] 11:23:36 SUCCESS Step 284 | Time: 16.39s | Loss: -0.0000 | Entropy: 0.1188 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3088 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:23:50.498
	[orchestrator] 11:23:48 SUCCESS Step 285 | Time: 16.79s | Reward: 1.7993 | Throughput: 3641.3 tokens/s | Seq. Length: 946.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:23:48    INFO Starting orchestrator step 286
Feb 15  03:23:52.065
	[default0]:11:23:52 SUCCESS Step 285 | Time: 14.49s | Loss: -0.0000 | Entropy: 0.1132 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3113 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:23:53.500
	[rank_0] 11:23:52 SUCCESS Step 285 | Time: 14.49s | Loss: -0.0000 | Entropy: 0.1132 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3113 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:24:08.506
	[orchestrator] 11:24:05 SUCCESS Step 286 | Time: 16.80s | Reward: 1.8000 | Throughput: 3792.3 tokens/s | Seq. Length: 989.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:24:05    INFO Starting orchestrator step 287
Feb 15  03:24:10.250
	[default0]:11:24:10 SUCCESS Step 286 | Time: 17.47s | Loss: -0.0000 | Entropy: 0.1108 | Mismatch KL: 0.0005 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3192 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:24:11.507
	[rank_0] 11:24:10 SUCCESS Step 286 | Time: 17.47s | Loss: -0.0000 | Entropy: 0.1108 | Mismatch KL: 0.0005 | Grad. Norm: 0.0000 | LR: 1.00e-05 | Throughput: 3192 tokens/s | MFU: 3.5% | Peak Mem.: 44.7 GiB
Feb 15  03:24:23.512
	[orchestrator] 11:24:22 SUCCESS Step 287 | Time: 17.01s | Reward: 1.7434 | Throughput: 3729.3 tokens/s | Seq. Length: 982.3 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:24:22    INFO Starting orchestrator step 288
Feb 15  03:24:27.328
	[default0]:11:24:27 SUCCESS Step 287 | Time: 16.45s | Loss: -0.0007 | Entropy: 0.1081 | Mismatch KL: 0.0003 | Grad. Norm: 0.0135 | LR: 1.00e-05 | Throughput: 3287 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:24:29.515
	[rank_0] 11:24:27 SUCCESS Step 287 | Time: 16.45s | Loss: -0.0007 | Entropy: 0.1081 | Mismatch KL: 0.0003 | Grad. Norm: 0.0135 | LR: 1.00e-05 | Throughput: 3287 tokens/s | MFU: 3.7% | Peak Mem.: 44.7 GiB
Feb 15  03:24:41.522
	[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 WARNING No trajectory steps for example 6. Skipping rollout.
[orchestrator] 11:24:39 SUCCESS Step 288 | Time: 17.09s | Reward: 1.3495 | Throughput: 2802.1 tokens/s | Seq. Length: 744.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:24:39    INFO Starting orchestrator step 289
Feb 15  03:24:44.000
	[default0]:11:24:43 SUCCESS Step 288 | Time: 15.98s | Loss: -0.0000 | Entropy: 0.1173 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3209 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:24:44.523
	[rank_0] 11:24:43 SUCCESS Step 288 | Time: 15.98s | Loss: -0.0000 | Entropy: 0.1173 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3209 tokens/s | MFU: 3.6% | Peak Mem.: 44.7 GiB
Feb 15  03:24:56.573
	[orchestrator] 11:24:56 SUCCESS Step 289 | Time: 16.80s | Reward: 1.7998 | Throughput: 3816.8 tokens/s | Seq. Length: 993.0 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:24:56    INFO Saving checkpoint at step 290
[orchestrator] 11:24:56    INFO Starting orchestrator step 290
Feb 15  03:25:00.683
	[default0]:11:25:00 SUCCESS Step 289 | Time: 15.98s | Loss: -0.0000 | Entropy: 0.1468 | Mismatch KL: 0.0006 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 6099 tokens/s | MFU: 6.8% | Peak Mem.: 44.7 GiB
Feb 15  03:25:01.388
	[default0]:11:25:01    INFO Saving checkpoint at step 290
Feb 15  03:25:02.576
	[rank_0] 11:25:00 SUCCESS Step 289 | Time: 15.98s | Loss: -0.0000 | Entropy: 0.1468 | Mismatch KL: 0.0006 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 6099 tokens/s | MFU: 6.8% | Peak Mem.: 44.7 GiB
[rank_0] 11:25:01    INFO Saving checkpoint at step 290
Feb 15  03:25:15.551
	[orchestrator] 11:25:13    INFO Logging samples to W&B table at step 290
[orchestrator] 11:25:13 SUCCESS Step 290 | Time: 16.89s | Reward: 1.7995 | Throughput: 3756.4 tokens/s | Seq. Length: 985.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 1
[orchestrator] 11:25:13    INFO Starting orchestrator step 291
Feb 15  03:25:33.560
	[orchestrator] 11:25:30 SUCCESS Step 291 | Time: 17.23s | Reward: 1.7964 | Throughput: 3666.3 tokens/s | Seq. Length: 976.3 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:25:30    INFO Starting orchestrator step 292
[orchestrator] 11:25:30    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 291 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:25:48.967
	[default0]:11:25:48    INFO Saving weight checkpoint at step 290
Feb 15  03:25:51.569
	[rank_0] 11:25:48    INFO Saving weight checkpoint at step 290
Feb 15  03:27:07.810
	[default0]:11:27:07 SUCCESS Step 290 | Time: 3.52s | Loss: 0.0000 | Entropy: 0.1103 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3048 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
[default0]:/root/prime-rl/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:603: UserWarning: Slicing a flattened dim from root mesh will be deprecated in PT 2.11. Users need to bookkeep the flattened mesh directly. 
[default0]:  sliced_mesh_layout = self._get_slice_mesh_layout(mesh_dim_names)
Feb 15  03:27:09.604
	[rank_0] 11:27:07 SUCCESS Step 290 | Time: 3.52s | Loss: 0.0000 | Entropy: 0.1103 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3048 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
[orchestrator] 11:27:08    INFO Orchestrator resumed: checkpoint 291 ready (after 98.13s)
[orchestrator] 11:27:09 SUCCESS Step 292 | Time: 98.42s | Reward: 1.7994 | Throughput: 637.1 tokens/s | Seq. Length: 978.7 tokens/sample | Async Level: 1 | Max. Off-Policy Level: 0
[orchestrator] 11:27:09    INFO Starting orchestrator step 293
Feb 15  03:27:12.027
	[default0]:11:27:11 SUCCESS Step 291 | Time: 3.46s | Loss: -0.0003 | Entropy: 0.1465 | Mismatch KL: 0.0005 | Grad. Norm: 0.0020 | LR: 1.00e-05 | Throughput: 3042 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:27:12.607
	[rank_0] 11:27:11 SUCCESS Step 291 | Time: 3.46s | Loss: -0.0003 | Entropy: 0.1465 | Mismatch KL: 0.0005 | Grad. Norm: 0.0020 | LR: 1.00e-05 | Throughput: 3042 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
[orchestrator] 11:27:09    INFO Orchestrator paused: waiting for trainer process to complete checkpoint 292 (>1 step(s) ahead). Training is progressing normally.
Feb 15  03:27:15.609
	[orchestrator] 11:27:12    INFO Orchestrator resumed: checkpoint 292 ready (after 3.01s)
Feb 15  03:27:16.141
	[default0]:11:27:16 SUCCESS Step 292 | Time: 3.52s | Loss: -0.0000 | Entropy: 0.1160 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3076 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:27:18.609
	[rank_0] 11:27:16 SUCCESS Step 292 | Time: 3.52s | Loss: -0.0000 | Entropy: 0.1160 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3076 tokens/s | MFU: 3.4% | Peak Mem.: 44.7 GiB
Feb 15  03:27:27.614
	[orchestrator] 11:27:26 SUCCESS Step 293 | Time: 16.95s | Reward: 1.7997 | Throughput: 3419.7 tokens/s | Seq. Length: 900.4 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:27:26    INFO Starting orchestrator step 294
Feb 15  03:27:30.305
	[default0]:11:27:30 SUCCESS Step 293 | Time: 13.50s | Loss: -0.0000 | Entropy: 0.1208 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3013 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  03:27:30.615
	[rank_0] 11:27:30 SUCCESS Step 293 | Time: 13.50s | Loss: -0.0000 | Entropy: 0.1208 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 3013 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  03:27:45.622
	[orchestrator] 11:27:42 SUCCESS Step 294 | Time: 16.58s | Reward: 1.7992 | Throughput: 3765.9 tokens/s | Seq. Length: 969.2 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:27:42    INFO Starting orchestrator step 295
Feb 15  03:27:46.080
	[default0]:11:27:46 SUCCESS Step 294 | Time: 15.06s | Loss: 0.0000 | Entropy: 0.0931 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2998 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  03:27:48.623
	[rank_0] 11:27:46 SUCCESS Step 294 | Time: 15.06s | Loss: 0.0000 | Entropy: 0.0931 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2998 tokens/s | MFU: 3.3% | Peak Mem.: 44.7 GiB
Feb 15  03:28:00.629
	[orchestrator] 11:27:59 SUCCESS Step 295 | Time: 16.77s | Reward: 1.7992 | Throughput: 3706.1 tokens/s | Seq. Length: 965.7 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:27:59    INFO Starting orchestrator step 296
Feb 15  03:28:03.256
	[default0]:11:28:03 SUCCESS Step 295 | Time: 16.37s | Loss: -0.0000 | Entropy: 0.0936 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2902 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  03:28:03.630
	[rank_0] 11:28:03 SUCCESS Step 295 | Time: 16.37s | Loss: -0.0000 | Entropy: 0.0936 | Mismatch KL: 0.0005 | Grad. Norm: 0.0002 | LR: 1.00e-05 | Throughput: 2902 tokens/s | MFU: 3.2% | Peak Mem.: 44.7 GiB
Feb 15  03:28:18.636
	[orchestrator] 11:28:15 SUCCESS Step 296 | Time: 16.32s | Reward: 1.7997 | Throughput: 3418.2 tokens/s | Seq. Length: 866.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:28:15    INFO Starting orchestrator step 297
Feb 15  03:28:19.429
	[default0]:11:28:19 SUCCESS Step 296 | Time: 15.52s | Loss: 0.0000 | Entropy: 0.1376 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2801 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  03:28:21.637
	[rank_0] 11:28:19 SUCCESS Step 296 | Time: 15.52s | Loss: 0.0000 | Entropy: 0.1376 | Mismatch KL: 0.0004 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2801 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  03:28:33.643
	[orchestrator] 11:28:32 SUCCESS Step 297 | Time: 16.30s | Reward: 1.7715 | Throughput: 3583.4 tokens/s | Seq. Length: 907.5 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:28:32    INFO Starting orchestrator step 298
Feb 15  03:28:35.603
	[default0]:11:28:35 SUCCESS Step 297 | Time: 15.47s | Loss: 0.0003 | Entropy: 0.1187 | Mismatch KL: 0.0005 | Grad. Norm: 0.0138 | LR: 1.00e-05 | Throughput: 2806 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  03:28:36.643
	[rank_0] 11:28:35 SUCCESS Step 297 | Time: 15.47s | Loss: 0.0003 | Entropy: 0.1187 | Mismatch KL: 0.0005 | Grad. Norm: 0.0138 | LR: 1.00e-05 | Throughput: 2806 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  03:28:51.652
	[orchestrator] 11:28:48 SUCCESS Step 298 | Time: 16.60s | Reward: 1.7997 | Throughput: 3567.5 tokens/s | Seq. Length: 919.8 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:28:48    INFO Starting orchestrator step 299
Feb 15  03:28:52.890
	[default0]:11:28:52 SUCCESS Step 298 | Time: 16.10s | Loss: -0.0000 | Entropy: 0.1139 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2804 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  03:28:54.653
	[rank_0] 11:28:52 SUCCESS Step 298 | Time: 16.10s | Loss: -0.0000 | Entropy: 0.1139 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 2804 tokens/s | MFU: 3.1% | Peak Mem.: 44.7 GiB
Feb 15  03:29:07.384
	[orchestrator] 11:29:05 SUCCESS Step 299 | Time: 16.83s | Reward: 1.7995 | Throughput: 3797.4 tokens/s | Seq. Length: 992.6 tokens/sample | Async Level: 0 | Max. Off-Policy Level: 0
[orchestrator] 11:29:05    INFO Saving checkpoint at step 300
[orchestrator] 11:29:05    INFO Logging final samples to W&B table
[orchestrator] 11:29:05    INFO Saving final summary to file
[orchestrator] 11:29:05    INFO Writing final checkpoint
[orchestrator] 11:29:05 SUCCESS Orchestrator finished.
Feb 15  03:29:09.478
	[default0]:11:29:09 SUCCESS Step 299 | Time: 15.74s | Loss: 0.0000 | Entropy: 0.1205 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 5352 tokens/s | MFU: 5.9% | Peak Mem.: 44.7 GiB
Feb 15  03:29:10.182
	[default0]:11:29:10    INFO Writing final checkpoint
Feb 15  03:29:10.386
	[rank_0] 11:29:09 SUCCESS Step 299 | Time: 15.74s | Loss: 0.0000 | Entropy: 0.1205 | Mismatch KL: 0.0005 | Grad. Norm: 0.0001 | LR: 1.00e-05 | Throughput: 5352 tokens/s | MFU: 5.9% | Peak Mem.: 44.7 GiB
[rank_0] 11:29:10    INFO Writing final checkpoint
Feb 15  03:29:56.086
	[default0]:11:29:56    INFO Writing final weight checkpoint
Feb 15  03:29:58.482
	[rank_0] 11:29:56    INFO Writing final weight checkpoint
Feb 15  03:31:10.828
	[default0]:11:31:10    INFO Peak memory: 44.7 GiB
[default0]:11:31:10 SUCCESS RL trainer finished!
Feb 15  03:31:10.928
	[default0]:wandb: 
[default0]:wandb: Run history:
[default0]:wandb:            entropy/max 
[default0]:wandb:           entropy/mean 
[default0]:wandb:         entropy/median 
[default0]:wandb:            entropy/min 
[default0]:wandb:            entropy/std 
[default0]:wandb:    geo_masked_high/max 
[default0]:wandb:   geo_masked_high/mean 
[default0]:wandb: geo_masked_high/median 
[default0]:wandb:    geo_masked_high/min 
[default0]:wandb:    geo_masked_high/std 
[default0]:wandb:                    +82 ...
[default0]:wandb: 
[default0]:wandb: Run summary:
[default0]:wandb:            entropy/max 3.58424
[default0]:wandb:           entropy/mean 0.12047
[default0]:wandb:         entropy/median 9e-05
[default0]:wandb:            entropy/min -0.0
[default0]:wandb:            entropy/std 0.33623
[default0]:wandb:    geo_masked_high/max 0
Feb 15  03:31:10.934
	[default0]:wandb:   geo_masked_high/mean 0
[default0]:wandb: geo_masked_high/median 0
[default0]:wandb:    geo_masked_high/min 0
[default0]:wandb:    geo_masked_high/std 0
[default0]:wandb:                    +82 ...
[default0]:wandb: 
[default0]:wandb: You can sync this run to the cloud by running:
[default0]:wandb: wandb sync /root/checkpoints/nemotron-all-envs-v2/wandb/offline-run-20260215_091020-se5z2se6
[default0]:wandb: Find logs at: /root/checkpoints/nemotron-all-envs-v2/wandb/offline-run-20260215_091020-se5z2se6/logs
Feb 15  03:31:13.553
	[rank_0] 11:31:10    INFO Peak memory: 44.7 GiB
[rank_0] 11:31:10 SUCCESS RL trainer finished!
Feb 15  03:31:17.588
	11:31:17 SUCCESS RL training finished!
